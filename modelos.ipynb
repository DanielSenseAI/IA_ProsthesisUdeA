{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec2807be",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.io import loadmat, whosmat\n",
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.linalg import inv\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "\n",
    "import pywt\n",
    "\n",
    "import pycaret.classification as pyc\n",
    "from pycaret.classification import *\n",
    "\n",
    "import src\n",
    "from src import config, loadmatNina\n",
    "from src.preprocessing_utils import get_envelope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_by_relabeled_200 = pd.read_csv(\"metrics_avg_by_repetition_tesis_3.csv\")\n",
    "#summary_by_relabeled_200.drop\n",
    "display(summary_by_relabeled_200)\n",
    "print(summary_by_relabeled_200.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c434d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Separar columnas que no se deben normalizar\n",
    "# non_normalized_cols = ['subject', 'relabeled', 're_repetition']\n",
    "# columns_to_normalize = [col for col in summary_by_relabeled_200.columns if col not in non_normalized_cols]\n",
    "\n",
    "# # Inicializar el escalador\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# # Aplicar MinMaxScaler solo a las columnas deseadas\n",
    "# normalized_data = scaler.fit_transform(summary_by_relabeled_200[columns_to_normalize])\n",
    "\n",
    "# # Combinar columnas no normalizadas con las normalizadas\n",
    "# pivoted_normalized = pd.concat(\n",
    "#     [summary_by_relabeled_200[non_normalized_cols].reset_index(drop=True),\n",
    "#      pd.DataFrame(normalized_data, columns=columns_to_normalize)],\n",
    "#     axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Channel 1_window_number', 'Channel 2_window_number', 'Channel 3_window_number', 'Channel 4_window_number','Channel 5_window_number', 'Channel 6_window_number', 'Channel 7_window_number', 'Channel 8_window_number','Channel 9_window_number', 'Channel 10_window_number', 'Channel 11_window_number', 'Channel 12_window_number','Channel 1_SSC',\n",
    "       'Channel 10_SSC', 'Channel 2_SSC', 'Channel 3_SSC', 'Channel 4_SSC',\n",
    "       'Channel 5_SSC', 'Channel 6_SSC', 'Channel 7_SSC', 'Channel 8_SSC',\n",
    "       'Channel 9_SSC']\n",
    "summary_by_relabeled_200 = summary_by_relabeled_200.drop(columns=cols_to_drop, errors='ignore')\n",
    "print(summary_by_relabeled_200.columns.tolist())\n",
    "display(summary_by_relabeled_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90887752",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_by_relabeled_200['relabeled'].value_counts(normalize=True))  # proporciones\n",
    "print(summary_by_relabeled_200['relabeled'].value_counts())  # conteo absoluto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a8937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar el dataframe\n",
    "df = summary_by_relabeled_200.copy()\n",
    "\n",
    "# Identificar columnas de métricas (todas excepto 'subject', 'relabeled' y 're_repetition')\n",
    "metric_columns = [col for col in df.columns if col not in ['subject', 'relabeled', 're_repetition']]\n",
    "\n",
    "# Escalar las métricas\n",
    "scaler = MinMaxScaler()\n",
    "df[metric_columns] = scaler.fit_transform(df[metric_columns])\n",
    "\n",
    "# Número de métricas\n",
    "n_metrics = len(metric_columns)\n",
    "\n",
    "# Crear figura para subplots\n",
    "fig, axes = plt.subplots(nrows=(n_metrics + 1) // 2, ncols=2, figsize=(14, 3 * ((n_metrics + 1) // 2)))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Crear boxplots por métrica\n",
    "for i, metric in enumerate(metric_columns):\n",
    "    if i < len(axes):\n",
    "        sns.boxplot(x='relabeled', y=metric, data=df, ax=axes[i], palette='viridis')\n",
    "        axes[i].set_title(f'{metric} por grasp', fontsize=14)\n",
    "        axes[i].set_xlabel('Grasp')\n",
    "        axes[i].set_ylabel('Valor normalizado')\n",
    "        if df['relabeled'].nunique() > 5:\n",
    "            axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Eliminar subplots vacíos\n",
    "for i in range(n_metrics, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Título general y ajuste del espacio\n",
    "plt.suptitle('Comparación de métricas EMG por grasp', fontsize=16)\n",
    "plt.subplots_adjust(top=0.96, hspace=0.6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae1c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_by_relabeled_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e84243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar el dataframe\n",
    "df = summary_by_relabeled_200.copy()\n",
    "\n",
    "# Identificar columnas de métricas (todas excepto 'subject', 'relabeled' y 're_repetition')\n",
    "metric_columns = [col for col in df.columns if col not in ['subject', 'relabeled', 're_repetition']]\n",
    "\n",
    "# Escalar las métricas\n",
    "scaler = MinMaxScaler()\n",
    "df[metric_columns] = scaler.fit_transform(df[metric_columns])\n",
    "\n",
    "# Número de métricas\n",
    "n_metrics = len(metric_columns)\n",
    "\n",
    "# Crear figura para subplots\n",
    "fig, axes = plt.subplots(nrows=(n_metrics + 1) // 2, ncols=2, figsize=(14, 3 * ((n_metrics + 1) // 2)))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Crear violin plots por métrica\n",
    "for i, metric in enumerate(metric_columns):\n",
    "    if i < len(axes):\n",
    "        sns.violinplot(x='relabeled', y=metric, data=df, ax=axes[i], palette='viridis', inner='box')\n",
    "        axes[i].set_title(f'{metric} por grasp', fontsize=14)\n",
    "        axes[i].set_xlabel('Grasp')\n",
    "        axes[i].set_ylabel('Valor normalizado')\n",
    "        if df['relabeled'].nunique() > 5:\n",
    "            axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Eliminar subplots vacíos\n",
    "for i in range(n_metrics, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Título general y ajuste del espacio\n",
    "plt.suptitle('Distribución de métricas EMG por grasp (Violin Plots)', fontsize=16)\n",
    "plt.subplots_adjust(top=0.96, hspace=0.6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc8f551",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4cf54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar el DataFrame\n",
    "df = summary_by_relabeled_200.copy()\n",
    "\n",
    "# Variables predictoras (excluyendo 'subject', 'relabeled', y 're_repetition')\n",
    "X = df.drop(columns=['subject', 'relabeled', 're_repetition'])\n",
    "y = df['relabeled']\n",
    "\n",
    "# Calcular la información mutua\n",
    "mi = mutual_info_classif(X, y, discrete_features=False, random_state=42)\n",
    "\n",
    "# Crear DataFrame de importancia\n",
    "mi_df = pd.DataFrame({'Feature': X.columns, 'Mutual Information': mi})\n",
    "mi_df = mi_df.sort_values(by='Mutual Information', ascending=False)\n",
    "\n",
    "# Visualizar\n",
    "plt.figure(figsize=(10, 50))\n",
    "sns.barplot(x='Mutual Information', y='Feature', data=mi_df, palette='magma')\n",
    "plt.title('Importancia de características EMG según Información Mutua con grasp', fontsize=14)\n",
    "plt.xlabel('Información Mutua')\n",
    "plt.ylabel('Característica')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f53aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar DataFrame original\n",
    "df = summary_by_relabeled_200.copy()\n",
    "\n",
    "# Variables predictoras y target\n",
    "X = df.drop(columns=['subject', 'relabeled', 're_repetition'])\n",
    "y = df['relabeled']\n",
    "\n",
    "# Calcular información mutua\n",
    "mi = mutual_info_classif(X, y, discrete_features=False, random_state=42)\n",
    "\n",
    "# Crear DataFrame con la MI\n",
    "mi_df = pd.DataFrame({'FullName': X.columns, 'Mutual Information': mi})\n",
    "\n",
    "# Separar en \"Channel\" y \"Feature\" \n",
    "mi_df[['Channel', 'Feature']] = mi_df['FullName'].str.extract(r'(Channel \\d+)_(.*)')\n",
    "\n",
    "# Crear tabla tipo matriz (canales como filas, features como columnas)\n",
    "heatmap_df = mi_df.pivot(index='Channel', columns='Feature', values='Mutual Information')\n",
    "\n",
    "# Ordenar los canales numéricamente\n",
    "heatmap_df.index = heatmap_df.index.str.extract(r'Channel (\\d+)')[0].astype(int)\n",
    "heatmap_df = heatmap_df.sort_index()\n",
    "heatmap_df.index = [f'Channel {i}' for i in heatmap_df.index]\n",
    "\n",
    "# Visualizar heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(heatmap_df, cmap='YlOrRd', annot=False, linewidths=0.5, linecolor='black', cbar_kws={'label': 'Mutual Information'})\n",
    "plt.title('Heatmap de Importancia de Características EMG\\n(mutual_info_classif)', fontsize=16)\n",
    "plt.xlabel('Característica')\n",
    "plt.ylabel('Canal EMG')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185912cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar el DataFrame\n",
    "df = summary_by_relabeled_200.copy()\n",
    "\n",
    "# Variables predictoras (excluyendo 'subject', 'relabeled' y 're_repetition')\n",
    "X = df.drop(columns=['subject', 'relabeled', 're_repetition'])\n",
    "y = df['relabeled']\n",
    "\n",
    "# Entrenar árbol de decisión\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X, y)\n",
    "\n",
    "# Obtener importancias\n",
    "importances = tree_clf.feature_importances_\n",
    "features_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Visualizar\n",
    "plt.figure(figsize=(10, 50))\n",
    "sns.barplot(x='Importance', y='Feature', data=features_df, palette='crest')\n",
    "plt.title('Importancia de características EMG según Árbol de Decisión', fontsize=14)\n",
    "plt.xlabel('Importancia')\n",
    "plt.ylabel('Característica')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f3ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar DataFrame\n",
    "df = summary_by_relabeled_200.copy()\n",
    "\n",
    "# Variables predictoras y etiquetas\n",
    "X = df.drop(columns=['subject', 'relabeled', 're_repetition'])\n",
    "y = df['relabeled']\n",
    "\n",
    "# Entrenar árbol de decisión\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X, y)\n",
    "\n",
    "# Obtener importancias\n",
    "importances = tree_clf.feature_importances_\n",
    "\n",
    "# Crear DataFrame con nombres completos y valores de importancia\n",
    "importance_df = pd.DataFrame({'FullName': X.columns, 'Importance': importances})\n",
    "\n",
    "# Extraer nombre del canal y característica (ej: 'Channel 1', 'RMS')\n",
    "importance_df[['Channel', 'Feature']] = importance_df['FullName'].str.extract(r'(Channel \\d+)_(.*)')\n",
    "\n",
    "# Pivotear para crear matriz (filas=canales, columnas=features)\n",
    "heatmap_df = importance_df.pivot(index='Channel', columns='Feature', values='Importance')\n",
    "\n",
    "# Ordenar canales numéricamente\n",
    "heatmap_df.index = heatmap_df.index.str.extract(r'Channel (\\d+)')[0].astype(int)\n",
    "heatmap_df = heatmap_df.sort_index()\n",
    "heatmap_df.index = [f'Channel {i}' for i in heatmap_df.index]\n",
    "\n",
    "# Visualización tipo heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(heatmap_df, cmap='crest', annot=False, linewidths=0.5, linecolor='black', cbar_kws={'label': 'Feature Importance'})\n",
    "plt.title('Heatmap de Importancia de Características EMG\\n(Árbol de Decisión)', fontsize=16)\n",
    "plt.xlabel('Característica')\n",
    "plt.ylabel('Canal EMG')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268801da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold config\n",
    "kf = KFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# 1. Seleccionar métricas (excluir ZC, ZC_STD, Kurt, Kurt_STD)\n",
    "excluded = ['ZC', 'ZC_STD', 'Kurt', 'Kurt_STD']\n",
    "features = [c for c in summary_by_relabeled_200.columns \n",
    "            if c not in ['subject', 'relabeled', 'stimulus','re_repetition'] \n",
    "            and not any(exc.upper() in c.upper() for exc in excluded)]\n",
    "\n",
    "X = summary_by_relabeled_200[features].values\n",
    "y = summary_by_relabeled_200['relabeled'].values\n",
    "\n",
    "# 2. Escalado\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 3. Determinar número óptimo de componentes usando varianza explicada acumulada\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_scaled)\n",
    "explained_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "# Graficar varianza explicada\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o')\n",
    "plt.xlabel('Número de componentes principales')\n",
    "plt.ylabel('Varianza explicada acumulada')\n",
    "plt.title('Selección del número óptimo de componentes en PCA')\n",
    "plt.grid(True)\n",
    "plt.axhline(0.90, color='r', linestyle='--', label='90% de varianza explicada')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Aplicar PCA con un número fijo de componentes (puedes ajustar este número según la curva)\n",
    "n_components = np.argmax(explained_variance >= 0.90) + 1  # Componentes que explican >=90% varianza\n",
    "print(f\"✅ Número de componentes seleccionados: {n_components}\")\n",
    "\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 5. Carga de cada feature en cada componente\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    index=features,\n",
    "    columns=[f'PC{i+1}' for i in range(n_components)]\n",
    ")\n",
    "\n",
    "# Mostrar los features más influyentes en PC1 y PC2\n",
    "print(\"Top 5 features por carga absoluta en PC1:\")\n",
    "display(loadings['PC1'].abs().sort_values(ascending=False).head(5))\n",
    "\n",
    "if n_components >= 2:\n",
    "    print(\"Top 5 features por carga absoluta en PC2:\")\n",
    "    display(loadings['PC2'].abs().sort_values(ascending=False).head(5))\n",
    "\n",
    "# 6. Visualización PCA 2D si hay al menos 2 componentes\n",
    "if n_components >= 2:\n",
    "    pca_df = pd.DataFrame(X_pca[:, :2], columns=['PC1', 'PC2'])\n",
    "    pca_df['relabeled'] = y\n",
    "    pca_df['subject'] = summary_by_relabeled_200['subject'].values\n",
    "\n",
    "    fig = px.scatter(\n",
    "        pca_df, x='PC1', y='PC2',\n",
    "        color='relabeled', symbol='subject',\n",
    "        title='Proyección PCA (PC1 vs PC2)',\n",
    "        hover_data=['subject', 'relabeled']\n",
    "    )\n",
    "\n",
    "    # ✅ Leyenda mejor distribuida y desplazable\n",
    "    fig.update_layout(\n",
    "    width=1000,\n",
    "    height=950,\n",
    "    legend=dict(\n",
    "        orientation='h',\n",
    "        yanchor='bottom',\n",
    "        y=-0.1,  # Debajo del gráfico\n",
    "        xanchor='center',\n",
    "        x=0.5,\n",
    "        font=dict(size=15)\n",
    "    )\n",
    ")\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf49593",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings.abs().sum(axis=1).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico para PC1\n",
    "pc1_abs_loadings = loadings['PC1'].abs().sort_values(ascending=False)\n",
    "fig_pc1 = px.bar(\n",
    "    pc1_abs_loadings,  # Top 10 features\n",
    "    x=pc1_abs_loadings.index,\n",
    "    y=pc1_abs_loadings.values,\n",
    "    labels={'x': 'Feature', 'y': 'Carga absoluta'},\n",
    "    title='Cargas absolutas en PC1'\n",
    ")\n",
    "fig_pc1.update_layout(xaxis_tickangle=-45)\n",
    "fig_pc1.show()\n",
    "\n",
    "# Gráfico para PC2\n",
    "pc2_abs_loadings = loadings['PC2'].abs().sort_values(ascending=False)\n",
    "fig_pc2 = px.bar(\n",
    "    pc2_abs_loadings,\n",
    "    x=pc2_abs_loadings.index,\n",
    "    y=pc2_abs_loadings.values,\n",
    "    labels={'x': 'Feature', 'y': 'Carga absoluta'},\n",
    "    title='Cargas absolutas en PC2'\n",
    ")\n",
    "fig_pc2.update_layout(xaxis_tickangle=-45)\n",
    "fig_pc2.show()\n",
    "\n",
    "pc3_abs_loadings = loadings['PC3'].abs().sort_values(ascending=False)\n",
    "fig_pc3 = px.bar(\n",
    "    pc3_abs_loadings,\n",
    "    x=pc3_abs_loadings.index,\n",
    "    y=pc3_abs_loadings.values,\n",
    "    labels={'x': 'Feature', 'y': 'Carga absoluta'},\n",
    "    title='Cargas absolutas en PC3'\n",
    ")\n",
    "\n",
    "fig_pc3.update_layout(xaxis_tickangle=-45)\n",
    "fig_pc3.show()\n",
    "\n",
    "pc4_abs_loadings = loadings['PC4'].abs().sort_values(ascending=False)\n",
    "fig_pc4 = px.bar(\n",
    "    pc4_abs_loadings,\n",
    "    x=pc4_abs_loadings.index,\n",
    "    y=pc4_abs_loadings.values,\n",
    "    labels={'x': 'Feature', 'y': 'Carga absoluta'},\n",
    "    title='Cargas absolutas en PC4'\n",
    ")\n",
    "\n",
    "fig_pc4.update_layout(xaxis_tickangle=-45)\n",
    "fig_pc4.show()\n",
    "\n",
    "pc5_abs_loadings = loadings['PC5'].abs().sort_values(ascending=False)\n",
    "fig_pc5 = px.bar(\n",
    "    pc5_abs_loadings,\n",
    "    x=pc5_abs_loadings.index,\n",
    "    y=pc5_abs_loadings.values,\n",
    "    labels={'x': 'Feature', 'y': 'Carga absoluta'},\n",
    "    title='Cargas absolutas en PC5'\n",
    ")\n",
    "\n",
    "fig_pc5.update_layout(xaxis_tickangle=-45)\n",
    "fig_pc5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced2b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de importancia global por feature: suma ponderada de cargas absolutas por varianza explicada\n",
    "explained_var = pca.explained_variance_ratio_[:n_components]  # vector (PC1, PC2, ..., PCn)\n",
    "\n",
    "# Multiplicar cada carga absoluta por la varianza explicada\n",
    "weighted_loadings = loadings.abs().values * explained_var  # matriz (features x PCs)\n",
    "\n",
    "# Sumar por filas para obtener importancia total por feature\n",
    "global_importance = weighted_loadings.sum(axis=1)\n",
    "\n",
    "# Crear DataFrame ordenado\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': loadings.index,\n",
    "    'Importance': global_importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Mostrar top 10\n",
    "print(\"Top 10 features por importancia global (PCA):\")\n",
    "display(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899731ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Separar canal y métrica con expresión regular\n",
    "importance_df[['Channel', 'Feature']] = (\n",
    "    importance_df['Feature']\n",
    "    .str.extract(r'^(Channel \\d+)[ _-]*(.+)$')   # admite separador _, espacio o -\n",
    ")\n",
    "\n",
    "# 2. Eliminar filas donde no se haya podido extraer canal o feature\n",
    "bad_rows = importance_df[importance_df['Channel'].isna() | importance_df['Feature'].isna()]\n",
    "\n",
    "\n",
    "importance_df = importance_df.dropna(subset=['Channel', 'Feature'])\n",
    "\n",
    "# 3. Pivotar a matriz canales × features\n",
    "heatmap_df = importance_df.pivot(index='Channel',\n",
    "                                 columns='Feature',\n",
    "                                 values='Importance')\n",
    "\n",
    "# 4. Ordenar los canales por número \n",
    "heatmap_df = (\n",
    "    heatmap_df\n",
    "    .assign(_n = heatmap_df.index.str.extract(r'(\\d+)').astype(int))\n",
    "    .sort_values('_n')\n",
    "    .drop(columns='_n')\n",
    ")\n",
    "\n",
    "# 5. Dibujar heatmap\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(\n",
    "    heatmap_df,\n",
    "    cmap='viridis',\n",
    "    linewidths=.5,\n",
    "    linecolor='black',\n",
    "    cbar_kws={'label': 'Importancia global (PCA)'}\n",
    ")\n",
    "plt.title('Importancia de características EMG – PCA ponderada', fontsize=16)\n",
    "plt.xlabel('Métrica')\n",
    "plt.ylabel('Canal')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_var = pca.explained_variance_ratio_\n",
    "for i, var in enumerate(explained_var, start=1):\n",
    "    print(f'PC{i}: {var:.4f} varianza explicada ({var*100:.2f}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b1bd72",
   "metadata": {},
   "source": [
    "## Clasificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb8157f",
   "metadata": {},
   "source": [
    "- PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c14b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "scores = cross_val_score(clf, X_pca, y, cv=kf, scoring='accuracy')\n",
    "print(f\"\\nAccuracy 5-fold CV en espacio PCA ({n_components} componentes): {scores.mean():.3f} ± {scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf742ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_scores = cross_val_score(rf_model, X_pca, y, cv=kf)\n",
    "\n",
    "print(f\"🎯 Accuracy 5-fold CV con Random Forest: {rf_scores.mean():.3f} ± {rf_scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908abb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo KNN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Evaluación utilizando validación cruzada\n",
    "knn_scores = cross_val_score(knn_model, X_pca, y, cv=kf)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"🎯 Accuracy 5-fold CV con KNN: {knn_scores.mean():.3f} ± {knn_scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a433426",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svm_scores = cross_val_score(svm_model, X_pca, y, cv=kf)\n",
    "\n",
    "print(f\"🎯 Accuracy 5-fold CV con SVM (RBF kernel): {svm_scores.mean():.3f} ± {svm_scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar etiquetas\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Clasificador XGBoost\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Validación cruzada 5-fold\n",
    "xgb_scores = cross_val_score(xgb_clf, X_pca, y_encoded, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"🎯 Accuracy 5-fold CV con XGBoost: {xgb_scores.mean():.3f} ± {xgb_scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6820b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Red neuronal\n",
    "mlp_clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),  # una capa oculta con 100 neuronas\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Validación cruzada 5-fold\n",
    "mlp_scores = cross_val_score(mlp_clf, X_pca, y_encoded, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"🧠 Accuracy 5-fold CV con MLPClassifier: {mlp_scores.mean():.3f} ± {mlp_scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el clasificador con los parámetros del modelo de PyCaret\n",
    "model = LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    class_weight=None,\n",
    "    colsample_bytree=1.0,\n",
    "    importance_type='split',\n",
    "    learning_rate=0.1,\n",
    "    max_depth=-1,\n",
    "    min_child_samples=20,\n",
    "    min_child_weight=0.001,\n",
    "    min_split_gain=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    subsample=1.0,\n",
    "    subsample_for_bin=200000,\n",
    "    subsample_freq=0\n",
    ")\n",
    "\n",
    "# Usar el mismo esquema de validación cruzada que PyCaret\n",
    "kf = KFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluación\n",
    "scores = cross_val_score(model, X_pca, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"LGBMClassifier Accuracy 7-fold CV: {scores.mean():.3f} ± {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b7307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el entorno de pycaret\n",
    "data = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(X_pca.shape[1])])\n",
    "data['relabeled'] = y\n",
    "\n",
    "# Iniciar la configuración de PyCaret\n",
    "clf = setup(\n",
    "    data=data, \n",
    "    target='relabeled', \n",
    "    session_id=42, \n",
    "    fold=7,  \n",
    "    normalize=False, \n",
    "    feature_selection=True, \n",
    "    pca=False,\n",
    "    fold_shuffle=True, \n",
    "    verbose=True   \n",
    ")\n",
    "\n",
    "best_model = compare_models(sort='Accuracy')\n",
    "\n",
    "\n",
    "if best_model is not None:\n",
    "    tuned_model = tune_model(best_model, optimize='Accuracy', n_iter=50)\n",
    "\n",
    "    # Finalizar \n",
    "    final_model = finalize_model(tuned_model)\n",
    "\n",
    "    # Evaluar el modelo final\n",
    "    evaluate_model(final_model)\n",
    "else:\n",
    "    print(\"No se encontró un modelo válido para tunear.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f3c5c3",
   "metadata": {},
   "source": [
    "- Without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4374a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "\n",
    "# Asegurar que la columna target sea tipo string\n",
    "summary_by_relabeled_200['relabeled'] = summary_by_relabeled_200['relabeled'].astype(str)\n",
    "\n",
    "# Configurar PyCaret\n",
    "clf = setup(\n",
    "    data=summary_by_relabeled_200,\n",
    "    target='relabeled',\n",
    "    session_id=42,\n",
    "    fold=7,\n",
    "    fold_shuffle=True,\n",
    "    normalize=True,\n",
    "    feature_selection=False,\n",
    "    pca=False,\n",
    "    data_split_stratify=True,\n",
    "    #silent=True,\n",
    "    use_gpu=False  # cambia a True si tienes GPU y quieres usarla\n",
    ")\n",
    "\n",
    "# Comparar modelos incluyendo el MLP\n",
    "models_to_compare = compare_models(\n",
    "    sort='Accuracy',\n",
    "    include=['mlp', 'lr', 'rf', 'xgboost', 'lightgbm', 'dt', 'knn', 'et', 'svm']  # puedes agregar o quitar modelos aquí\n",
    ")\n",
    "\n",
    "# Seleccionar el mejor modelo\n",
    "if models_to_compare is not None:\n",
    "    best_model = models_to_compare\n",
    "    tuned_model = tune_model(best_model, optimize='Accuracy', n_iter=80)\n",
    "    final_model = finalize_model(tuned_model)\n",
    "    evaluate_model(final_model)\n",
    "else:\n",
    "    print(\"No se encontró un modelo válido para tunear.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0aa8bd",
   "metadata": {},
   "source": [
    "## Independent Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7842154a",
   "metadata": {},
   "source": [
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adffd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, accuracy_score, f1_score, recall_score, precision_score,\n",
    "    cohen_kappa_score, matthews_corrcoef, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Definir X e y\n",
    "X = summary_by_relabeled_200.drop(columns=['relabeled', 'subject', 're_repetition'])\n",
    "y = summary_by_relabeled_200['relabeled'].astype(str)\n",
    "\n",
    "# 2. Pipeline\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs'\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Validación cruzada\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# 4. Métricas personalizadas\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'kappa': make_scorer(cohen_kappa_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "}\n",
    "\n",
    "# 5. Evaluación de métricas\n",
    "results = cross_validate(\n",
    "    model, X, y, cv=cv, scoring=scoring, return_train_score=False\n",
    ")\n",
    "\n",
    "print(\"✅ Métricas promedio en validación cruzada (7 folds):\")\n",
    "for metric, values in results.items():\n",
    "    if \"test\" in metric:\n",
    "        print(f\"{metric.replace('test_', '').upper():<15}: {np.mean(values):.4f}\")\n",
    "\n",
    "# 6. Matrices de confusión por fold y global\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    all_y_true.extend(y_val)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "    # Matriz por fold\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=np.unique(y))\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "    plt.title(f'Matriz de confusión - Fold {fold}')\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Verdadero\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Matriz total\n",
    "cm_total = confusion_matrix(all_y_true, all_y_pred, labels=np.unique(y))\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm_total, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Matriz de confusión global (todos los folds)')\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Verdadero\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Curva de aprendizaje (accuracy vs. tamaño del set de entrenamiento)\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model, X, y,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Calcular media y desviación estándar\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Graficar curva de aprendizaje\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Accuracy Entrenamiento')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean, 'o-', color='green', label='Accuracy Validación')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2, color='green')\n",
    "\n",
    "plt.title('Curva de Aprendizaje - Logistic Regression')\n",
    "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092bb00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, recall_score, precision_score,\n",
    "    cohen_kappa_score, matthews_corrcoef, confusion_matrix, log_loss\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Preparar datos\n",
    "X = summary_by_relabeled_200.drop(columns=['relabeled', 'subject', 're_repetition'])\n",
    "y = summary_by_relabeled_200['relabeled'].astype(str)\n",
    "classes = np.unique(y)\n",
    "\n",
    "# 2. Configuración\n",
    "max_epochs = 500\n",
    "patience = 3\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# Almacenar resultados globales\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "# Curvas por fold\n",
    "all_train_acc = []\n",
    "all_val_acc = []\n",
    "\n",
    "# 3. Cross-validation manual con early stopping\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    print(f\"\\n🔁 Fold {fold}\")\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Escalar\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Modelo SGD\n",
    "    model = SGDClassifier(\n",
    "        loss='log_loss',  # equivalente a regresión logística\n",
    "        max_iter=1,       # solo una iteración por .fit\n",
    "        tol=None,\n",
    "        learning_rate='optimal',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    patience_counter = 0\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.partial_fit(X_train_scaled, y_train, classes=classes)\n",
    "\n",
    "        # Accuracy\n",
    "        y_train_pred = model.predict(X_train_scaled)\n",
    "        y_val_pred = model.predict(X_val_scaled)\n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        val_acc = accuracy_score(y_val, y_val_pred)\n",
    "        train_acc_history.append(train_acc)\n",
    "        val_acc_history.append(val_acc)\n",
    "\n",
    "        # Early stopping basado en validation loss\n",
    "        val_loss = log_loss(y_val, model.predict_proba(X_val_scaled), labels=classes)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"⏹️ Early stopping en epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    # Guardar resultados globales\n",
    "    y_pred_fold = best_model.predict(X_val_scaled)\n",
    "    all_y_true.extend(y_val)\n",
    "    all_y_pred.extend(y_pred_fold)\n",
    "\n",
    "    # Matriz por fold\n",
    "    cm = confusion_matrix(y_val, y_pred_fold, labels=classes)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(f'Matriz de confusión - Fold {fold}')\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Verdadero\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Guardar curvas\n",
    "    all_train_acc.append(train_acc_history)\n",
    "    all_val_acc.append(val_acc_history)\n",
    "\n",
    "# 4. Matriz total\n",
    "cm_total = confusion_matrix(all_y_true, all_y_pred, labels=classes)\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm_total, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=classes, yticklabels=classes)\n",
    "plt.title('Matriz de confusión global (todos los folds)')\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Verdadero\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Curva de accuracy vs. epoch (promediada)\n",
    "max_len = max(len(acc) for acc in all_val_acc)\n",
    "train_acc_array = np.array([np.pad(acc, (0, max_len - len(acc)), constant_values=np.nan) for acc in all_train_acc])\n",
    "val_acc_array = np.array([np.pad(acc, (0, max_len - len(acc)), constant_values=np.nan) for acc in all_val_acc])\n",
    "\n",
    "mean_train = np.nanmean(train_acc_array, axis=0)\n",
    "mean_val = np.nanmean(val_acc_array, axis=0)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, max_len + 1), mean_train, label='Accuracy Entrenamiento', color='blue')\n",
    "plt.plot(range(1, max_len + 1), mean_val, label='Accuracy Validación', color='green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Curva de Accuracy vs. Epoch (con early stopping)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Métricas globales (macro)\n",
    "accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "f1 = f1_score(all_y_true, all_y_pred, average='macro')\n",
    "recall = recall_score(all_y_true, all_y_pred, average='macro')\n",
    "precision = precision_score(all_y_true, all_y_pred, average='macro')\n",
    "kappa = cohen_kappa_score(all_y_true, all_y_pred)\n",
    "mcc = matthews_corrcoef(all_y_true, all_y_pred)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n📊 Métricas globales (macro):\")\n",
    "print(f\"Accuracy          : {accuracy:.4f}\")\n",
    "print(f\"F1 Score (macro)  : {f1:.4f}\")\n",
    "print(f\"Recall (macro)    : {recall:.4f}\")\n",
    "print(f\"Precision (macro) : {precision:.4f}\")\n",
    "print(f\"Cohen's Kappa     : {kappa:.4f}\")\n",
    "print(f\"Matthews CorrCoef : {mcc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6128c504",
   "metadata": {},
   "source": [
    "- Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01adc499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, cohen_kappa_score, matthews_corrcoef, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Definir X e y\n",
    "X = summary_by_relabeled_200.drop(columns=['relabeled', 'subject', 're_repetition'])\n",
    "y = summary_by_relabeled_200['relabeled'].astype(str)\n",
    "\n",
    "# 2. Crear pipeline\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    ExtraTreesClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "\n",
    "# 3. Validación cruzada\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# 4. Definir métricas\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'kappa': make_scorer(cohen_kappa_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "}\n",
    "\n",
    "# 5. Evaluación por validación cruzada\n",
    "results = cross_validate(\n",
    "    model, X, y, cv=cv, scoring=scoring, return_train_score=False\n",
    ")\n",
    "\n",
    "print(\"✅ ExtraTreesClassifier - Métricas promedio en validación cruzada (7 folds):\")\n",
    "for metric, values in results.items():\n",
    "    if \"test\" in metric:\n",
    "        print(f\"{metric.replace('test_', '').upper():<15}: {np.mean(values):.4f}\")\n",
    "\n",
    "# 6. Matrices de confusión por fold\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    all_y_true.extend(y_val)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=np.unique(y))\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "    plt.title(f'Matriz de confusión - Fold {fold}')\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Verdadero\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 7. Matriz de confusión total\n",
    "cm_total = confusion_matrix(all_y_true, all_y_pred, labels=np.unique(y))\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm_total, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Matriz de confusión global (todos los folds)')\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Verdadero\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. Curva de aprendizaje: accuracy vs número de muestras (tamaño del set de entrenamiento)\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model, X, y, cv=cv, scoring='accuracy',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=-1, shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "# Calcular promedio y desviación\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Graficar la curva de aprendizaje\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', label=\"Accuracy Entrenamiento\", color='blue')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean, 'o-', label=\"Accuracy Validación\", color='green')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2, color='green')\n",
    "\n",
    "plt.title('Curva de Aprendizaje - ExtraTreesClassifier')\n",
    "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d98da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, cohen_kappa_score, matthews_corrcoef, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Definir X e y\n",
    "X = summary_by_relabeled_200.drop(columns=['relabeled', 'subject', 're_repetition'])\n",
    "y = summary_by_relabeled_200['relabeled'].astype(str)\n",
    "\n",
    "# 2. Crear pipeline\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    ExtraTreesClassifier(min_samples_split=5, min_samples_leaf=3)\n",
    "\n",
    ")\n",
    "\n",
    "# 3. Validación cruzada\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# 4. Definir métricas\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'kappa': make_scorer(cohen_kappa_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "}\n",
    "\n",
    "# 5. Evaluación por validación cruzada\n",
    "results = cross_validate(\n",
    "    model, X, y, cv=cv, scoring=scoring, return_train_score=False\n",
    ")\n",
    "\n",
    "print(\"✅ ExtraTreesClassifier - Métricas promedio en validación cruzada (7 folds):\")\n",
    "for metric, values in results.items():\n",
    "    if \"test\" in metric:\n",
    "        print(f\"{metric.replace('test_', '').upper():<15}: {np.mean(values):.4f}\")\n",
    "\n",
    "# 6. Matrices de confusión por fold\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    all_y_true.extend(y_val)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=np.unique(y))\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "    plt.title(f'Matriz de confusión - Fold {fold}')\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Verdadero\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 7. Matriz de confusión total\n",
    "cm_total = confusion_matrix(all_y_true, all_y_pred, labels=np.unique(y))\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm_total, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Matriz de confusión global (todos los folds)')\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Verdadero\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. Curva de aprendizaje: accuracy vs número de muestras (tamaño del set de entrenamiento)\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model, X, y, cv=cv, scoring='accuracy',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=-1, shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "# Calcular promedio y desviación\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Graficar la curva de aprendizaje\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', label=\"Accuracy Entrenamiento\", color='blue')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean, 'o-', label=\"Accuracy Validación\", color='green')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2, color='green')\n",
    "\n",
    "plt.title('Curva de Aprendizaje - ExtraTreesClassifier')\n",
    "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ef89a1",
   "metadata": {},
   "source": [
    "- SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f7169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, accuracy_score, f1_score, recall_score, precision_score,\n",
    "    cohen_kappa_score, matthews_corrcoef, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Definir X e y\n",
    "X = summary_by_relabeled_200.drop(columns=['relabeled', 'subject', 're_repetition'])\n",
    "y = summary_by_relabeled_200['relabeled'].astype(str)\n",
    "\n",
    "# 2. Pipeline\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(kernel='rbf', probability=True, random_state=42)\n",
    ")\n",
    "\n",
    "# 3. Validación cruzada\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# 4. Métricas personalizadas\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'kappa': make_scorer(cohen_kappa_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "}\n",
    "\n",
    "# 5. Evaluación de métricas\n",
    "results = cross_validate(\n",
    "    model, X, y, cv=cv, scoring=scoring, return_train_score=False\n",
    ")\n",
    "\n",
    "print(\"✅ SVM - Métricas promedio en validación cruzada (7 folds):\")\n",
    "for metric, values in results.items():\n",
    "    if \"test\" in metric:\n",
    "        print(f\"{metric.replace('test_', '').upper():<15}: {np.mean(values):.4f}\")\n",
    "\n",
    "# 6. Matrices de confusión por fold y global\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    all_y_true.extend(y_val)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "    # Matriz por fold\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=np.unique(y))\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "    plt.title(f'Matriz de confusión - Fold {fold}')\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Verdadero\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Matriz total\n",
    "cm_total = confusion_matrix(all_y_true, all_y_pred, labels=np.unique(y))\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm_total, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Matriz de confusión global (todos los folds)')\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Verdadero\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Curva de aprendizaje\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    estimator=model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "val_scores_mean = np.mean(val_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', label='Entrenamiento', color='blue')\n",
    "plt.plot(train_sizes, val_scores_mean, 's--', label='Validación', color='green')\n",
    "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Curva de aprendizaje - SVM (kernel RBF)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e287a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, accuracy_score, f1_score, recall_score, precision_score,\n",
    "    cohen_kappa_score, matthews_corrcoef, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Definir X e y\n",
    "X = summary_by_relabeled_200.drop(columns=['relabeled', 'subject', 're_repetition'])\n",
    "y = summary_by_relabeled_200['relabeled'].astype(str)\n",
    "\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(kernel='rbf', C=0.5, gamma=0.01, probability=True, random_state=42)\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Validación cruzada\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# 4. Métricas personalizadas\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'kappa': make_scorer(cohen_kappa_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "}\n",
    "\n",
    "# 5. Evaluación de métricas\n",
    "results = cross_validate(\n",
    "    model, X, y, cv=cv, scoring=scoring, return_train_score=False\n",
    ")\n",
    "\n",
    "print(\"✅ SVM - Métricas promedio en validación cruzada (7 folds):\")\n",
    "for metric, values in results.items():\n",
    "    if \"test\" in metric:\n",
    "        print(f\"{metric.replace('test_', '').upper():<15}: {np.mean(values):.4f}\")\n",
    "\n",
    "# 6. Matrices de confusión por fold y global\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    all_y_true.extend(y_val)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "    # Matriz por fold\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=np.unique(y))\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "    plt.title(f'Matriz de confusión - Fold {fold}')\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Verdadero\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Matriz total\n",
    "cm_total = confusion_matrix(all_y_true, all_y_pred, labels=np.unique(y))\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm_total, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Matriz de confusión global (todos los folds)')\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Verdadero\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Curva de aprendizaje\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    estimator=model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "val_scores_mean = np.mean(val_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', label='Entrenamiento', color='blue')\n",
    "plt.plot(train_sizes, val_scores_mean, 's--', label='Validación', color='green')\n",
    "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Curva de aprendizaje - SVM (kernel RBF)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8222795",
   "metadata": {},
   "source": [
    "- KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, accuracy_score, f1_score, recall_score, precision_score,\n",
    "    cohen_kappa_score, matthews_corrcoef, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Definir X e y\n",
    "X = summary_by_relabeled_200.drop(columns=['relabeled', 'subject', 're_repetition'])\n",
    "y = summary_by_relabeled_200['relabeled'].astype(str)\n",
    "\n",
    "# 2. Pipeline\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KNeighborsClassifier(n_neighbors=5)\n",
    ")\n",
    "\n",
    "# 3. Validación cruzada\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# 4. Métricas personalizadas\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'kappa': make_scorer(cohen_kappa_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "}\n",
    "\n",
    "# 5. Evaluación de métricas\n",
    "results = cross_validate(\n",
    "    model, X, y, cv=cv, scoring=scoring, return_train_score=False\n",
    ")\n",
    "\n",
    "print(\"✅ KNN - Métricas promedio en validación cruzada (7 folds):\")\n",
    "for metric, values in results.items():\n",
    "    if \"test\" in metric:\n",
    "        print(f\"{metric.replace('test_', '').upper():<15}: {np.mean(values):.4f}\")\n",
    "\n",
    "# 6. Matrices de confusión por fold y global\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    all_y_true.extend(y_val)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "    # Matriz por fold\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=np.unique(y))\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "    plt.title(f'Matriz de confusión - Fold {fold}')\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Verdadero\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Matriz total\n",
    "cm_total = confusion_matrix(all_y_true, all_y_pred, labels=np.unique(y))\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm_total, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Matriz de confusión global (todos los folds)')\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Verdadero\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Curva de aprendizaje (accuracy vs training size)\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model, X, y, cv=cv, scoring='accuracy',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Precisión en entrenamiento')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean, 'o-', color='green', label='Precisión en validación')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2, color='green')\n",
    "\n",
    "plt.title('Curva de aprendizaje - KNN')\n",
    "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61285016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, accuracy_score, f1_score, recall_score, precision_score,\n",
    "    cohen_kappa_score, matthews_corrcoef, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Definir X e y\n",
    "X = summary_by_relabeled_200.drop(columns=['relabeled', 'subject', 're_repetition'])\n",
    "y = summary_by_relabeled_200['relabeled'].astype(str)\n",
    "\n",
    "# 2. Pipeline\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KNeighborsClassifier(n_neighbors=3)\n",
    ")\n",
    "\n",
    "# 3. Validación cruzada\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# 4. Métricas personalizadas\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'kappa': make_scorer(cohen_kappa_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "}\n",
    "\n",
    "# 5. Evaluación de métricas\n",
    "results = cross_validate(\n",
    "    model, X, y, cv=cv, scoring=scoring, return_train_score=False\n",
    ")\n",
    "\n",
    "print(\"✅ KNN - Métricas promedio en validación cruzada (7 folds):\")\n",
    "for metric, values in results.items():\n",
    "    if \"test\" in metric:\n",
    "        print(f\"{metric.replace('test_', '').upper():<15}: {np.mean(values):.4f}\")\n",
    "\n",
    "# 6. Matrices de confusión por fold y global\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    all_y_true.extend(y_val)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "    # Matriz por fold\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=np.unique(y))\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "    plt.title(f'Matriz de confusión - Fold {fold}')\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Verdadero\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Matriz total\n",
    "cm_total = confusion_matrix(all_y_true, all_y_pred, labels=np.unique(y))\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm_total, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Matriz de confusión global (todos los folds)')\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Verdadero\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Curva de aprendizaje (accuracy vs training size)\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model, X, y, cv=cv, scoring='accuracy',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Precisión en entrenamiento')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean, 'o-', color='green', label='Precisión en validación')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2, color='green')\n",
    "\n",
    "plt.title('Curva de aprendizaje - KNN')\n",
    "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e3a84",
   "metadata": {},
   "source": [
    "- RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, cohen_kappa_score, matthews_corrcoef,\n",
    "    confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Definir X e y\n",
    "X = summary_by_relabeled_200.drop(columns=['relabeled', 'subject', 're_repetition'])\n",
    "y = summary_by_relabeled_200['relabeled'].astype(str)\n",
    "\n",
    "# 2. Pipeline con MLPClassifier\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    ")\n",
    "\n",
    "# 3. Validación cruzada\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# 4. Métricas personalizadas\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'kappa': make_scorer(cohen_kappa_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "}\n",
    "\n",
    "# 5. Evaluación de métricas\n",
    "results = cross_validate(\n",
    "    model, X, y, cv=cv, scoring=scoring, return_train_score=False\n",
    ")\n",
    "\n",
    "print(\"✅ RNA (MLPClassifier) - Métricas promedio en validación cruzada (7 folds):\")\n",
    "for metric, values in results.items():\n",
    "    if \"test\" in metric:\n",
    "        print(f\"{metric.replace('test_', '').upper():<15}: {np.mean(values):.4f}\")\n",
    "\n",
    "# 6. Matrices de confusión por fold y global\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    all_y_true.extend(y_val)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "    # Matriz de confusión por fold\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=np.unique(y))\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "    plt.title(f'Matriz de confusión - Fold {fold}')\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Verdadero\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Matriz de confusión total\n",
    "cm_total = confusion_matrix(all_y_true, all_y_pred, labels=np.unique(y))\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm_total, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Matriz de confusión global (todos los folds)')\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Verdadero\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Curva de aprendizaje (accuracy vs training size)\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model, X, y, cv=cv, scoring='accuracy',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Precisión en entrenamiento')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean, 'o-', color='green', label='Precisión en validación')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2, color='green')\n",
    "\n",
    "plt.title('Curva de aprendizaje - MLPClassifier')\n",
    "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ed18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, cohen_kappa_score, matthews_corrcoef,\n",
    "    confusion_matrix, accuracy_score\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Definir X e y\n",
    "X = summary_by_relabeled_200.drop(columns=['relabeled', 'subject', 're_repetition'])\n",
    "y = summary_by_relabeled_200['relabeled'].astype(str)\n",
    "\n",
    "# 2. Validación cruzada\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# 3. Matrices de confusión y curvas por fold\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n",
    "    print(f\"\\n🔁 Fold {fold}\")\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # 4. Modelo con early stopping\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(100,),\n",
    "        max_iter=500,\n",
    "        early_stopping=False,\n",
    "        validation_fraction=0.1,\n",
    "        n_iter_no_change=3,\n",
    "        random_state=42\n",
    "    )\n",
    "    model = make_pipeline(StandardScaler(), mlp)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 5. Predicción\n",
    "    y_pred = model.predict(X_val)\n",
    "    all_y_true.extend(y_val)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "    # 6. Matriz de confusión por fold\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=np.unique(y))\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "    plt.title(f'Matriz de confusión - Fold {fold}')\n",
    "    plt.xlabel(\"Predicho\")\n",
    "    plt.ylabel(\"Verdadero\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "# Matriz de confusión total\n",
    "cm_total = confusion_matrix(all_y_true, all_y_pred, labels=np.unique(y))\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm_total, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Matriz de confusión global (todos los folds)')\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Verdadero\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Curva de aprendizaje (accuracy vs training size)\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model, X, y, cv=cv, scoring='accuracy',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Precisión en entrenamiento')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean, 'o-', color='green', label='Precisión en validación')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2, color='green')\n",
    "\n",
    "plt.title('Curva de aprendizaje - MLPClassifier')\n",
    "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.show()\n",
    "# 6. Métricas globales (macro)\n",
    "accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "f1 = f1_score(all_y_true, all_y_pred, average='macro')\n",
    "recall = recall_score(all_y_true, all_y_pred, average='macro')\n",
    "precision = precision_score(all_y_true, all_y_pred, average='macro')\n",
    "kappa = cohen_kappa_score(all_y_true, all_y_pred)\n",
    "mcc = matthews_corrcoef(all_y_true, all_y_pred)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n📊 Métricas globales (macro):\")\n",
    "print(f\"Accuracy          : {accuracy:.4f}\")\n",
    "print(f\"F1 Score (macro)  : {f1:.4f}\")\n",
    "print(f\"Recall (macro)    : {recall:.4f}\")\n",
    "print(f\"Precision (macro) : {precision:.4f}\")\n",
    "print(f\"Cohen's Kappa     : {kappa:.4f}\")\n",
    "print(f\"Matthews CorrCoef : {mcc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
