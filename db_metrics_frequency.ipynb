{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libreries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from itertools import combinations\n",
    "from scipy import stats\n",
    "from scipy.io import loadmat, whosmat\n",
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import src\n",
    "from src import config, loadmatNina\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the database to analyze\n",
    "database = 'DB4'\n",
    "\n",
    "data_path = f'data/{database}'\n",
    "\n",
    "# Find the folder named with the convention s + \"number\"\n",
    "folder = None\n",
    "for item in os.listdir(data_path):\n",
    "    if re.match(r'[sS]\\d+', item) or re.match(r'Subject\\d+', item):\n",
    "        folder = item\n",
    "        break\n",
    "\n",
    "if folder:\n",
    "    folder_path = os.path.join(data_path, folder)\n",
    "    results = []\n",
    "\n",
    "    # Iterate over all .mat files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.mat'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            info = whosmat(file_path)\n",
    "            results.append((file_name, info))\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    data = {}\n",
    "    for file_name, info in results:\n",
    "        for item in info:\n",
    "            if item[0] not in data:\n",
    "                data[item[0]] = {}\n",
    "            data[item[0]][file_name] = item[1:]\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.transpose()\n",
    "    df.columns.name = 'File Name'\n",
    "\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No folder found with the convention s + 'number'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For complete signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "def calculate_emg_metrics(signal, fs=1000):\n",
    "    \"\"\"\n",
    "    Calculates various metrics for an EMG signal.\n",
    "\n",
    "    Parameters:\n",
    "    - signal: NumPy array containing the EMG signal.\n",
    "    - fs: Sampling frequency in Hz (default: 1000 Hz).\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with the computed metrics.\n",
    "    \"\"\"\n",
    "    # Mean Absolute Value (MAV)\n",
    "    mav = np.mean(np.abs(signal))\n",
    "    \n",
    "    # Integrated Absolute Value (IAV)\n",
    "    iav = np.sum(np.abs(signal))\n",
    "    \n",
    "    # Root Mean Square (RMS)\n",
    "    rms = np.sqrt(np.mean(signal**2))\n",
    "    \n",
    "    # Waveform Length (WL)\n",
    "    wl = np.sum(np.abs(np.diff(signal)))\n",
    "    \n",
    "    # Zero Crossings (ZC)\n",
    "    zc = np.sum(np.diff(np.sign(signal)) != 0)\n",
    "    \n",
    "    # Slope Sign Changes (SSC)\n",
    "    diff_signal = np.diff(signal)\n",
    "    ssc = np.sum((diff_signal[1:] * diff_signal[:-1]) < 0)\n",
    "    \n",
    "    # Variance (VAR)\n",
    "    var = np.var(signal)\n",
    "    \n",
    "    # Coefficient of Variation (CoV)\n",
    "    mean_signal = np.mean(signal)\n",
    "    cov = (np.std(signal) / mean_signal) if mean_signal != 0 else 0\n",
    "    \n",
    "    # Mean Frequency (MNF)\n",
    "    freqs = np.fft.rfftfreq(len(signal), d=1/fs)\n",
    "    fft_magnitude = np.abs(np.fft.rfft(signal))\n",
    "    mnf = np.sum(freqs * fft_magnitude) / np.sum(fft_magnitude)\n",
    "    \n",
    "    # Marginal Discrete Wavelet Transform (mDWT)\n",
    "    coeffs = pywt.wavedec(signal, 'db4', level=4)\n",
    "    mdwt = np.sum([np.sum(np.abs(c)) for c in coeffs])\n",
    "    \n",
    "    # Temporal Difference (TD)\n",
    "    td = np.sum(np.abs(np.diff(signal)))\n",
    "    \n",
    "    # Mean Absolute Value Slope (MAVS)\n",
    "    mavs = np.mean(np.abs(np.diff(signal)))\n",
    "    \n",
    "    # Return the metrics as a dictionary\n",
    "    metrics = {\n",
    "        \"MAV\": mav,\n",
    "        \"IAV\": iav,\n",
    "        \"RMS\": rms,\n",
    "        \"WL\": wl,\n",
    "        \"ZC\": zc,\n",
    "        \"SSC\": ssc,\n",
    "        \"VAR\": var,\n",
    "        \"CoV\": cov,\n",
    "        \"MNF\": mnf,\n",
    "        \"mDWT\": mdwt,\n",
    "        \"TD\": td,\n",
    "        \"MAVS\": mavs\n",
    "    }\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For signal with means and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "def calculate_emg_metrics_std(signal, fs=1000):\n",
    "    \"\"\"\n",
    "    Calculates various metrics for an EMG signal, including mean and standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    - signal: NumPy array containing the EMG signal.\n",
    "    - fs: Sampling frequency in Hz (default: 1000 Hz).\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with the computed metrics.\n",
    "    \"\"\"\n",
    "    if signal.ndim == 2:\n",
    "        metrics_per_channel = [calculate_emg_metrics(signal[:, ch], fs) for ch in range(signal.shape[1])]\n",
    "        averaged_metrics = {key: np.mean([m[key] for m in metrics_per_channel]) for key in metrics_per_channel[0]}\n",
    "        return averaged_metrics\n",
    "    \n",
    "    # Mean Absolute Value (MAV)\n",
    "    mav = np.mean(np.abs(signal))\n",
    "    mav_std = np.std(np.abs(signal))\n",
    "    \n",
    "    # Integrated Absolute Value (IAV)\n",
    "    iav = np.sum(np.abs(signal))\n",
    "    iav_std = np.std(np.abs(signal))\n",
    "    \n",
    "    # Root Mean Square (RMS)\n",
    "    rms = np.sqrt(np.mean(signal**2))\n",
    "    rms_std = np.std(signal)\n",
    "    \n",
    "    # Waveform Length (WL)\n",
    "    wl = np.sum(np.abs(np.diff(signal)))\n",
    "    wl_std = np.std(np.abs(np.diff(signal)))\n",
    "    \n",
    "    # Zero Crossings (ZC)\n",
    "    zc = np.sum(np.diff(np.sign(signal)) != 0)\n",
    "    zc_std = np.std(np.diff(np.sign(signal)) != 0)\n",
    "    \n",
    "    # Slope Sign Changes (SSC)\n",
    "    diff_signal = np.diff(signal)\n",
    "    ssc = np.sum((diff_signal[1:] * diff_signal[:-1]) < 0)\n",
    "    ssc_std = np.std((diff_signal[1:] * diff_signal[:-1]) < 0)\n",
    "    \n",
    "    # Variance (VAR)\n",
    "    var = np.var(signal)\n",
    "    var_std = np.std(signal)\n",
    "    \n",
    "    # Coefficient of Variation (CoV)\n",
    "    mean_signal = np.mean(signal)\n",
    "    cov = (np.std(signal) / mean_signal) if mean_signal != 0 else 0\n",
    "    cov_std = np.std(cov)\n",
    "    \n",
    "    # Mean Frequency (MNF)\n",
    "    freqs = np.fft.rfftfreq(len(signal), d=1/fs)\n",
    "    fft_magnitude = np.abs(np.fft.rfft(signal))\n",
    "    mnf = np.sum(freqs * fft_magnitude) / np.sum(fft_magnitude)\n",
    "    mnf_std = np.std(freqs * fft_magnitude) / np.sum(fft_magnitude)\n",
    "    \n",
    "    # Marginal Discrete Wavelet Transform (mDWT)\n",
    "    coeffs = pywt.wavedec(signal, 'db4', level=4)\n",
    "    mdwt = np.sum([np.sum(np.abs(c)) for c in coeffs])\n",
    "    mdwt_std = np.std([np.sum(np.abs(c)) for c in coeffs])\n",
    "    \n",
    "    # Temporal Difference (TD)\n",
    "    td = np.sum(np.abs(np.diff(signal)))\n",
    "    td_std = np.std(np.abs(np.diff(signal)))\n",
    "    \n",
    "    # Mean Absolute Value Slope (MAVS)\n",
    "    mavs = np.mean(np.abs(np.diff(signal)))\n",
    "    mavs_std = np.std(np.abs(np.diff(signal)))\n",
    "    \n",
    "    # Return the metrics as a dictionary\n",
    "    metrics = {\n",
    "        \"MAV\": mav, \"MAV_STD\": mav_std,\n",
    "        \"IAV\": iav, \"IAV_STD\": iav_std,\n",
    "        \"RMS\": rms, \"RMS_STD\": rms_std,\n",
    "        \"WL\": wl, \"WL_STD\": wl_std,\n",
    "        \"ZC\": zc, \"ZC_STD\": zc_std,\n",
    "        \"SSC\": ssc, \"SSC_STD\": ssc_std,\n",
    "        \"VAR\": var, \"VAR_STD\": var_std,\n",
    "        \"CoV\": cov, \"CoV_STD\": cov_std,\n",
    "        \"MNF\": mnf, \"MNF_STD\": mnf_std,\n",
    "        \"mDWT\": mdwt, \"mDWT_STD\": mdwt_std,\n",
    "        \"TD\": td, \"TD_STD\": td_std,\n",
    "        \"MAVS\": mavs, \"MAVS_STD\": mavs_std\n",
    "    }\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This functions calculate the metrics for channel and average the values for a complete result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_emg_metrics_means(signal):\n",
    "    \"\"\"\n",
    "    Calculates the metrics of an EMG signal. If there are multiple channels, it computes \n",
    "    the metrics for each channel and then averages the results.\n",
    "    \"\"\"\n",
    "    if signal.ndim == 2:  # If the signal has multiple channels\n",
    "        metrics_per_channel = [calculate_emg_metrics_means(signal[:, ch]) for ch in range(signal.shape[1])]\n",
    "        averaged_metrics = {key: np.mean([m[key] for m in metrics_per_channel]) for key in metrics_per_channel[0]}\n",
    "        return averaged_metrics\n",
    "    \n",
    "    # Mean Absolute Value (MAV)\n",
    "    mav = np.mean(np.abs(signal))\n",
    "    \n",
    "    # Integrated Absolute Value (IAV)\n",
    "    iav = np.sum(np.abs(signal))\n",
    "    \n",
    "    # Root Mean Square (RMS)\n",
    "    rms = np.sqrt(np.mean(signal**2))\n",
    "    \n",
    "    # Waveform Length (WL)\n",
    "    wl = np.sum(np.abs(np.diff(signal)))\n",
    "    \n",
    "    # Zero Crossings (ZC)\n",
    "    zc = np.sum(np.diff(np.sign(signal)) != 0)\n",
    "    \n",
    "    # Slope Sign Changes (SSC)\n",
    "    diff_signal = np.diff(signal)\n",
    "    ssc = np.sum((diff_signal[1:] * diff_signal[:-1]) < 0)\n",
    "    \n",
    "    # Variance (VAR)\n",
    "    var = np.var(signal)\n",
    "    \n",
    "    # Coefficient of Variation (CoV)\n",
    "    mean_signal = np.mean(signal)\n",
    "    cov = (np.std(signal) / mean_signal) if mean_signal != 0 else 0\n",
    "    \n",
    "    # Mean Frequency (MNF)\n",
    "    freqs = np.fft.rfftfreq(len(signal), d=1/fs)\n",
    "    fft_magnitude = np.abs(np.fft.rfft(signal))\n",
    "    mnf = np.sum(freqs * fft_magnitude) / np.sum(fft_magnitude)\n",
    "    \n",
    "    # Marginal Discrete Wavelet Transform (mDWT)\n",
    "    coeffs = pywt.wavedec(signal, 'db4', level=4)\n",
    "    mdwt = np.sum([np.sum(np.abs(c)) for c in coeffs])\n",
    "    \n",
    "    # Temporal Difference (TD)\n",
    "    td = np.sum(np.abs(np.diff(signal)))\n",
    "    \n",
    "    # Mean Absolute Value Slope (MAVS)\n",
    "    mavs = np.mean(np.abs(np.diff(signal)))\n",
    "    \n",
    "    # Return the metrics as a dictionary\n",
    "    metrics = {\n",
    "        \"MAV\": mav,\n",
    "        \"IAV\": iav,\n",
    "        \"RMS\": rms,\n",
    "        \"WL\": wl,\n",
    "        \"ZC\": zc,\n",
    "        \"SSC\": ssc,\n",
    "        \"VAR\": var,\n",
    "        \"CoV\": cov,\n",
    "        \"MNF\": mnf,\n",
    "        \"mDWT\": mdwt,\n",
    "        \"TD\": td,\n",
    "        \"MAVS\": mavs\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots and metrics for complete grasp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database name\n",
    "database = 'DB4'\n",
    "\n",
    "# Full path to the database folder\n",
    "data_path = os.path.abspath(os.path.join('data', database))\n",
    "\n",
    "# List of subjects, generating names from 's1' to 's10'\n",
    "subjects = [f's{i}' for i in range(1, 11)]\n",
    "\n",
    "# Iterate over each subject\n",
    "for subject in subjects:\n",
    "    subject_dir = os.path.join(data_path, subject)\n",
    "    \n",
    "    # Iterate over exercise files E1, E2, and E3 for the current subject\n",
    "    for exercise in [\"E1\", \"E2\", \"E3\"]:\n",
    "        filename = f\"{subject.upper()}_{exercise}_A1.mat\"\n",
    "        file_path = os.path.join(subject_dir, filename)\n",
    "        \n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing: {filename}\")\n",
    "        \n",
    "        # Load data from the .mat file\n",
    "        mat_data = src.loadmatNina(database, filename, subject=subject)\n",
    "        \n",
    "        # Verify the structure of the loaded dictionary\n",
    "        print(f\"Keys in mat_data: {mat_data.keys()}\")\n",
    "        \n",
    "        # Retrieve re-labeled data and the list of labeled grasps\n",
    "        test_df, grasps_etiquetados = src.build_dataframe(\n",
    "            mat_file=mat_data,\n",
    "            database=database,\n",
    "            filename=filename,\n",
    "            rectify=False,\n",
    "            normalize=True\n",
    "        )\n",
    "        \n",
    "        # Iterate over each labeled grasp\n",
    "        for grasp in grasps_etiquetados:\n",
    "            try:\n",
    "                # Check if 'emg' key exists in mat_data\n",
    "                if 'emg' not in mat_data:\n",
    "                    raise KeyError(f\"The key 'emg' is not in mat_data. Available keys: {mat_data.keys()}\")\n",
    "                \n",
    "                # Get the EMG signal for the labeled grasp\n",
    "                emg_signal = mat_data['emg'][grasp]  # Adjust based on the actual structure\n",
    "                \n",
    "                # Compute EMG signal metrics\n",
    "                metrics = calculate_emg_metrics(emg_signal)\n",
    "                \n",
    "                # Print computed metrics\n",
    "                print(f\"\\nMetrics for Grasp {grasp}:\")\n",
    "                for key, value in metrics.items():\n",
    "                    print(f\"{key}: {value:.4f}\")\n",
    "                \n",
    "                # Plot the EMG signal for the grasp\n",
    "                src.plot_emg_data(\n",
    "                    database=database,\n",
    "                    mat_file=mat_data,\n",
    "                    grasp_number=grasp,\n",
    "                    interactive=False,\n",
    "                    include_rest=True,\n",
    "                    use_stimulus=False,\n",
    "                    addFourier=False,\n",
    "                    padding=100,\n",
    "                    title=f\"{filename} - Grasp {grasp}\"\n",
    "                )\n",
    "            except KeyError as e:\n",
    "                print(f\"    Error: {str(e)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"    Error processing grasp {grasp}: {str(e)}\")\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe with metrics for a complete signal without discriminating by channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store all extracted metrics\n",
    "metrics_data = []\n",
    "\n",
    "# Iterate over each subject in the database\n",
    "for subject in subjects:\n",
    "    subject_dir = os.path.join(data_path, subject)\n",
    "    \n",
    "    # Iterate over exercise files E1, E2, and E3\n",
    "    for exercise in [\"E1\", \"E2\", \"E3\"]:\n",
    "        filename = f\"{subject.upper()}_{exercise}_A1.mat\"\n",
    "        file_path = os.path.join(subject_dir, filename)\n",
    "        \n",
    "        # Check if the file exists before processing\n",
    "        if not os.path.exists(file_path):\n",
    "            continue  # Skip if file is not available\n",
    "        \n",
    "        # Load data from the .mat file\n",
    "        mat_data = src.loadmatNina(database, filename, subject=subject)\n",
    "        \n",
    "        # Build DataFrame with re-labeled data\n",
    "        test_df, grasps_etiquetados = src.build_dataframe(\n",
    "            mat_file=mat_data,\n",
    "            database=database,\n",
    "            filename=filename,\n",
    "            rectify=False,\n",
    "            normalize=True\n",
    "        )\n",
    "        \n",
    "        # Iterate over labeled grasps\n",
    "        for grasp in grasps_etiquetados:\n",
    "            try:\n",
    "                # Retrieve the corresponding EMG signal\n",
    "                emg_signal = mat_data['emg'][grasp]\n",
    "                \n",
    "                # Compute EMG signal metrics\n",
    "                metrics = calculate_emg_metrics(emg_signal)\n",
    "                \n",
    "                # Append metrics with metadata to the list\n",
    "                metrics_data.append({\n",
    "                    \"subject\": subject,\n",
    "                    \"exercise\": exercise,\n",
    "                    \"filename\": filename,\n",
    "                    \"grasp\": grasp,\n",
    "                    **metrics  # Unpack metrics into the dictionary\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in {filename} - Grasp {grasp}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "# Create a DataFrame with organized metrics\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "# Reorder columns (optional) for better visualization\n",
    "column_order = [\"subject\", \"exercise\", \"filename\", \"grasp\"] + list(metrics.keys())\n",
    "metrics_df = metrics_df[column_order]\n",
    "\n",
    "# Print the final DataFrame with extracted metrics\n",
    "print(\"\\nMetrics DataFrame:\")\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe with average of metrics for channels in each grasp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe with mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import src\n",
    "\n",
    "# List to store all computed metrics\n",
    "metrics_data = []\n",
    "\n",
    "# Iterate over each subject in the database\n",
    "for subject in subjects:\n",
    "    subject_dir = os.path.join(data_path, subject)\n",
    "    \n",
    "    # Iterate over exercise files E1, E2, and E3\n",
    "    for exercise in [\"E1\", \"E2\", \"E3\"]:\n",
    "        filename = f\"{subject.upper()}_{exercise}_A1.mat\"\n",
    "        file_path = os.path.join(subject_dir, filename)\n",
    "        \n",
    "        # Check if the file exists before processing\n",
    "        if not os.path.exists(file_path):\n",
    "            continue  # Skip if file is not available\n",
    "        \n",
    "        # Load data from the .mat file\n",
    "        mat_data = src.loadmatNina(database, filename, subject=subject)\n",
    "        \n",
    "        # Build DataFrame with re-labeled data\n",
    "        test_df, grasps_etiquetados = src.build_dataframe(\n",
    "            mat_file=mat_data,\n",
    "            database=database,\n",
    "            filename=filename,\n",
    "            rectify=False,\n",
    "            normalize=True\n",
    "        )\n",
    "        \n",
    "        # Iterate over labeled grasps\n",
    "        for grasp in grasps_etiquetados:\n",
    "            try:\n",
    "                # Retrieve the corresponding EMG signal\n",
    "                emg_signal = mat_data['emg'][grasp]\n",
    "                \n",
    "                # Compute EMG signal metrics using standard deviation\n",
    "                metrics = calculate_emg_metrics_std(emg_signal)\n",
    "                \n",
    "                # Append metrics with metadata to the list\n",
    "                metrics_data.append({\n",
    "                    \"subject\": subject,\n",
    "                    \"exercise\": exercise,\n",
    "                    \"filename\": filename,\n",
    "                    \"grasp\": grasp,\n",
    "                    **metrics  # Unpack metrics into the dictionary\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in {filename} - Grasp {grasp}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "# Create a DataFrame with organized metrics\n",
    "metrics_df_std = pd.DataFrame(metrics_data)\n",
    "\n",
    "# Reorder columns (optional) for better visualization\n",
    "column_order = [\"subject\", \"exercise\", \"filename\", \"grasp\"] + list(metrics.keys())\n",
    "metrics_df_std = metrics_df_std[column_order]\n",
    "\n",
    "# Print the final DataFrame with extracted metrics\n",
    "print(\"\\nMetrics DataFrame:\")\n",
    "display(metrics_df_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe for every channels of data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store all generated DataFrames\n",
    "all_dataframes = []\n",
    "\n",
    "# Look for folders matching the pattern \"s + number\" or \"Subject + number\"\n",
    "for folder in os.listdir(data_path):\n",
    "    if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "        folder_path = os.path.join(data_path, folder)\n",
    "        \n",
    "        # Iterate over all .mat files in the folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.mat'):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                \n",
    "                # Attempt to load the .mat file\n",
    "                try:\n",
    "                    mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error loading {file_name}: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Attempt to process the file with src.build_dataframe\n",
    "                try:\n",
    "                    test_df, grasps = src.build_dataframe(\n",
    "                        mat_file=mat_data,\n",
    "                        database=database,\n",
    "                        filename=file_name,\n",
    "                        rectify=False,\n",
    "                        normalize=True\n",
    "                    )\n",
    "                    \n",
    "                    # Add a column with the subject name (folder) to the DataFrame\n",
    "                    test_df['subject'] = folder  \n",
    "                    \n",
    "                    # Append the processed DataFrame to the list\n",
    "                    all_dataframes.append(test_df)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_name}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "# Concatenate all DataFrames into a single one if data is available\n",
    "if all_dataframes:  \n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Display the combined DataFrame\n",
    "    print(\"\\n Combined DataFrame:\")\n",
    "    display(combined_df)  \n",
    "\n",
    "else:\n",
    "    print(\"Warning: No DataFrames were generated. Check the input data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe with metrics for channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_emg_metrics(signal, fs=1000):\n",
    "    \"\"\"\n",
    "    Calculates various metrics for an EMG signal, including mean and standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    - signal: NumPy array containing the EMG signal.\n",
    "    - fs: Sampling frequency in Hz (default: 1000 Hz).\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with the computed metrics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if signal.ndim == 2:\n",
    "            metrics_per_channel = [calculate_emg_metrics(signal[:, ch], fs) for ch in range(signal.shape[1])]\n",
    "            averaged_metrics = {key: np.mean([m[key] for m in metrics_per_channel]) for key in metrics_per_channel[0]}\n",
    "            return averaged_metrics\n",
    "        \n",
    "        abs_signal = np.abs(signal)\n",
    "        diff_signal = np.diff(signal)\n",
    "        diff_abs_signal = np.abs(diff_signal)\n",
    "        \n",
    "        # Compute Metrics\n",
    "        metrics = {\n",
    "            \"MAV\": np.mean(abs_signal), \"MAV_STD\": np.std(abs_signal),\n",
    "            \"IAV\": np.sum(abs_signal), \"IAV_STD\": np.std(abs_signal),\n",
    "            \"RMS\": np.sqrt(np.mean(signal**2)), \"RMS_STD\": np.std(signal),\n",
    "            \"WL\": np.sum(diff_abs_signal), \"WL_STD\": np.std(diff_abs_signal),\n",
    "            \"ZC\": np.sum(np.diff(np.sign(signal)) != 0), \"ZC_STD\": np.std(np.diff(np.sign(signal)) != 0),\n",
    "            \"SSC\": np.sum((diff_signal[1:] * diff_signal[:-1]) < 0), \"SSC_STD\": np.std((diff_signal[1:] * diff_signal[:-1]) < 0),\n",
    "            \"VAR\": np.var(signal), \"VAR_STD\": np.std(signal),\n",
    "            \"CoV\": (np.std(signal) / np.mean(signal)) if np.mean(signal) != 0 else 0,\n",
    "            \"TD\": np.sum(diff_abs_signal), \"TD_STD\": np.std(diff_abs_signal),\n",
    "            \"MAVS\": np.mean(diff_abs_signal), \"MAVS_STD\": np.std(diff_abs_signal),\n",
    "            \"MNP\": np.mean(signal**2), \"MNP_STD\": np.std(signal**2),\n",
    "        }\n",
    "        \n",
    "        # Spectral Metrics\n",
    "        freqs = np.fft.rfftfreq(len(signal), d=1/fs)\n",
    "        fft_magnitude = np.abs(np.fft.rfft(signal))\n",
    "        metrics[\"MNF\"] = np.sum(freqs * fft_magnitude) / np.sum(fft_magnitude) if np.sum(fft_magnitude) != 0 else 0\n",
    "        metrics[\"MNF_STD\"] = np.std(freqs * fft_magnitude) / np.sum(fft_magnitude) if np.sum(fft_magnitude) != 0 else 0\n",
    "        \n",
    "        # Wavelet Transform\n",
    "        coeffs = pywt.wavedec(signal, 'db4', level=4)\n",
    "        mdwt_values = np.array([np.sum(np.abs(c)) for c in coeffs])\n",
    "        metrics[\"mDWT\"] = np.sum(mdwt_values)\n",
    "        metrics[\"mDWT_STD\"] = np.std(mdwt_values)\n",
    "        \n",
    "        # Kurtosis\n",
    "        std_signal = np.std(signal)\n",
    "        metrics[\"Kurt\"] = np.mean((signal - np.mean(signal)) ** 4) / (std_signal ** 4) if std_signal != 0 else 0\n",
    "        metrics[\"Kurt_STD\"] = np.std(metrics[\"Kurt\"])\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_emg_metrics: {e}\")\n",
    "        return {}\n",
    "\n",
    "# List to store the calculated metrics for each channel\n",
    "metrics_data = []\n",
    "\n",
    "# Iterate over each subject and each identified movement (relabeled or stimulus)\n",
    "for (subject, relabeled), group in combined_df.groupby(['subject', 'relabeled']):  # Change 'relabeled' to 'stimulus' if needed\n",
    "    # Iterate over each EMG channel\n",
    "    for channel in group.columns:  # Loop through all DataFrame columns\n",
    "        if channel.startswith('Channel'):  # Filter only EMG signal columns\n",
    "            # Get the signal values for the current channel\n",
    "            channel_signal = group[channel].values\n",
    "            \n",
    "            # Compute EMG signal metrics for the current channel\n",
    "            metrics = calculate_emg_metrics(channel_signal)\n",
    "            \n",
    "            # Append metadata and computed metrics to the list\n",
    "            metrics_data.append({\n",
    "                \"subject\": subject,  # Subject identification\n",
    "                \"relabeled\": relabeled,  # Movement identification (relabeled or stimulus)\n",
    "                \"channel\": channel,  # EMG channel\n",
    "                **metrics  # Unpack all computed metrics\n",
    "            })\n",
    "\n",
    "# Create a DataFrame containing all the obtained metrics\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "# Reorder columns for better visualization (optional)\n",
    "column_order = [\"subject\", \"relabeled\", \"channel\"] + list(metrics.keys())\n",
    "metrics_df = metrics_df[column_order]\n",
    "\n",
    "# Display the DataFrame with the computed metrics\n",
    "print(\"\\nMetrics DataFrame by Channel, Subject, and Relabeled:\")\n",
    "display(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'channel' column to group data by subject and movement type\n",
    "grouped_df = metrics_df.drop(columns=['channel'])\n",
    "\n",
    "# Compute the mean value of each metric grouped by subject and movement\n",
    "df_mean = grouped_df.groupby(['subject', 'relabeled']).mean()\n",
    "\n",
    "# Compute the standard deviation of each metric grouped by subject and movement\n",
    "df_std = grouped_df.groupby(['subject', 'relabeled']).std()\n",
    "\n",
    "# Rename columns to indicate they contain mean values\n",
    "df_mean.columns = [f\"{col} mean\" for col in df_mean.columns]\n",
    "\n",
    "# Rename columns to indicate they contain standard deviation values\n",
    "df_std.columns = [f\"{col} std\" for col in df_std.columns]\n",
    "\n",
    "# Merge the mean and standard deviation DataFrames into a single DataFrame\n",
    "df_result = df_mean.merge(df_std, on=['subject', 'relabeled']).reset_index()\n",
    "\n",
    "# Display the final DataFrame with aggregated metrics\n",
    "display(df_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dendogram for grasp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns containing numerical features\n",
    "features = df_result.iloc[:, 2:]  # Exclude 'subject' and 'relabeled'\n",
    "\n",
    "# Normalize the data to improve comparability and avoid bias due to different scales\n",
    "df_scaled = StandardScaler().fit_transform(features)\n",
    "\n",
    "# Apply hierarchical clustering using the Ward method (minimizes variance within clusters)\n",
    "linked = sch.linkage(df_scaled, method='ward')\n",
    "\n",
    "# Create and visualize the dendrogram\n",
    "plt.figure(figsize=(20, 10))\n",
    "sch.dendrogram(\n",
    "    linked, \n",
    "    labels=df_result['relabeled'].values,  # Labels on the x-axis based on the 'relabeled' variable\n",
    "    leaf_rotation=90,  # Rotate labels for better readability\n",
    "    leaf_font_size=8  # Adjust font size\n",
    ")\n",
    "plt.title(\"Dendrogram based on the 'relabeled' variable\")\n",
    "plt.xlabel(\"Clusters\")\n",
    "plt.ylabel(\"Euclidean Distance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'relabeled' and calculate the mean and standard deviation of each numerical feature\n",
    "grouped = df_result.select_dtypes(include=['number']).groupby(df_result['relabeled']).agg(['mean', 'std'])\n",
    "display(grouped)\n",
    "\n",
    "# Flatten column names to make them easier to work with\n",
    "grouped.columns = ['_'.join(col).strip() for col in grouped.columns.values]\n",
    "\n",
    "# Normalize the data to prevent magnitude differences from affecting the clustering distance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(grouped)\n",
    "\n",
    "# Apply hierarchical clustering using the Ward method (minimizes variance within clusters)\n",
    "linked = sch.linkage(scaled_features, method='ward')\n",
    "\n",
    "# Create and visualize the dendrogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "sch.dendrogram(\n",
    "    linked, \n",
    "    labels=grouped.index.tolist(),  # Labels on the x-axis based on the 'relabeled' variable\n",
    "    leaf_rotation=90,  # Rotate labels for better readability\n",
    "    leaf_font_size=8  # Adjust font size\n",
    ")\n",
    "plt.title(\"Dendrogram based on mean and standard deviation per grasp type\")\n",
    "plt.xlabel(\"Grasps\")\n",
    "plt.ylabel(\"Euclidean Distance\") \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Compute the average of metrics per channel\n",
    "# Exclude 'subject', 'relabeled', and 'channel' to keep only the metric columns\n",
    "metrics_columns = [col for col in metrics_df.columns if col not in [\"subject\", \"relabeled\", \"channel\"]]\n",
    "\n",
    "# Group by 'channel' and compute the mean of each metric\n",
    "average_metrics_df = metrics_df.groupby('channel')[metrics_columns].mean().reset_index()\n",
    "display(average_metrics_df)\n",
    "\n",
    "# 2. Prepare data for clustering\n",
    "X = average_metrics_df[metrics_columns].values  # Extract metric values as an array for clustering\n",
    "\n",
    "# 3. Compute the distance matrix and perform hierarchical clustering\n",
    "Z = linkage(X, method='ward')  # 'ward' minimizes variance within clusters\n",
    "\n",
    "# 4. Plot the dendrogram with adjustments for better visualization\n",
    "plt.figure(figsize=(15, 8)) \n",
    "plt.title('Dendrogram of EMG Channels (Average Metrics)', fontsize=16, pad=20)\n",
    "plt.xlabel('Channels', fontsize=14)\n",
    "plt.ylabel('Distance', fontsize=14)\n",
    "\n",
    "# Adjust the dendrogram to prevent overlapping labels\n",
    "dendrogram(\n",
    "    Z,\n",
    "    labels=average_metrics_df['channel'].values,  # Labels for each channel\n",
    "    leaf_rotation=90,  # Rotate labels for better readability\n",
    "    leaf_font_size=12,  # Adjust font size\n",
    "    color_threshold=0.7 * max(Z[:, 2]),  # Threshold to color clusters\n",
    ")\n",
    "\n",
    "plt.tight_layout()  # Automatically adjust layout for better fit\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Compute the mean and standard deviation of metrics per channel\n",
    "# Exclude 'subject', 'relabeled', and 'channel' to keep only numerical metric columns\n",
    "metrics_columns = [col for col in metrics_df.columns if col not in [\"subject\", \"relabeled\", \"channel\"]]\n",
    "\n",
    "# Group by 'channel' and compute the mean and standard deviation for each metric\n",
    "agg_metrics_df = metrics_df.groupby('channel')[metrics_columns].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Flatten column names for easier access (concatenating \"metric_type\")\n",
    "agg_metrics_df.columns = ['_'.join(col).strip('_') for col in agg_metrics_df.columns]\n",
    "\n",
    "display(agg_metrics_df)  # Display the aggregated metrics table\n",
    "\n",
    "# 2. Prepare data for clustering using only the metric averages\n",
    "X = agg_metrics_df[[col for col in agg_metrics_df.columns if col.endswith('_mean')]].values  # Extract only \"_mean\" columns\n",
    "\n",
    "# 3. Compute the distance matrix and perform hierarchical clustering\n",
    "Z = linkage(X, method='ward')  # 'ward' minimizes variance within clusters\n",
    "\n",
    "# 4. Plot the dendrogram with adjustments for better visualization\n",
    "plt.figure(figsize=(15, 8)) \n",
    "plt.title('Dendrogram of EMG Channels (Average Metrics)', fontsize=16, pad=20)\n",
    "plt.xlabel('Channels', fontsize=14)\n",
    "plt.ylabel('Distance', fontsize=14)\n",
    "\n",
    "# Adjust the dendrogram to prevent overlapping labels\n",
    "dendrogram(\n",
    "    Z,\n",
    "    labels=agg_metrics_df['channel'].values,  # Labels for EMG channels\n",
    "    leaf_rotation=90,  # Rotate labels for better readability\n",
    "    leaf_font_size=12,  # Adjust font size\n",
    "    color_threshold=0.7 * max(Z[:, 2]),  # Threshold to color clusters\n",
    ")\n",
    "\n",
    "plt.tight_layout()  # Automatically adjust layout for better fit\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# 1. Select only metric columns for clustering, excluding metadata\n",
    "# Exclude non-metric columns ('subject', 'relabeled', and 'channel')\n",
    "metrics_columns = [col for col in metrics_df.columns if col not in [\"subject\", \"relabeled\", \"channel\"]]\n",
    "X = metrics_df[metrics_columns].values  # Convert to a NumPy array for clustering\n",
    "\n",
    "# 2. Compute the distance matrix and perform hierarchical clustering\n",
    "Z = linkage(X, method='ward')  # 'ward' method minimizes variance within clusters\n",
    "\n",
    "# 3. Plot the dendrogram with adjustments for better visualization\n",
    "plt.figure(figsize=(20, 10))  # Increase figure size\n",
    "plt.title('Dendrogram of EMG Channels', fontsize=16, pad=20)\n",
    "plt.xlabel('Channels', fontsize=14)\n",
    "plt.ylabel('Distance', fontsize=14)\n",
    "\n",
    "# Configure the dendrogram\n",
    "dendrogram(\n",
    "    Z,\n",
    "    labels=metrics_df['channel'].values,  # Labels for EMG channels\n",
    "    leaf_rotation=90,  # Rotate labels for better readability\n",
    "    leaf_font_size=10,  # Adjust font size\n",
    "    color_threshold=0.7 * max(Z[:, 2]),  # Threshold to color clusters\n",
    ")\n",
    "\n",
    "plt.tight_layout()  # Automatically adjust layout for better fit\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mahalanobis use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Group by 'relabeled' and compute the mean and standard deviation of each metric\n",
    "grouped = df_result.select_dtypes(include=['number']).groupby(df_result['relabeled']).agg(['mean', 'std'])\n",
    "\n",
    "# 2. Flatten column names for easier access\n",
    "grouped.columns = ['_'.join(col).strip() for col in grouped.columns.values]\n",
    "\n",
    "# 3. Normalize the data to avoid magnitude differences affecting clustering\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(grouped)\n",
    "\n",
    "# 4. Compute the covariance matrix and its pseudoinverse (for Mahalanobis distance)\n",
    "cov_matrix = np.cov(scaled_features, rowvar=False)  # Covariance matrix\n",
    "inv_cov_matrix = np.linalg.pinv(cov_matrix)  # Pseudoinverse instead of inverse\n",
    "\n",
    "# 5. Compute Mahalanobis distances between each pair of groups\n",
    "mahalanobis_distances = pdist(scaled_features, metric='mahalanobis', VI=inv_cov_matrix)\n",
    "\n",
    "# 6. Convert to a square distance matrix\n",
    "distance_matrix = squareform(mahalanobis_distances)\n",
    "\n",
    "# 7. Apply hierarchical clustering using Mahalanobis distance\n",
    "linked = sch.linkage(distance_matrix, method='average')  # 'average' method for more stability\n",
    "\n",
    "# 8. Generate the dendrogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "sch.dendrogram(linked, labels=grouped.index.tolist(), leaf_rotation=90, leaf_font_size=8)\n",
    "plt.title(\"Dendrogram based on Mahalanobis Distance\", fontsize=14, pad=15)\n",
    "plt.xlabel(\"Grasps\", fontsize=12)\n",
    "plt.ylabel(\"Mahalanobis Distance\", fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the relevant columns for clustering analysis\n",
    "X = df_result.iloc[:, 3:35].values  # Assuming df_result is equivalent to ypolfqrt in R\n",
    "\n",
    "# Normalize the data to prevent bias due to differences in variable scales\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Compute the covariance matrix and its inverse\n",
    "cov_matrix = np.cov(X_scaled, rowvar=False)\n",
    "inv_cov_matrix = np.linalg.pinv(cov_matrix)  # Use pseudoinverse to avoid singularity issues\n",
    "\n",
    "# Compute the Mahalanobis distance between samples\n",
    "mahalanobis_distances = pdist(X_scaled, metric='mahalanobis', VI=inv_cov_matrix)\n",
    "\n",
    "# Convert the distance vector into a square distance matrix for clustering\n",
    "distance_matrix = squareform(mahalanobis_distances)\n",
    "\n",
    "# Apply hierarchical clustering using the Ward method\n",
    "# This method minimizes the variance within the formed clusters.\n",
    "linked = sch.linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Create and visualize the dendrogram with label and font size adjustments\n",
    "plt.figure(figsize=(12, 6))  # Adjust figure size\n",
    "sch.dendrogram(\n",
    "    linked, \n",
    "    labels=df_result['relabeled'].values,  # Use grasp movement labels\n",
    "    leaf_rotation=90,  # Rotate labels for better readability\n",
    "    leaf_font_size=8  # Adjust font size for labels\n",
    ")\n",
    "plt.title(\"Dendrogram based on Mahalanobis Distance\")  # Set plot title\n",
    "plt.xlabel(\"Grasps\")  # X-axis label\n",
    "plt.ylabel(\"Mahalanobis Distance\")  # Y-axis label\n",
    "plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by the 'relabeled' column and compute the mean and standard deviation\n",
    "grouped = df_result.select_dtypes(include=['number']).groupby(df_result['relabeled']).agg(['mean', 'std'])\n",
    "\n",
    "# Flatten column names for easier data access\n",
    "# Add '_mean' and '_std' suffixes to identify each statistic\n",
    "grouped.columns = ['_'.join(col).strip() for col in grouped.columns.values]\n",
    "\n",
    "# Normalize the data so that all features are on the same scale\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(grouped)\n",
    "\n",
    "# Compute the covariance matrix and invert it\n",
    "cov_matrix = np.cov(scaled_features, rowvar=False)\n",
    "inv_cov_matrix = np.linalg.pinv(cov_matrix)  # Use the pseudo-inverse to avoid issues with singular matrices\n",
    "\n",
    "# Compute the Mahalanobis distance between samples\n",
    "mahalanobis_distances = pdist(scaled_features, metric='mahalanobis', VI=inv_cov_matrix)\n",
    "\n",
    "# Convert the distance vector into a square matrix\n",
    "distance_matrix = squareform(mahalanobis_distances)\n",
    "\n",
    "# Apply hierarchical clustering using the Ward method\n",
    "linked = sch.linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Generate the dendrogram to visualize the clusters\n",
    "plt.figure(figsize=(12, 6))\n",
    "sch.dendrogram(linked, labels=grouped.index.tolist(), leaf_rotation=90, leaf_font_size=8)\n",
    "plt.title(\"Dendrogram based on mean and standard deviation with Mahalanobis distance\")\n",
    "plt.xlabel(\"Grasps\")\n",
    "plt.ylabel(\"Mahalanobis Distance\") \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
