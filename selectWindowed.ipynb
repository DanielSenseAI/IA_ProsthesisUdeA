{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b1ac074",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7b0f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from itertools import combinations\n",
    "from scipy import stats\n",
    "from scipy.io import loadmat, whosmat\n",
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.linalg import inv\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "\n",
    "import pywt\n",
    "\n",
    "import src\n",
    "from src import config, loadmatNina\n",
    "from src.preprocessing_utils import get_envelope\n",
    "import pycaret.classification as pyc\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c830f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the database to analyze\n",
    "database = 'DB4'\n",
    "\n",
    "data_path = f'data/{database}'\n",
    "\n",
    "# Find the folder named with the convention s + \"number\"\n",
    "folder = None\n",
    "for item in os.listdir(data_path):\n",
    "    if re.match(r'[sS]\\d+', item) or re.match(r'Subject\\d+', item):\n",
    "        folder = item\n",
    "        break\n",
    "\n",
    "if folder:\n",
    "    folder_path = os.path.join(data_path, folder)\n",
    "    results = []\n",
    "\n",
    "    # Iterate over all .mat files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.mat'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            info = whosmat(file_path)\n",
    "            results.append((file_name, info))\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    data = {}\n",
    "    for file_name, info in results:\n",
    "        for item in info:\n",
    "            if item[0] not in data:\n",
    "                data[item[0]] = {}\n",
    "            data[item[0]][file_name] = item[1:]\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.transpose()\n",
    "    df.columns.name = 'File Name'\n",
    "\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No folder found with the convention s + 'number'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6573e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_emg_metrics(signal, fs=2000):\n",
    "    \"\"\"\n",
    "    Calculates various metrics for an EMG signal.\n",
    "\n",
    "    Parameters:\n",
    "    - signal: NumPy array containing the EMG signal.\n",
    "    - fs: Sampling frequency in Hz (default: 1000 Hz).\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with the computed metrics.\n",
    "    \"\"\"\n",
    "    # Mean Absolute Value (MAV)\n",
    "    mav = np.mean(np.abs(signal))\n",
    "    \n",
    "    # Integrated Absolute Value (IAV)\n",
    "    iav = np.sum(np.abs(signal))\n",
    "    \n",
    "    # Root Mean Square (RMS)\n",
    "    rms = np.sqrt(np.mean(signal**2))\n",
    "    \n",
    "    # Waveform Length (WL)\n",
    "    wl = np.sum(np.abs(np.diff(signal)))\n",
    "    \n",
    "    # Zero Crossings (ZC)\n",
    "    zc = np.sum(np.diff(np.sign(signal)) != 0)\n",
    "    \n",
    "    # Slope Sign Changes (SSC)\n",
    "    diff_signal = np.diff(signal)\n",
    "    ssc = np.sum((diff_signal[1:] * diff_signal[:-1]) < 0)\n",
    "    \n",
    "    # Variance (VAR)\n",
    "    var = np.var(signal)\n",
    "    \n",
    "    # Coefficient of Variation (CoV)\n",
    "    mean_signal = np.mean(signal)\n",
    "    cov = (np.std(signal) / mean_signal) if mean_signal != 0 else 0\n",
    "    \n",
    "    # Mean Frequency (MNF)\n",
    "    freqs = np.fft.rfftfreq(len(signal), d=1/fs)\n",
    "    fft_magnitude = np.abs(np.fft.rfft(signal))\n",
    "    mnf = np.sum(freqs * fft_magnitude) / np.sum(fft_magnitude)\n",
    "    \n",
    "    # Marginal Discrete Wavelet Transform (mDWT)\n",
    "    coeffs = pywt.wavedec(signal, 'db4', level=4)\n",
    "    mdwt = np.sum([np.sum(np.abs(c)) for c in coeffs])\n",
    "    \n",
    "    # Temporal Difference (TD)\n",
    "    td = np.sum(np.abs(np.diff(signal)))\n",
    "    \n",
    "    # Mean Absolute Value Slope (MAVS)\n",
    "    mavs = np.mean(np.abs(np.diff(signal)))\n",
    "    \n",
    "    # Return the metrics as a dictionary\n",
    "    metrics = {\n",
    "        \"MAV\": mav,\n",
    "        \"IAV\": iav,\n",
    "        \"RMS\": rms,\n",
    "        \"WL\": wl,\n",
    "        \"ZC\": zc,\n",
    "        \"SSC\": ssc,\n",
    "        \"VAR\": var,\n",
    "        \"CoV\": cov,\n",
    "        \"MNF\": mnf,\n",
    "        \"mDWT\": mdwt,\n",
    "        \"TD\": td,\n",
    "        \"MAVS\": mavs\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def calculate_emg_metrics_std(signal, fs=2000):\n",
    "    \"\"\"\n",
    "    Calculates various metrics for an EMG signal, including mean and standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    - signal: NumPy array containing the EMG signal.\n",
    "    - fs: Sampling frequency in Hz (default: 1000 Hz).\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with the computed metrics.\n",
    "    \"\"\"\n",
    "    if signal.ndim == 2:\n",
    "        metrics_per_channel = [calculate_emg_metrics(signal[:, ch], fs) for ch in range(signal.shape[1])]\n",
    "        averaged_metrics = {key: np.mean([m[key] for m in metrics_per_channel]) for key in metrics_per_channel[0]}\n",
    "        return averaged_metrics\n",
    "    \n",
    "    # Mean Absolute Value (MAV)\n",
    "    mav = np.mean(np.abs(signal))\n",
    "    mav_std = np.std(np.abs(signal))\n",
    "    \n",
    "    # Integrated Absolute Value (IAV)\n",
    "    iav = np.sum(np.abs(signal))\n",
    "    iav_std = np.std(np.abs(signal))\n",
    "    \n",
    "    # Root Mean Square (RMS)\n",
    "    rms = np.sqrt(np.mean(signal**2))\n",
    "    rms_std = np.std(signal)\n",
    "    \n",
    "    # Waveform Length (WL)\n",
    "    wl = np.sum(np.abs(np.diff(signal)))\n",
    "    wl_std = np.std(np.abs(np.diff(signal)))\n",
    "    \n",
    "    # Zero Crossings (ZC)\n",
    "    zc = np.sum(np.diff(np.sign(signal)) != 0)\n",
    "    zc_std = np.std(np.diff(np.sign(signal)) != 0)\n",
    "    \n",
    "    # Slope Sign Changes (SSC)\n",
    "    diff_signal = np.diff(signal)\n",
    "    ssc = np.sum((diff_signal[1:] * diff_signal[:-1]) < 0)\n",
    "    ssc_std = np.std((diff_signal[1:] * diff_signal[:-1]) < 0)\n",
    "    \n",
    "    # Variance (VAR)\n",
    "    var = np.var(signal)\n",
    "    var_std = np.std(signal)\n",
    "    \n",
    "    # Coefficient of Variation (CoV)\n",
    "    mean_signal = np.mean(signal)\n",
    "    cov = (np.std(signal) / mean_signal) if mean_signal != 0 else 0\n",
    "    cov_std = np.std(cov)\n",
    "    \n",
    "    # Mean Frequency (MNF)\n",
    "    freqs = np.fft.rfftfreq(len(signal), d=1/fs)\n",
    "    fft_magnitude = np.abs(np.fft.rfft(signal))\n",
    "    mnf = np.sum(freqs * fft_magnitude) / np.sum(fft_magnitude)\n",
    "    mnf_std = np.std(freqs * fft_magnitude) / np.sum(fft_magnitude)\n",
    "    \n",
    "    # Marginal Discrete Wavelet Transform (mDWT)\n",
    "    coeffs = pywt.wavedec(signal, 'db4', level=4)\n",
    "    mdwt = np.sum([np.sum(np.abs(c)) for c in coeffs])\n",
    "    mdwt_std = np.std([np.sum(np.abs(c)) for c in coeffs])\n",
    "    \n",
    "    # Temporal Difference (TD)\n",
    "    td = np.sum(np.abs(np.diff(signal)))\n",
    "    td_std = np.std(np.abs(np.diff(signal)))\n",
    "    \n",
    "    # Mean Absolute Value Slope (MAVS)\n",
    "    mavs = np.mean(np.abs(np.diff(signal)))\n",
    "    mavs_std = np.std(np.abs(np.diff(signal)))\n",
    "    \n",
    "    # Return the metrics as a dictionary\n",
    "    metrics = {\n",
    "        \"MAV\": mav, \"MAV_STD\": mav_std,\n",
    "        \"IAV\": iav, \"IAV_STD\": iav_std,\n",
    "        \"RMS\": rms, \"RMS_STD\": rms_std,\n",
    "        \"WL\": wl, \"WL_STD\": wl_std,\n",
    "        \"ZC\": zc, \"ZC_STD\": zc_std,\n",
    "        \"SSC\": ssc, \"SSC_STD\": ssc_std,\n",
    "        \"VAR\": var, \"VAR_STD\": var_std,\n",
    "        \"CoV\": cov, \"CoV_STD\": cov_std,\n",
    "        \"MNF\": mnf, \"MNF_STD\": mnf_std,\n",
    "        \"mDWT\": mdwt, \"mDWT_STD\": mdwt_std,\n",
    "        \"TD\": td, \"TD_STD\": td_std,\n",
    "        \"MAVS\": mavs, \"MAVS_STD\": mavs_std\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def calculate_emg_metrics_cv(signal, fs=2000):\n",
    "    \"\"\"\n",
    "    Calculates various metrics for an EMG signal, including their coefficient of variation (CV).\n",
    "\n",
    "    Parameters:\n",
    "    - signal: NumPy array containing the EMG signal.\n",
    "    - fs: Sampling frequency in Hz (default: 2000 Hz).\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with the computed metrics and their CVs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if signal.ndim == 2:\n",
    "            metrics_per_channel = [calculate_emg_metrics(signal[:, ch], fs) for ch in range(signal.shape[1])]\n",
    "            averaged_metrics = {key: np.mean([m[key] for m in metrics_per_channel]) for key in metrics_per_channel[0]}\n",
    "            cv_metrics = {}\n",
    "            for key in averaged_metrics:\n",
    "                values = np.array([m[key] for m in metrics_per_channel])\n",
    "                mean_val = np.mean(values)\n",
    "                std_val = np.std(values)\n",
    "                cv = (std_val / mean_val) * 100 if mean_val != 0 else np.nan\n",
    "                cv_metrics[key + \"_CV\"] = cv\n",
    "            return {**averaged_metrics, **cv_metrics}\n",
    "\n",
    "        abs_signal = np.abs(signal)\n",
    "        diff_signal = np.diff(signal)\n",
    "        diff_abs_signal = np.abs(diff_signal)\n",
    "\n",
    "        def compute_cv(values):\n",
    "            mean_val = np.mean(values)\n",
    "            std_val = np.std(values)\n",
    "            return (std_val / mean_val) * 100 if mean_val != 0 else np.nan\n",
    "\n",
    "        metrics = {\n",
    "            \"MAV\": np.mean(abs_signal),\n",
    "            \"IAV\": np.sum(abs_signal),\n",
    "            \"RMS\": np.sqrt(np.mean(signal**2)),\n",
    "            \"WL\": np.sum(diff_abs_signal),\n",
    "            \"ZC\": np.sum(np.diff(np.sign(signal)) != 0),\n",
    "            \"SSC\": np.sum((diff_signal[1:] * diff_signal[:-1]) < 0),\n",
    "            \"VAR\": np.var(signal),\n",
    "            \"CoV\": (np.std(signal) / np.mean(signal)) if np.mean(signal) != 0 else 0,\n",
    "            \"TD\": np.sum(diff_abs_signal),\n",
    "            \"MAVS\": np.mean(diff_abs_signal),\n",
    "            \"MNP\": np.mean(signal**2),\n",
    "        }\n",
    "\n",
    "        # Espectro\n",
    "        freqs = np.fft.rfftfreq(len(signal), d=1/fs)\n",
    "        fft_magnitude = np.abs(np.fft.rfft(signal))\n",
    "        metrics[\"MNF\"] = np.sum(freqs * fft_magnitude) / np.sum(fft_magnitude) if np.sum(fft_magnitude) != 0 else 0\n",
    "\n",
    "        # Wavelet\n",
    "        coeffs = pywt.wavedec(signal, 'db4', level=4)\n",
    "        mdwt_values = np.array([np.sum(np.abs(c)) for c in coeffs])\n",
    "        metrics[\"mDWT\"] = np.sum(mdwt_values)\n",
    "\n",
    "        # Kurtosis\n",
    "        std_signal = np.std(signal)\n",
    "        metrics[\"Kurt\"] = np.mean((signal - np.mean(signal)) ** 4) / (std_signal ** 4) if std_signal != 0 else 0\n",
    "\n",
    "        # Calcular CVs\n",
    "        cv_metrics = {\n",
    "            \"MAV_CV\": compute_cv(abs_signal),\n",
    "            \"IAV_CV\": compute_cv(abs_signal),\n",
    "            \"RMS_CV\": compute_cv(signal),\n",
    "            \"WL_CV\": compute_cv(diff_abs_signal),\n",
    "            \"ZC_CV\": compute_cv(np.diff(np.sign(signal)) != 0),\n",
    "            \"SSC_CV\": compute_cv((diff_signal[1:] * diff_signal[:-1]) < 0),\n",
    "            \"VAR_CV\": compute_cv(signal),\n",
    "            \"TD_CV\": compute_cv(diff_abs_signal),\n",
    "            \"MAVS_CV\": compute_cv(diff_abs_signal),\n",
    "            \"MNP_CV\": compute_cv(signal**2),\n",
    "            \"MNF_CV\": compute_cv(freqs * fft_magnitude) if np.sum(fft_magnitude) != 0 else np.nan,\n",
    "            \"mDWT_CV\": compute_cv(mdwt_values),\n",
    "            \"Kurt_CV\": 0  # No se calcula CV de kurtosis porque es escalar\n",
    "        }\n",
    "\n",
    "        return {**metrics, **cv_metrics}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_emg_metrics_cv: {e}\")\n",
    "        return {}\n",
    "\n",
    "import numpy as np\n",
    "import pywt\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "import numpy as np\n",
    "import pywt\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "def calculate_emg_metrics_means(signal, fs=2000):\n",
    "    \"\"\"\n",
    "    Calculates averaged EMG metrics for a single or multi-channel signal.\n",
    "    Computes the Coefficient of Variation (CoV) for each metric.\n",
    "\n",
    "    Parameters:\n",
    "    - signal: np.ndarray. EMG signal, either 1D (samples) or 2D (samples x channels).\n",
    "    - fs: int. Sampling frequency in Hz (default: 2000 Hz).\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary with EMG metrics and their CoV.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if signal.ndim == 2:\n",
    "            all_metrics = [calculate_emg_metrics_means(signal[:, ch], fs) for ch in range(signal.shape[1])]\n",
    "            averaged = {k: np.mean([m[k] for m in all_metrics]) for k in all_metrics[0]}\n",
    "            return averaged\n",
    "\n",
    "        # Single-channel processing\n",
    "        abs_signal = np.abs(signal)\n",
    "        diff_signal = np.diff(signal)\n",
    "        diff_abs_signal = np.abs(diff_signal)\n",
    "        mean_signal = np.mean(signal)\n",
    "        std_signal = np.std(signal)\n",
    "\n",
    "        freqs = np.fft.rfftfreq(len(signal), d=1/fs)\n",
    "        fft_magnitude = np.abs(np.fft.rfft(signal))\n",
    "\n",
    "        coeffs = pywt.wavedec(signal, 'db4', level=4)\n",
    "        mdwt_values = np.array([np.sum(np.abs(c)) for c in coeffs])\n",
    "\n",
    "        def cov(x):\n",
    "            mu = np.mean(x)\n",
    "            sigma = np.std(x)\n",
    "            return sigma / mu if mu != 0 else 0\n",
    "\n",
    "        metrics = {\n",
    "            \"MAV\": np.mean(abs_signal),\n",
    "            # \"MAV_CoV\": cov(abs_signal),\n",
    "\n",
    "            \"IAV\": np.sum(abs_signal),\n",
    "            # \"IAV_CoV\": cov(abs_signal),\n",
    "\n",
    "            \"RMS\": np.sqrt(np.mean(signal**2)),\n",
    "            # \"RMS_CoV\": cov(signal),\n",
    "\n",
    "            \"WL\": np.sum(diff_abs_signal),\n",
    "            # \"WL_CoV\": cov(diff_abs_signal),\n",
    "\n",
    "            \"ZC\": np.sum(np.diff(np.sign(signal)) != 0),\n",
    "            # \"ZC_CoV\": cov(np.diff(np.sign(signal)) != 0),\n",
    "\n",
    "            \"SSC\": np.sum((diff_signal[1:] * diff_signal[:-1]) < 0),\n",
    "            # \"SSC_CoV\": cov((diff_signal[1:] * diff_signal[:-1]) < 0),\n",
    "\n",
    "            \"VAR\": np.var(signal),\n",
    "            # \"VAR_CoV\": cov(signal),\n",
    "\n",
    "            # \"CoV\": (std_signal / mean_signal) if mean_signal != 0 else 0,\n",
    "\n",
    "            \"TD\": np.sum(diff_abs_signal),\n",
    "            # \"TD_CoV\": cov(diff_abs_signal),\n",
    "\n",
    "            \"MAVS\": np.mean(diff_abs_signal),\n",
    "            # \"MAVS_CoV\": cov(diff_abs_signal),\n",
    "\n",
    "            \"MNP\": np.mean(signal**2),\n",
    "            # \"MNP_CoV\": cov(signal**2),\n",
    "\n",
    "            \"MNF\": np.sum(freqs * fft_magnitude) / np.sum(fft_magnitude) if np.sum(fft_magnitude) != 0 else 0,\n",
    "            # \"MNF_CoV\": cov(freqs * fft_magnitude) if np.sum(fft_magnitude) != 0 else 0,\n",
    "\n",
    "            \"mDWT\": np.sum(mdwt_values),\n",
    "            # \"mDWT_CoV\": cov(mdwt_values),\n",
    "\n",
    "            \"Kurt\": kurtosis(signal, fisher=False),\n",
    "            # \"Kurt_CoV\": 0  # CoV no aplica al escalar de curtosis\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_emg_metrics_means: {e}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf09f7",
   "metadata": {},
   "source": [
    "## Combined dataframe for all database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database name\n",
    "database = 'DB4'\n",
    "\n",
    "# Full path to the database folder\n",
    "data_path = os.path.abspath(os.path.join('data', database))\n",
    "\n",
    "# List of subjects, generating names from 's1' to 's10'\n",
    "subjects = [f's{i}' for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bffcf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store all generated DataFrames\n",
    "all_dataframes = []\n",
    "\n",
    "# Look for folders matching the pattern \"s + number\" or \"Subject + number\"\n",
    "for folder in os.listdir(data_path):\n",
    "    if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "        folder_path = os.path.join(data_path, folder)\n",
    "        \n",
    "        # Iterate over all .mat files in the folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.mat'):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                \n",
    "                # Attempt to load the .mat file\n",
    "                try:\n",
    "                    mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_name}: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Attempt to process the file with src.build_dataframe\n",
    "                try:\n",
    "                    test_df, grasps = src.build_dataframe(\n",
    "                        mat_file=mat_data,\n",
    "                        database=database,\n",
    "                        filename=file_name,\n",
    "                        rectify=False,\n",
    "                        normalize=True\n",
    "                    )\n",
    "                    \n",
    "                    # Add a column with the subject name (folder) to the DataFrame\n",
    "                    test_df['subject'] = folder  \n",
    "                    \n",
    "                    # Append the processed DataFrame to the list\n",
    "                    all_dataframes.append(test_df)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_name}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "# Concatenate all DataFrames into a single one if data is available\n",
    "if all_dataframes:  \n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Display the combined DataFrame\n",
    "    print(\"\\n Combined DataFrame:\")\n",
    "    display(combined_df)  \n",
    "\n",
    "else:\n",
    "    print(\"Warning: No DataFrames were generated. Check the input data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211ba8b",
   "metadata": {},
   "source": [
    "## Metrics with std for every channel, for every grasp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c008ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_data = []\n",
    "\n",
    "# Iterate over each subject and each identified movement (relabeled or stimulus)\n",
    "for (subject, relabeled,re_repetition), group in combined_df.groupby(['subject', 'relabeled','re_repetition']):  # Change 'relabeled' to 'stimulus' if needed\n",
    "    # Iterate over each EMG channel\n",
    "    for channel in group.columns:  # Loop through all DataFrame columns\n",
    "        if channel.startswith('Channel'):  # Filter only EMG signal columns\n",
    "            # Get the signal values for the current channel\n",
    "            channel_signal = group[channel].values\n",
    "            \n",
    "            # Compute EMG signal metrics for the current channel\n",
    "            metrics = calculate_emg_metrics_means(channel_signal)\n",
    "            \n",
    "            # Append metadata and computed metrics to the list\n",
    "            metrics_data.append({\n",
    "                \"subject\": subject,  # Subject identification\n",
    "                \"relabeled\": relabeled,  # Movement identification (relabeled or stimulus)\n",
    "                \"channel\": channel,  # EMG channel\n",
    "                're_reptition': re_repetition,  # Repetition number\n",
    "                **metrics  # Unpack all computed metrics\n",
    "            })\n",
    "\n",
    "# Create a DataFrame containing all the obtained metrics\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "# Reorder columns for better visualization (optional)\n",
    "column_order = [\"subject\", \"relabeled\", \"channel\"] + list(metrics.keys())\n",
    "metrics_df = metrics_df[column_order]\n",
    "\n",
    "# Display the DataFrame with the computed metrics\n",
    "print(\"\\nMetrics DataFrame by Channel, Subject, and Relabeled:\")\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ad3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'channel' column to group data by subject and movement type\n",
    "grouped_df = metrics_df.drop(columns=['channel'])\n",
    "display(grouped_df)\n",
    "\n",
    "# Compute the mean value of each metric grouped by subject and movement\n",
    "df_mean = grouped_df.groupby(['subject', 'relabeled']).mean()\n",
    "\n",
    "# Compute the standard deviation of each metric grouped by subject and movement\n",
    "df_std = grouped_df.groupby(['subject', 'relabeled']).std()\n",
    "\n",
    "# Rename columns to indicate they contain mean values\n",
    "df_mean.columns = [f\"{col} mean\" for col in df_mean.columns]\n",
    "\n",
    "# Rename columns to indicate they contain standard deviation values\n",
    "df_std.columns = [f\"{col} std\" for col in df_std.columns]\n",
    "\n",
    "# Merge the mean and standard deviation DataFrames into a single DataFrame\n",
    "df_result = df_mean.merge(df_std, on=['subject', 'relabeled']).reset_index()\n",
    "\n",
    "# Display the final DataFrame with aggregated metrics\n",
    "display(df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67377c4b",
   "metadata": {},
   "source": [
    "### Relabeled Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ee51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_labels = [55,2,14,28,32,0]\n",
    "dataframe_windowing = grouped_df[grouped_df['relabeled'].isin(filtered_labels)]\n",
    "dataframe_windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a797b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_data = []\n",
    "\n",
    "# Definir columnas EMG (que comienzan con 'Channel')\n",
    "emg_columns = [col for col in combined_df.columns if col.startswith('Channel')]\n",
    "\n",
    "# Iterar sobre cada sujeto y cada movimiento identificado\n",
    "for (subject, relabeled), group in combined_df.groupby(['subject', 'relabeled']):\n",
    "    for channel in emg_columns:\n",
    "        channel_signal = group[channel].values\n",
    "        metrics = calculate_emg_metrics_means(channel_signal)\n",
    "\n",
    "        metrics_data.append({\n",
    "            \"subject\": subject,\n",
    "            \"relabeled\": relabeled,\n",
    "            \"channel\": channel,\n",
    "            **metrics\n",
    "        })\n",
    "\n",
    "# Crear DataFrame de métricas por canal\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "# Filtrar por clases si es necesario\n",
    "metrics_df = metrics_df[metrics_df['relabeled'].isin(filtered_labels)]\n",
    "\n",
    "# Calcular promedio de métricas por sujeto y clase (sin incluir columna 'channel')\n",
    "avg_metrics_df = metrics_df.drop(columns=[\"channel\"]).groupby(['subject', 'relabeled']).mean().reset_index()\n",
    "\n",
    "# Mostrar DataFrame promediado\n",
    "print(\"\\nPromedio de métricas por Subject y Relabeled (promedio de canales):\")\n",
    "display(avg_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac73e820",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots_Windowed(fm, window_length, overlap, target_channels, cutoff_freq, envelope_type, filtered_labels):\n",
    "    \"\"\"\n",
    "    Función para graficar las ventanas de múltiples canales de EMG.\n",
    "\n",
    "    Parámetros:\n",
    "    - fm: Frecuencia de muestreo en Hz.\n",
    "    - window_length: Longitud de la ventana en muestras.\n",
    "    - overlap: Porcentaje de superposición entre ventanas.\n",
    "    - target_channels: Lista de nombres de canales a graficar.\n",
    "    \"\"\"\n",
    "    all_dataframes = []\n",
    "\n",
    "    for folder in os.listdir(data_path):\n",
    "        if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "            folder_path = os.path.join(data_path, folder)\n",
    "            \n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith('.mat'):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    \n",
    "                    try:\n",
    "                        mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading {file_name}: {str(e)}\")\n",
    "                        continue\n",
    "                    \n",
    "                    df_norm, grasps_etiquetados = src.build_dataframe(\n",
    "                        mat_file=mat_data,\n",
    "                        database=database,\n",
    "                        filename=file_name,\n",
    "                        rectify=False,\n",
    "                        normalize=True\n",
    "                    )\n",
    "                    df_norm = df_norm[df_norm['relabeled'].isin(filtered_labels)]\n",
    "\n",
    "                    # Verificar que todos los canales están disponibles\n",
    "                    missing_channels = [ch for ch in target_channels if ch not in df_norm.columns]\n",
    "                    if missing_channels:\n",
    "                        print(f\"Canales faltantes en {file_name}: {missing_channels}, omitiendo.\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Aplicar envelope a todos los canales de interés\n",
    "                    envelope_df = src.get_envelope_lowpass(df_norm[target_channels], fm=fm, cutoff_freq=cutoff_freq, envelope_type=envelope_type)\n",
    "                    \n",
    "                    meta_columns = [\"Time (s)\", \"subject\", \"re_repetition\", \"stimulus\", \"relabeled\"]\n",
    "                    result_df = pd.concat([envelope_df, df_norm[meta_columns]], axis=1)\n",
    "\n",
    "                    for grasp in grasps_etiquetados:\n",
    "                        try:\n",
    "                            grasp_df = result_df[result_df['stimulus'] == grasp]\n",
    "                            if grasp_df.empty:\n",
    "                                continue\n",
    "                            \n",
    "                            ventanas = src.create_windows_with_overlap(grasp_df, window_length, overlap)\n",
    "                            ventanas_df = [pd.DataFrame(ventana, columns=target_channels) for ventana in ventanas if len(ventana) == window_length]\n",
    "\n",
    "                            if not ventanas_df:\n",
    "                                continue\n",
    "                            \n",
    "                            all_dataframes.extend(ventanas_df)\n",
    "\n",
    "                            # Graficar la primera ventana para todos los canales juntos\n",
    "                            plt.figure(figsize=(12, 6))\n",
    "                            tiempo = np.linspace(0, window_length / fm, window_length)\n",
    "                            for channel in target_channels:\n",
    "                                plt.plot(tiempo, ventanas_df[0][channel], label=channel)\n",
    "                            \n",
    "                            plt.xlabel(\"Tiempo (s)\")\n",
    "                            plt.ylabel(\"Amplitud EMG (envelope)\")\n",
    "                            plt.title(f\"{file_name} - Grasp {grasp} - Todos los canales\")\n",
    "                            plt.legend(loc='upper right')\n",
    "                            plt.grid(True)\n",
    "                            plt.tight_layout()\n",
    "                            plt.show()\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing grasp {grasp}: {str(e)}\")\n",
    "                            continue\n",
    "\n",
    "\n",
    "def envelope_raw(fm, window_length, overlap, target_channel, cutoff_freq,envelope_type, filtered_labels):\n",
    "    \"\"\"\n",
    "    Función para graficar las ventanas de un canal específico de EMG.\n",
    "    \n",
    "    Parámetros:\n",
    "    - fm: Frecuencia de muestreo en Hz.\n",
    "    - window_length: Longitud de la ventana en muestras.\n",
    "    - overlap: Porcentaje de superposición entre ventanas.\n",
    "    - target_channel: Nombre del canal objetivo a graficar.\n",
    "    \"\"\"\n",
    "# Lista para almacenar todos los DataFrames generados\n",
    "    all_dataframes = []\n",
    "    # Buscar carpetas que coincidan con el patrón \"s + número\" o \"Subject + número\"\n",
    "    for folder in os.listdir(data_path):\n",
    "        if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "            folder_path = os.path.join(data_path, folder)\n",
    "            \n",
    "            # Iterar sobre todos los archivos .mat en la carpeta\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith('.mat'):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    \n",
    "                    # Intentar cargar el archivo .mat\n",
    "                    try:\n",
    "                        mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading {file_name}: {str(e)}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Procesar el archivo con src.build_dataframe\n",
    "                    df_norm, grasps_etiquetados = src.build_dataframe(\n",
    "                        mat_file=mat_data,\n",
    "                        database=database,\n",
    "                        filename=file_name,\n",
    "                        rectify=False,\n",
    "                        normalize=True\n",
    "                    )\n",
    "                    df_norm = df_norm[df_norm['relabeled'].isin(filtered_labels)]\n",
    "                    print(f\"Columnas disponibles en {file_name}: {df_norm.columns.tolist()}\")\n",
    "\n",
    "                    # Verificar si el canal objetivo está presente en el DataFrame\n",
    "                    if target_channel not in df_norm.columns:\n",
    "                        print(f\"{target_channel} no encontrado en {file_name}, omitiendo.\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Guardar la señal cruda antes de aplicar el envelope\n",
    "                    raw_signal = df_norm[[target_channel]].copy()\n",
    "                    \n",
    "                    # Aplicar extracción del envelope solo a Channel_10\n",
    "                    envelope_df = src.get_envelope_lowpass(df_norm[[target_channel]], fm=fm, cutoff_freq=cutoff_freq, envelope_type=envelope_type)  \n",
    "                    \n",
    "                    # Conservar columnas meta\n",
    "                    meta_columns = [\"Time (s)\", \"subject\", \"re_repetition\", \"stimulus\", \"relabeled\"]\n",
    "                    # Combinar señal envolvente con metadatos\n",
    "                    result_df = pd.concat([envelope_df, df_norm[meta_columns]], axis=1)\n",
    "                    \n",
    "                    # Procesar cada grasp\n",
    "                    for grasp in grasps_etiquetados:\n",
    "                        try:\n",
    "                            print(f\"\\nProcessing Grasp {grasp}:\")\n",
    "                            grasp_df = result_df[result_df['stimulus'] == grasp]\n",
    "                            raw_grasp_df = raw_signal[df_norm['stimulus'] == grasp]  # Datos crudos correspondientes\n",
    "                            \n",
    "                            if grasp_df.empty:\n",
    "                                print(f\"No hay datos para el grasp {grasp} en {file_name}.\")\n",
    "                                continue\n",
    "                            \n",
    "                            # Crear ventanas con overlap a partir del DataFrame filtrado\n",
    "                            ventanas = src.create_windows_with_overlap(grasp_df, window_length, overlap)\n",
    "                            ventanas_raw = src.create_windows_with_overlap(raw_grasp_df, window_length, overlap)\n",
    "                            \n",
    "                            # Guardar cada ventana como un DataFrame individual, solo si tiene el tamaño completo\n",
    "                            ventanas_df = [pd.DataFrame(ventana, columns=[target_channel]) for ventana in ventanas if len(ventana) == window_length]\n",
    "                            ventanas_raw_df = [pd.DataFrame(ventana, columns=[target_channel]) for ventana in ventanas_raw if len(ventana) == window_length]\n",
    "                            \n",
    "                            if not ventanas_df or not ventanas_raw_df:\n",
    "                                print(f\"No hay ventanas válidas para el grasp {grasp} en {file_name}.\")\n",
    "                                continue\n",
    "                            \n",
    "                            # Agregar a la lista general de DataFrames\n",
    "                            all_dataframes.extend(ventanas_df)\n",
    "                            \n",
    "                            # Graficar la primera ventana de este grasp con ambas señales\n",
    "                            plt.figure(figsize=(12, 5))\n",
    "                            tiempo = np.linspace(0, window_length / fm, window_length)\n",
    "                            \n",
    "                            # Graficar señal cruda\n",
    "                            plt.plot(tiempo, ventanas_raw_df[0][target_channel], color='c', alpha=0.7, \n",
    "                                    label=f\"{target_channel} - Señal Cruda\")\n",
    "                            \n",
    "                            # Graficar envolvente\n",
    "                            plt.plot(tiempo, ventanas_df[0][target_channel], color='m', linewidth=2, \n",
    "                                    label=f\"{target_channel} - Envolvente\")\n",
    "                            \n",
    "                            plt.xlabel(\"Tiempo (s)\")\n",
    "                            plt.ylabel(\"Amplitud\")\n",
    "                            plt.title(f\"{file_name} - Grasp {grasp} - {target_channel}\")\n",
    "                            plt.legend()\n",
    "                            plt.grid(True)\n",
    "                            plt.tight_layout()\n",
    "                            plt.show()\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing grasp {grasp}: {str(e)}\")\n",
    "                            continue\n",
    "\n",
    "def plots_Windowed_all_channels(fm, window_length, overlap, cutoff_freq, envelope_type, filtered_labels):\n",
    "    \"\"\"\n",
    "    Función para graficar las ventanas de todos los canales EMG en un único plot.\n",
    "    \n",
    "    Parámetros:\n",
    "    - fm: Frecuencia de muestreo en Hz.\n",
    "    - window_length: Longitud de la ventana en muestras.\n",
    "    - overlap: Porcentaje de superposición entre ventanas.\n",
    "    - cutoff_freq: Frecuencia de corte del filtro.\n",
    "    - envelope_type: Tipo de envolvente (1: RMS, 2: lowpass rectificado, etc.).\n",
    "    - filtered_labels: Lista de etiquetas que se desean mantener.\n",
    "    \"\"\"\n",
    "\n",
    "    for folder in os.listdir(data_path):\n",
    "        if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "            folder_path = os.path.join(data_path, folder)\n",
    "\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith('.mat'):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "                    try:\n",
    "                        mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading {file_name}: {str(e)}\")\n",
    "                        continue\n",
    "\n",
    "                    df_norm, grasps_etiquetados = src.build_dataframe(\n",
    "                        mat_file=mat_data,\n",
    "                        database=database,\n",
    "                        filename=file_name,\n",
    "                        rectify=False,\n",
    "                        normalize=True\n",
    "                    )\n",
    "                    df_norm = df_norm[df_norm['relabeled'].isin(filtered_labels)]\n",
    "\n",
    "                    # Detectar todos los canales EMG válidos\n",
    "                    emg_channels = [col for col in df_norm.columns if col.startswith(\"Channel\")]\n",
    "\n",
    "                    # Procesar cada grasp\n",
    "                    for grasp in grasps_etiquetados:\n",
    "                        try:\n",
    "                            print(f\"\\nProcesando grasp {grasp} en {file_name}...\")\n",
    "\n",
    "                            # Filtrar por grasp\n",
    "                            grasp_df = df_norm[df_norm[\"stimulus\"] == grasp]\n",
    "                            if grasp_df.empty:\n",
    "                                continue\n",
    "\n",
    "                            # Obtener envolventes de todos los canales\n",
    "                            envelope_df = src.get_envelope_lowpass(grasp_df[emg_channels], fm=fm, cutoff_freq=cutoff_freq, envelope_type=envelope_type)\n",
    "\n",
    "                            # Crear ventanas\n",
    "                            ventanas = src.create_windows_with_overlap(envelope_df, window_length, overlap)\n",
    "                            ventanas_df = [pd.DataFrame(ventana, columns=emg_channels) for ventana in ventanas if len(ventana) == window_length]\n",
    "\n",
    "                            if not ventanas_df:\n",
    "                                continue\n",
    "\n",
    "                            # Tomar la primera ventana y graficar todos los canales en un solo plot\n",
    "                            plt.figure(figsize=(12, 6))\n",
    "                            tiempo = np.linspace(0, window_length / fm, window_length)\n",
    "                            for channel in emg_channels:\n",
    "                                plt.plot(tiempo, ventanas_df[0][channel], label=channel)\n",
    "\n",
    "                            plt.title(f\"{file_name} - Grasp {grasp} - Todos los canales\")\n",
    "                            plt.xlabel(\"Tiempo (s)\")\n",
    "                            plt.ylabel(\"Amplitud EMG (envolvente)\")\n",
    "                            plt.legend(ncol=4, fontsize='small')\n",
    "                            plt.grid(True)\n",
    "                            plt.tight_layout()\n",
    "                            plt.show()\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error procesando grasp {grasp}: {str(e)}\")\n",
    "                            continue\n",
    "\n",
    "def envelope_raw_all_channels(fm, window_length, overlap, cutoff_freq, envelope_type, filtered_labels):\n",
    "    \"\"\"\n",
    "    Función para graficar la señal cruda y la envolvente de todos los canales EMG disponibles.\n",
    "    \n",
    "    Parámetros:\n",
    "    - fm: Frecuencia de muestreo en Hz.\n",
    "    - window_length: Longitud de la ventana en muestras.\n",
    "    - overlap: Porcentaje de superposición entre ventanas.\n",
    "    - cutoff_freq: Frecuencia de corte para el filtro de envolvente.\n",
    "    - envelope_type: Tipo de envolvente (0 = rectificada, 1 = RMS).\n",
    "    - filtered_labels: Lista de etiquetas de grasp a conservar.\n",
    "    \"\"\"\n",
    "    for folder in os.listdir(data_path):\n",
    "        if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "            folder_path = os.path.join(data_path, folder)\n",
    "            \n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith('.mat'):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    \n",
    "                    try:\n",
    "                        mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading {file_name}: {str(e)}\")\n",
    "                        continue\n",
    "                    \n",
    "                    df_norm, grasps_etiquetados = src.build_dataframe(\n",
    "                        mat_file=mat_data,\n",
    "                        database=database,\n",
    "                        filename=file_name,\n",
    "                        rectify=False,\n",
    "                        normalize=True\n",
    "                    )\n",
    "                    df_norm = df_norm[df_norm['relabeled'].isin(filtered_labels)]\n",
    "\n",
    "                    # Detectar columnas de EMG\n",
    "                    emg_columns = [col for col in df_norm.columns if col.startswith('Channel')]\n",
    "                    if not emg_columns:\n",
    "                        print(f\"No se encontraron canales EMG en {file_name}, omitiendo.\")\n",
    "                        continue\n",
    "\n",
    "                    print(f\"{file_name}: canales EMG detectados: {emg_columns}\")\n",
    "                    \n",
    "                    # Señal cruda\n",
    "                    raw_signal = df_norm[emg_columns].copy()\n",
    "                    \n",
    "                    # Señal con envolvente aplicada\n",
    "                    envelope_df = src.get_envelope_lowpass(df_norm[emg_columns], fm=fm, cutoff_freq=cutoff_freq, envelope_type=envelope_type)\n",
    "\n",
    "                    meta_columns = [\"Time (s)\", \"subject\", \"re_repetition\", \"stimulus\", \"relabeled\"]\n",
    "                    result_df = pd.concat([envelope_df, df_norm[meta_columns]], axis=1)\n",
    "\n",
    "                    for grasp in grasps_etiquetados:\n",
    "                        try:\n",
    "                            print(f\"\\nProcesando grasp {grasp} en {file_name}...\")\n",
    "                            grasp_df = result_df[result_df['stimulus'] == grasp]\n",
    "                            raw_grasp_df = raw_signal[df_norm['stimulus'] == grasp]\n",
    "\n",
    "                            if grasp_df.empty or raw_grasp_df.empty:\n",
    "                                print(f\"No hay datos válidos para grasp {grasp} en {file_name}.\")\n",
    "                                continue\n",
    "\n",
    "                            ventanas = src.create_windows_with_overlap(grasp_df, window_length, overlap)\n",
    "                            ventanas_raw = src.create_windows_with_overlap(raw_grasp_df, window_length, overlap)\n",
    "\n",
    "                            ventanas_df = [pd.DataFrame(v, columns=emg_columns) for v in ventanas if len(v) == window_length]\n",
    "                            ventanas_raw_df = [pd.DataFrame(v, columns=emg_columns) for v in ventanas_raw if len(v) == window_length]\n",
    "\n",
    "                            if not ventanas_df or not ventanas_raw_df:\n",
    "                                print(f\"No hay ventanas válidas para el grasp {grasp}.\")\n",
    "                                continue\n",
    "\n",
    "                            # Graficar la primera ventana\n",
    "                            tiempo = np.linspace(0, window_length / fm, window_length)\n",
    "                            plt.figure(figsize=(14, 6))\n",
    "\n",
    "                            for ch in emg_columns:\n",
    "                                plt.plot(tiempo, ventanas_raw_df[0][ch], alpha=0.5, label=f\"{ch} Cruda\")\n",
    "                                plt.plot(tiempo, ventanas_df[0][ch], linewidth=2, label=f\"{ch} Envolvente\")\n",
    "\n",
    "                            plt.xlabel(\"Tiempo (s)\")\n",
    "                            plt.ylabel(\"Amplitud\")\n",
    "                            plt.title(f\"{file_name} - Grasp {grasp} - Todos los canales\")\n",
    "                            plt.legend(ncol=2, fontsize='small')\n",
    "                            plt.grid(True)\n",
    "                            plt.tight_layout()\n",
    "                            plt.show()\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error al procesar grasp {grasp}: {str(e)}\")\n",
    "                            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d1dc3",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f1ca28",
   "metadata": {},
   "source": [
    "- Raw Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1868306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots_Windowed(\n",
    "#     fm=2000,\n",
    "#     window_length=200,\n",
    "#     overlap=0,\n",
    "#     target_channels=emg_columns,  \n",
    "#     cutoff_freq=0.6,\n",
    "#     envelope_type=1,\n",
    "#     filtered_labels=filtered_labels\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc2398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots_Windowed(\n",
    "#     fm=2000,\n",
    "#     window_length=400,\n",
    "#     overlap=0,\n",
    "#     target_channels=emg_columns,  \n",
    "#     cutoff_freq=0.6,\n",
    "#     envelope_type=1,\n",
    "#     filtered_labels=filtered_labels\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f911d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots_Windowed(\n",
    "#     fm=2000,\n",
    "#     window_length=600,\n",
    "#     overlap=0,\n",
    "#     target_channels=emg_columns, \n",
    "#     cutoff_freq=0.6,\n",
    "#     envelope_type=1,\n",
    "#     filtered_labels=filtered_labels\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e189f3ee",
   "metadata": {},
   "source": [
    "- Envelope signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c3d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = 2000\n",
    "window_length = 200\n",
    "overlap = 0\n",
    "cutoff_freq = 0.6\n",
    "envelope_type = 1\n",
    "\n",
    "envelope_raw_all_channels(\n",
    "    fm=fm,\n",
    "    window_length=window_length,\n",
    "    overlap=overlap,\n",
    "    cutoff_freq=cutoff_freq,\n",
    "    envelope_type=envelope_type,\n",
    "    filtered_labels=filtered_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d54f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fm = 2000\n",
    "# window_length = 400\n",
    "# overlap = 0\n",
    "# cutoff_freq = 0.6\n",
    "# envelope_type = 1\n",
    "\n",
    "# envelope_raw_all_channels(\n",
    "#     fm=fm,\n",
    "#     window_length=window_length,\n",
    "#     overlap=overlap,\n",
    "#     cutoff_freq=cutoff_freq,\n",
    "#     envelope_type=envelope_type,\n",
    "#     filtered_labels=filtered_labels\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fm = 2000\n",
    "# window_length = 600\n",
    "# overlap = 0\n",
    "# cutoff_freq = 0.6\n",
    "# envelope_type = 1\n",
    "\n",
    "\n",
    "# envelope_raw_all_channels(\n",
    "#     fm=fm,\n",
    "#     window_length=window_length,\n",
    "#     overlap=overlap,\n",
    "#     cutoff_freq=cutoff_freq,\n",
    "#     envelope_type=envelope_type,\n",
    "#     filtered_labels=filtered_labels\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3eee23",
   "metadata": {},
   "source": [
    "## Windowed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5d38ad",
   "metadata": {},
   "source": [
    "- 300 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8183cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = 2000\n",
    "overlap = 0\n",
    "cutoff_freq = 0.6\n",
    "envelope_type = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e56be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_length = 600\n",
    "# # Lista para almacenar las métricas de todas las ventanas\n",
    "# all_metrics = []\n",
    "\n",
    "# # Obtener nombres de los canales EMG (suponiendo que empiezan por 'Channel')\n",
    "# emg_columns = [col for col in combined_df.columns if col.startswith('Channel')]\n",
    "\n",
    "# for folder in os.listdir(data_path):\n",
    "#     if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "#         folder_path = os.path.join(data_path, folder)\n",
    "\n",
    "#         for file_name in os.listdir(folder_path):\n",
    "#             if file_name.endswith('.mat'):\n",
    "#                 file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "#                 try:\n",
    "#                     mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error loading {file_name}: {str(e)}\")\n",
    "#                     continue\n",
    "\n",
    "#                 test_df, grasps = src.build_dataframe(\n",
    "#                     mat_file=mat_data,\n",
    "#                     database=database,\n",
    "#                     filename=file_name,\n",
    "#                     rectify=False,\n",
    "#                     normalize=True\n",
    "#                 )\n",
    "\n",
    "#                 test_df = test_df[test_df['relabeled'].isin(filtered_labels)]\n",
    "\n",
    "#                 # Extraer la envolvente de todos los canales EMG\n",
    "#                 envelope_df = src.get_envelope_lowpass(test_df[emg_columns], fm=fm, cutoff_freq=0.6, envelope_type=1)\n",
    "\n",
    "#                 # Añadir columnas meta\n",
    "#                 meta_columns = [\"Time (s)\", \"subject\", \"re_repetition\", \"stimulus\", \"relabeled\"]\n",
    "#                 result_df = pd.concat([envelope_df, test_df[meta_columns]], axis=1)\n",
    "\n",
    "#                 for grasp in grasps:\n",
    "#                     grasp_df = result_df[result_df['stimulus'] == grasp]\n",
    "\n",
    "#                     if grasp_df.empty:\n",
    "#                         print(f\"No hay datos para el grasp {grasp} en {file_name}.\")\n",
    "#                         continue\n",
    "\n",
    "#                     for channel in emg_columns:\n",
    "#                         ventanas = src.create_windows_with_overlap(grasp_df[[channel, 'relabeled']], window_length, overlap)\n",
    "\n",
    "#                         for i, ventana in enumerate(ventanas):\n",
    "#                             if len(ventana) == window_length:\n",
    "#                                 signal = ventana[channel].values\n",
    "#                                 metrics = calculate_emg_metrics_means(signal)\n",
    "\n",
    "#                                 metrics_with_meta = {\n",
    "#                                     \"subject\": folder,\n",
    "#                                     \"relabeled\": grasp_df['relabeled'].iloc[0],\n",
    "#                                     \"stimulus\": grasp,\n",
    "#                                     \"channel\": channel,\n",
    "#                                     \"window_id\": f\"{file_name}_{grasp}_{channel}_{i}\",\n",
    "#                                     \"file_name\": file_name,\n",
    "#                                     \"window_number\": i,\n",
    "#                                     **metrics\n",
    "#                                 }\n",
    "#                                 all_metrics.append(metrics_with_meta)\n",
    "\n",
    "# # Crear DataFrame con todas las métricas calculadas\n",
    "# metrics_df = pd.DataFrame(all_metrics)\n",
    "\n",
    "# # Ordenar columnas\n",
    "# meta_cols = [\"subject\", \"relabeled\", \"stimulus\", \"channel\", \"window_id\", \"file_name\", \"window_number\"]\n",
    "# metric_cols = [col for col in metrics_df.columns if col not in meta_cols]\n",
    "# metrics_df = metrics_df[meta_cols + sorted(metric_cols)]\n",
    "\n",
    "# # 1. DataFrame con estructura por ventana (como pediste)\n",
    "# summary_per_window = metrics_df[['window_id', 'file_name', 'window_number'] + sorted(metric_cols)]\n",
    "# display(summary_per_window)\n",
    "\n",
    "# # 2. Promedio por canal y tipo de movimiento\n",
    "# summary_by_channel = metrics_df.groupby(['relabeled', 'channel']).mean(numeric_only=True).reset_index()\n",
    "# display(summary_by_channel)\n",
    "\n",
    "# # 3. Promedio final por tipo de movimiento (acumulado)\n",
    "# summary_by_movement = summary_by_channel.groupby(['relabeled']).mean(numeric_only=True).reset_index()\n",
    "# display(summary_by_movement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1869f79a",
   "metadata": {},
   "source": [
    "- 200 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 400\n",
    "all_metrics = []\n",
    "\n",
    "emg_columns = [col for col in combined_df.columns if col.startswith('Channel')]\n",
    "\n",
    "for folder in os.listdir(data_path):\n",
    "    if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "        folder_path = os.path.join(data_path, folder)\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.mat'):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "                try:\n",
    "                    mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_name}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "                test_df, grasps = src.build_dataframe(\n",
    "                    mat_file=mat_data,\n",
    "                    database=database,\n",
    "                    filename=file_name,\n",
    "                    rectify=False,\n",
    "                    normalize=True\n",
    "                )\n",
    "\n",
    "                test_df = test_df[test_df['relabeled'].isin(filtered_labels)]\n",
    "\n",
    "                envelope_df = src.get_envelope_lowpass(test_df[emg_columns], fm=fm, cutoff_freq=0.6, envelope_type=1)\n",
    "\n",
    "                meta_columns = [\"Time (s)\", \"subject\", \"re_repetition\", \"stimulus\", \"relabeled\"]\n",
    "                result_df = pd.concat([envelope_df, test_df[meta_columns]], axis=1)\n",
    "\n",
    "                for grasp in grasps:\n",
    "                    grasp_df = result_df[result_df['stimulus'] == grasp]\n",
    "\n",
    "                    if grasp_df.empty:\n",
    "                        continue\n",
    "\n",
    "                    # Agrupar por repetición\n",
    "                    for repetition in grasp_df['re_repetition'].unique():\n",
    "                        rep_df = grasp_df[grasp_df['re_repetition'] == repetition]\n",
    "\n",
    "                        for channel in emg_columns:\n",
    "                            ventanas = src.create_windows_with_overlap(rep_df[[channel, 'relabeled']], window_length, overlap)\n",
    "\n",
    "                            for i, ventana in enumerate(ventanas):\n",
    "                                if len(ventana) == window_length:\n",
    "                                    signal = ventana[channel].values\n",
    "                                    metrics = calculate_emg_metrics_means(signal)\n",
    "\n",
    "                                    metrics_with_meta = {\n",
    "                                        \"subject\": folder,\n",
    "                                        \"relabeled\": rep_df['relabeled'].iloc[0],\n",
    "                                        \"stimulus\": grasp,\n",
    "                                        \"channel\": channel,\n",
    "                                        \"re_repetition\": repetition,\n",
    "                                        \"window_id\": f\"{file_name}_{grasp}_{channel}_{repetition}_{i}\",\n",
    "                                        \"file_name\": file_name,\n",
    "                                        \"window_number\": i,\n",
    "                                        **metrics\n",
    "                                    }\n",
    "                                    all_metrics.append(metrics_with_meta)\n",
    "\n",
    "# Crear DataFrame con todas las métricas calculadas\n",
    "metrics_df_200 = pd.DataFrame(all_metrics)\n",
    "\n",
    "# Ordenar columnas\n",
    "meta_cols = [\"subject\", \"relabeled\", \"stimulus\", \"channel\", \"re_repetition\", \"window_id\", \"file_name\", \"window_number\"]\n",
    "metric_cols_200 = [col for col in metrics_df_200.columns if col not in meta_cols]\n",
    "metrics_df_200 = metrics_df_200[meta_cols + sorted(metric_cols_200)]\n",
    "\n",
    "# 1. Estructura por ventana\n",
    "summary_per_window_200 = metrics_df_200[['window_id', 'file_name', 'window_number'] + sorted(metric_cols_200)]\n",
    "display(summary_per_window_200)\n",
    "\n",
    "# 2. Promedio por canal, repetición y tipo de movimiento\n",
    "summary_by_channel_rep_200 = metrics_df_200.groupby(['subject', 'relabeled', 'channel', 're_repetition']).mean(numeric_only=True).reset_index()\n",
    "display(summary_by_channel_rep_200)\n",
    "\n",
    "# 3. Promedio final por tipo de movimiento (acumulado)\n",
    "summary_by_movement_200 = summary_by_channel_rep_200.groupby(['relabeled']).mean(numeric_only=True).reset_index()\n",
    "display(summary_by_movement_200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9cfc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas que contengan \"channel11\" o \"channel12\" (sin distinguir mayúsculas)\n",
    "metrics_df_200 = metrics_df_200[~metrics_df_200['channel'].isin(['Channel 11', 'Channel 12'])]\n",
    "\n",
    "metrics_df_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e524f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Eliminar columnas no deseadas\n",
    "cols_to_drop = ['Kurt', 'ZC', 'MNF', 'MNP', ' SSC', 'TD', 'VAR', 'WL']\n",
    "metrics_df_filtered = metrics_df_200.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "# 1.1. Eliminar columnas con nombres mal formateados (ej. 'ChannelChannel 3_window_number')\n",
    "metrics_df_filtered = metrics_df_filtered.loc[:, ~metrics_df_filtered.columns.str.contains(\"ChannelChannel\")]\n",
    "\n",
    "# 2. Agrupar por subject, relabeled, re_repetition y channel, promediando las métricas\n",
    "grouped = metrics_df_filtered.groupby(['subject', 'relabeled', 're_repetition', 'channel']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# 3. Pivotar para reorganizar métricas por canal\n",
    "pivoted = grouped.pivot_table(\n",
    "    index=['subject', 'relabeled', 're_repetition'],\n",
    "    columns='channel'\n",
    ")\n",
    "\n",
    "# 4. Aplanar MultiIndex de columnas (por ejemplo: Channel1_IAV)\n",
    "pivoted.columns = [f\"{col[1]}_{col[0]}\" for col in pivoted.columns]\n",
    "pivoted = pivoted.reset_index()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Separar columnas que no se deben normalizar\n",
    "non_normalized_cols = ['subject', 'relabeled', 're_repetition']\n",
    "columns_to_normalize = [col for col in pivoted.columns if col not in non_normalized_cols]\n",
    "\n",
    "# Inicializar el escalador\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Aplicar MinMaxScaler solo a las columnas deseadas\n",
    "normalized_data = scaler.fit_transform(pivoted[columns_to_normalize])\n",
    "\n",
    "# Combinar columnas no normalizadas con las normalizadas\n",
    "pivoted_normalized = pd.concat(\n",
    "    [pivoted[non_normalized_cols].reset_index(drop=True),\n",
    "     pd.DataFrame(normalized_data, columns=columns_to_normalize)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# 5. Guardar en CSV\n",
    "pivoted_normalized.to_csv(\"metrics_avg_by_repetition_tesis_3.csv\", index=False)\n",
    "\n",
    "print(\"✅ DataFrame transformado y guardado como 'metrics_avg_by_repetition.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3bf676",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47961f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pivoted_normalized.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07deb431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Suponiendo que ya tienes cargado el DataFrame llamado summary_by_channel_200\n",
    "\n",
    "# # 1. Pivotar el DataFrame\n",
    "# df_pivoted = summary_by_channel_200.pivot_table(\n",
    "#     index=['relabeled', 'window_number'],\n",
    "#     columns='channel'\n",
    "# )\n",
    "\n",
    "# # 2. Aplanar columnas MultiIndex\n",
    "# df_pivoted.columns = [f\"Channel{col[1]}_{col[0]}\" for col in df_pivoted.columns]\n",
    "# df_pivoted = df_pivoted.reset_index()\n",
    "\n",
    "# # 3. Eliminar columnas no deseadas\n",
    "# columns_to_drop = [col for col in df_pivoted.columns if any(x in col for x in ['Kurt', 'ZC'])]\n",
    "# df_cleaned = df_pivoted.drop(columns=columns_to_drop)\n",
    "# display(df_cleaned)\n",
    "# # 4. Guardar como CSV\n",
    "# df_cleaned.to_csv(\"summary_by_window.csv\", index=False)\n",
    "\n",
    "# print(\"✅ DataFrame reestructurado y guardado como 'summary_by_window.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001cc0de",
   "metadata": {},
   "source": [
    "- 100 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_length = 200\n",
    "# # Lista para almacenar las métricas de todas las ventanas\n",
    "# all_metrics = []\n",
    "\n",
    "# # Obtener nombres de los canales EMG (suponiendo que empiezan por 'Channel')\n",
    "# emg_columns = [col for col in combined_df.columns if col.startswith('Channel')]\n",
    "\n",
    "# for folder in os.listdir(data_path):\n",
    "#     if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "#         folder_path = os.path.join(data_path, folder)\n",
    "\n",
    "#         for file_name in os.listdir(folder_path):\n",
    "#             if file_name.endswith('.mat'):\n",
    "#                 file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "#                 try:\n",
    "#                     mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error loading {file_name}: {str(e)}\")\n",
    "#                     continue\n",
    "\n",
    "#                 test_df, grasps = src.build_dataframe(\n",
    "#                     mat_file=mat_data,\n",
    "#                     database=database,\n",
    "#                     filename=file_name,\n",
    "#                     rectify=False,\n",
    "#                     normalize=True\n",
    "#                 )\n",
    "\n",
    "#                 test_df = test_df[test_df['relabeled'].isin(filtered_labels)]\n",
    "\n",
    "#                 # Extraer la envolvente de todos los canales EMG\n",
    "#                 envelope_df = src.get_envelope_lowpass(test_df[emg_columns], fm=fm, cutoff_freq=0.6, envelope_type=1)\n",
    "\n",
    "#                 # Añadir columnas meta\n",
    "#                 meta_columns = [\"Time (s)\", \"subject\", \"re_repetition\", \"stimulus\", \"relabeled\"]\n",
    "#                 result_df = pd.concat([envelope_df, test_df[meta_columns]], axis=1)\n",
    "\n",
    "#                 for grasp in grasps:\n",
    "#                     grasp_df = result_df[result_df['stimulus'] == grasp]\n",
    "\n",
    "#                     if grasp_df.empty:\n",
    "#                         print(f\"No hay datos para el grasp {grasp} en {file_name}.\")\n",
    "#                         continue\n",
    "\n",
    "#                     for channel in emg_columns:\n",
    "#                         ventanas = src.create_windows_with_overlap(grasp_df[[channel, 'relabeled']], window_length, overlap)\n",
    "\n",
    "#                         for i, ventana in enumerate(ventanas):\n",
    "#                             if len(ventana) == window_length:\n",
    "#                                 signal = ventana[channel].values\n",
    "#                                 metrics = calculate_emg_metrics_means(signal)\n",
    "\n",
    "#                                 metrics_with_meta = {\n",
    "#                                     \"subject\": folder,\n",
    "#                                     \"relabeled\": grasp_df['relabeled'].iloc[0],\n",
    "#                                     \"stimulus\": grasp,\n",
    "#                                     \"channel\": channel,\n",
    "#                                     \"window_id\": f\"{file_name}_{grasp}_{channel}_{i}\",\n",
    "#                                     \"file_name\": file_name,\n",
    "#                                     \"window_number\": i,\n",
    "#                                     **metrics\n",
    "#                                 }\n",
    "#                                 all_metrics.append(metrics_with_meta)\n",
    "\n",
    "# # Crear DataFrame con todas las métricas calculadas\n",
    "# metrics_df_100 = pd.DataFrame(all_metrics)\n",
    "\n",
    "# # Ordenar columnas\n",
    "# meta_cols = [\"subject\", \"relabeled\", \"stimulus\", \"channel\", \"window_id\", \"file_name\", \"window_number\"]\n",
    "# metric_cols_100 = [col for col in metrics_df_100.columns if col not in meta_cols]\n",
    "# metrics_df_100 = metrics_df_100[meta_cols + sorted(metric_cols)]\n",
    "\n",
    "# # 1. DataFrame con estructura por ventana (como pediste)\n",
    "# summary_per_window_100 = metrics_df_100[['window_id', 'file_name', 'window_number'] + sorted(metric_cols_100)]\n",
    "# display(summary_per_window_100)\n",
    "\n",
    "# # 2. Promedio por canal y tipo de movimiento\n",
    "# summary_by_channel_100 = metrics_df_100.groupby(['relabeled', 'channel']).mean(numeric_only=True).reset_index()\n",
    "# display(summary_by_channel_100)\n",
    "\n",
    "# # 3. Promedio final por tipo de movimiento (acumulado)\n",
    "# summary_by_movement_100 = summary_by_channel_100.groupby(['relabeled']).mean(numeric_only=True).reset_index()\n",
    "# display(summary_by_movement_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8b2ebc",
   "metadata": {},
   "source": [
    "## Dataframes for grasp with enveloped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ce909",
   "metadata": {},
   "source": [
    "- 300 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parámetros para el ventaneado\n",
    "# fm = 2000  # Frecuencia de muestreo en Hz\n",
    "# window_length = 600  # Ventana de 300 ms en muestras\n",
    "# overlap = 0  # Sin superposición\n",
    "\n",
    "# # Diccionario para almacenar DataFrames por cada valor único de 'relabeled'\n",
    "# metrics_dfs_by_relabeled = {}\n",
    "\n",
    "# # Buscar carpetas que coincidan con el patrón \"s + número\" o \"Subject + número\"\n",
    "# for folder in os.listdir(data_path):\n",
    "#     if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "#         folder_path = os.path.join(data_path, folder)\n",
    "\n",
    "#         for file_name in os.listdir(folder_path):\n",
    "#             if file_name.endswith('.mat'):\n",
    "#                 file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "#                 try:\n",
    "#                     mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error loading {file_name}: {str(e)}\")\n",
    "#                     continue\n",
    "\n",
    "#                 test_df, grasps = src.build_dataframe(\n",
    "#                     mat_file=mat_data,\n",
    "#                     database=database,\n",
    "#                     filename=file_name,\n",
    "#                     rectify=False,\n",
    "#                     normalize=True\n",
    "#                 )\n",
    "#                 test_df = test_df[test_df['relabeled'].isin(filtered_labels)]\n",
    "\n",
    "#                 # Identificar todos los canales EMG\n",
    "#                 emg_columns = [col for col in test_df.columns if col.startswith(\"Channel\")]\n",
    "#                 if not emg_columns:\n",
    "#                     print(f\"No se encontraron canales EMG en {file_name}.\")\n",
    "#                     continue\n",
    "\n",
    "#                 # Aplicar extracción del envelope a todos los canales\n",
    "#                 envelope_df = src.get_envelope_lowpass(test_df[emg_columns], fm=fm, cutoff_freq=0.6, envelope_type=1)\n",
    "\n",
    "#                 # Conservar columnas meta\n",
    "#                 meta_columns = [\"Time (s)\", \"subject\", \"re_repetition\", \"stimulus\", \"relabeled\"]\n",
    "#                 result_df = pd.concat([envelope_df, test_df[meta_columns]], axis=1)\n",
    "\n",
    "#                 for grasp in grasps:\n",
    "#                     grasp_df = result_df[result_df['stimulus'] == grasp]\n",
    "\n",
    "#                     if grasp_df.empty:\n",
    "#                         continue\n",
    "\n",
    "#                     # Procesar por canal y luego promediar\n",
    "#                     metrics_by_window = []\n",
    "\n",
    "#                     for channel in emg_columns:\n",
    "#                         ventanas = src.create_windows_with_overlap(grasp_df[[channel, 'relabeled']], window_length, overlap)\n",
    "\n",
    "#                         for ventana in ventanas:\n",
    "#                             if len(ventana) == window_length:\n",
    "#                                 signal = ventana[channel].values\n",
    "#                                 metrics = calculate_emg_metrics_means(signal)\n",
    "#                                 metrics_by_window.append(metrics)\n",
    "\n",
    "#                     # Si se calcularon métricas en al menos un canal\n",
    "#                     if metrics_by_window:\n",
    "#                         avg_metrics = pd.DataFrame(metrics_by_window).mean().to_dict()\n",
    "\n",
    "#                         relabeled_value = grasp_df['relabeled'].iloc[0]\n",
    "#                         metrics_with_meta = {\n",
    "#                             \"subject\": folder,\n",
    "#                             \"relabeled\": relabeled_value,\n",
    "#                             \"stimulus\": grasp,\n",
    "#                             **avg_metrics\n",
    "#                         }\n",
    "\n",
    "#                         if relabeled_value not in metrics_dfs_by_relabeled:\n",
    "#                             metrics_dfs_by_relabeled[relabeled_value] = []\n",
    "\n",
    "#                         metrics_dfs_by_relabeled[relabeled_value].append(metrics_with_meta)\n",
    "\n",
    "# # Convertir a DataFrames y agrupar por sujeto y relabeled\n",
    "# for relabeled_value, data in metrics_dfs_by_relabeled.items():\n",
    "#     df = pd.DataFrame(data)\n",
    "#     df_mean = df.groupby([\"subject\", \"relabeled\", \"stimulus\"]).mean(numeric_only=True).reset_index()\n",
    "#     var_name = f\"df_relabeled_{relabeled_value}_300\"\n",
    "#     globals()[var_name] = df_mean\n",
    "#     display(globals()[var_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46d7828",
   "metadata": {},
   "source": [
    "- 200 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros para el ventaneado\n",
    "fm = 2000  # Frecuencia de muestreo en Hz\n",
    "window_length = 400  # Ventana de 200 ms en muestras\n",
    "overlap = 0  # Sin superposición\n",
    "\n",
    "# Diccionario para almacenar DataFrames por cada valor único de 'relabeled'\n",
    "metrics_dfs_by_relabeled = {}\n",
    "\n",
    "# Buscar carpetas que coincidan con el patrón \"s + número\" o \"Subject + número\"\n",
    "for folder in os.listdir(data_path):\n",
    "    if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "        folder_path = os.path.join(data_path, folder)\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.mat'):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "                try:\n",
    "                    mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_name}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "                test_df, grasps = src.build_dataframe(\n",
    "                    mat_file=mat_data,\n",
    "                    database=database,\n",
    "                    filename=file_name,\n",
    "                    rectify=False,\n",
    "                    normalize=True\n",
    "                )\n",
    "                test_df = test_df[test_df['relabeled'].isin(filtered_labels)]\n",
    "\n",
    "                # Identificar todos los canales EMG\n",
    "                emg_columns = [col for col in test_df.columns if col.startswith(\"Channel\")]\n",
    "                if not emg_columns:\n",
    "                    print(f\"No se encontraron canales EMG en {file_name}.\")\n",
    "                    continue\n",
    "\n",
    "                # Aplicar extracción del envelope a todos los canales\n",
    "                envelope_df = src.get_envelope_lowpass(test_df[emg_columns], fm=fm, cutoff_freq=0.6, envelope_type=1)\n",
    "\n",
    "                # Conservar columnas meta\n",
    "                meta_columns = [\"Time (s)\", \"subject\", \"re_repetition\", \"stimulus\", \"relabeled\"]\n",
    "                result_df = pd.concat([envelope_df, test_df[meta_columns]], axis=1)\n",
    "\n",
    "                for grasp in grasps:\n",
    "                    grasp_df = result_df[result_df['stimulus'] == grasp]\n",
    "\n",
    "                    if grasp_df.empty:\n",
    "                        continue\n",
    "\n",
    "                    # Procesar por canal y luego promediar\n",
    "                    metrics_by_window = []\n",
    "\n",
    "                    for channel in emg_columns:\n",
    "                        ventanas = src.create_windows_with_overlap(grasp_df[[channel, 'relabeled']], window_length, overlap)\n",
    "\n",
    "                        for ventana in ventanas:\n",
    "                            if len(ventana) == window_length:\n",
    "                                signal = ventana[channel].values\n",
    "                                metrics = calculate_emg_metrics_means(signal)\n",
    "                                metrics_by_window.append(metrics)\n",
    "\n",
    "                    # Si se calcularon métricas en al menos un canal\n",
    "                    if metrics_by_window:\n",
    "                        avg_metrics = pd.DataFrame(metrics_by_window).mean().to_dict()\n",
    "\n",
    "                        relabeled_value = grasp_df['relabeled'].iloc[0]\n",
    "                        metrics_with_meta = {\n",
    "                            \"subject\": folder,\n",
    "                            \"relabeled\": relabeled_value,\n",
    "                            \"stimulus\": grasp,\n",
    "                            **avg_metrics\n",
    "                        }\n",
    "\n",
    "                        if relabeled_value not in metrics_dfs_by_relabeled:\n",
    "                            metrics_dfs_by_relabeled[relabeled_value] = []\n",
    "\n",
    "                        metrics_dfs_by_relabeled[relabeled_value].append(metrics_with_meta)\n",
    "\n",
    "# Convertir a DataFrames y agrupar por sujeto y relabeled\n",
    "for relabeled_value, data in metrics_dfs_by_relabeled.items():\n",
    "    df = pd.DataFrame(data)\n",
    "    df_mean = df.groupby([\"subject\", \"relabeled\", \"stimulus\"]).mean(numeric_only=True).reset_index()\n",
    "    var_name = f\"df_relabeled_{relabeled_value}_200\"\n",
    "    globals()[var_name] = df_mean\n",
    "    display(globals()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd927db",
   "metadata": {},
   "source": [
    "- 100 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3712105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parámetros para el ventaneado\n",
    "# fm = 2000  # Frecuencia de muestreo en Hz\n",
    "# window_length = 200  # Ventana de 100 ms en muestras\n",
    "# overlap = 0  # Sin superposición\n",
    "\n",
    "# # Diccionario para almacenar DataFrames por cada valor único de 'relabeled'\n",
    "# metrics_dfs_by_relabeled = {}\n",
    "\n",
    "# # Buscar carpetas que coincidan con el patrón \"s + número\" o \"Subject + número\"\n",
    "# for folder in os.listdir(data_path):\n",
    "#     if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "#         folder_path = os.path.join(data_path, folder)\n",
    "\n",
    "#         for file_name in os.listdir(folder_path):\n",
    "#             if file_name.endswith('.mat'):\n",
    "#                 file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "#                 try:\n",
    "#                     mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error loading {file_name}: {str(e)}\")\n",
    "#                     continue\n",
    "\n",
    "#                 test_df, grasps = src.build_dataframe(\n",
    "#                     mat_file=mat_data,\n",
    "#                     database=database,\n",
    "#                     filename=file_name,\n",
    "#                     rectify=False,\n",
    "#                     normalize=True\n",
    "#                 )\n",
    "#                 test_df = test_df[test_df['relabeled'].isin(filtered_labels)]\n",
    "\n",
    "#                 # Identificar todos los canales EMG\n",
    "#                 emg_columns = [col for col in test_df.columns if col.startswith(\"Channel\")]\n",
    "#                 if not emg_columns:\n",
    "#                     print(f\"No se encontraron canales EMG en {file_name}.\")\n",
    "#                     continue\n",
    "\n",
    "#                 # Aplicar extracción del envelope a todos los canales\n",
    "#                 envelope_df = src.get_envelope_lowpass(test_df[emg_columns], fm=fm, cutoff_freq=0.6, envelope_type=1)\n",
    "\n",
    "#                 # Conservar columnas meta\n",
    "#                 meta_columns = [\"Time (s)\", \"subject\", \"re_repetition\", \"stimulus\", \"relabeled\"]\n",
    "#                 result_df = pd.concat([envelope_df, test_df[meta_columns]], axis=1)\n",
    "\n",
    "#                 for grasp in grasps:\n",
    "#                     grasp_df = result_df[result_df['stimulus'] == grasp]\n",
    "\n",
    "#                     if grasp_df.empty:\n",
    "#                         continue\n",
    "\n",
    "#                     # Procesar por canal y luego promediar\n",
    "#                     metrics_by_window = []\n",
    "\n",
    "#                     for channel in emg_columns:\n",
    "#                         ventanas = src.create_windows_with_overlap(grasp_df[[channel, 'relabeled']], window_length, overlap)\n",
    "\n",
    "#                         for ventana in ventanas:\n",
    "#                             if len(ventana) == window_length:\n",
    "#                                 signal = ventana[channel].values\n",
    "#                                 metrics = calculate_emg_metrics_means(signal)\n",
    "#                                 metrics_by_window.append(metrics)\n",
    "\n",
    "#                     # Si se calcularon métricas en al menos un canal\n",
    "#                     if metrics_by_window:\n",
    "#                         avg_metrics = pd.DataFrame(metrics_by_window).mean().to_dict()\n",
    "\n",
    "#                         relabeled_value = grasp_df['relabeled'].iloc[0]\n",
    "#                         metrics_with_meta = {\n",
    "#                             \"subject\": folder,\n",
    "#                             \"relabeled\": relabeled_value,\n",
    "#                             \"stimulus\": grasp,\n",
    "#                             **avg_metrics\n",
    "#                         }\n",
    "\n",
    "#                         if relabeled_value not in metrics_dfs_by_relabeled:\n",
    "#                             metrics_dfs_by_relabeled[relabeled_value] = []\n",
    "\n",
    "#                         metrics_dfs_by_relabeled[relabeled_value].append(metrics_with_meta)\n",
    "\n",
    "# # Convertir a DataFrames y agrupar por sujeto y relabeled\n",
    "# for relabeled_value, data in metrics_dfs_by_relabeled.items():\n",
    "#     df = pd.DataFrame(data)\n",
    "#     df_mean = df.groupby([\"subject\", \"relabeled\", \"stimulus\"]).mean(numeric_only=True).reset_index()\n",
    "#     var_name = f\"df_relabeled_{relabeled_value}_100\"\n",
    "#     globals()[var_name] = df_mean\n",
    "#     display(globals()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621d8464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista para almacenar todos los DataFrames promediados\n",
    "all_metrics_dfs = []\n",
    "\n",
    "# Convertir listas en DataFrames, promediar por sujeto y asignar variables\n",
    "for relabeled_value, data in metrics_dfs_by_relabeled.items():\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    df_mean = df.groupby([\"subject\", \"relabeled\", \"stimulus\"]).mean().reset_index()\n",
    "    var_name = f\"df_relabeled_{relabeled_value}_200\"\n",
    "    globals()[var_name] = df_mean\n",
    "    #display(globals()[var_name])\n",
    "\n",
    "    # Agregar al DataFrame general\n",
    "    all_metrics_dfs.append(df_mean)\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "df_all = pd.concat(all_metrics_dfs, ignore_index=True)\n",
    "df_metrics = df_all.drop(columns=['ZC','Kurt'])\n",
    "# Guardar en un archivo CSV\n",
    "df_metrics.to_csv(\"metrics_all_subjects.csv\", index=False)\n",
    "\n",
    "display(df_all)\n",
    "display(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e6ab2e",
   "metadata": {},
   "source": [
    "### Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a143a92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista para almacenar todos los DataFrames promediados\n",
    "all_metrics_dfs = []\n",
    "\n",
    "# Convertir listas en DataFrames, promediar por sujeto y asignar variables\n",
    "for relabeled_value, data in metrics_dfs_by_relabeled.items():\n",
    "    df = pd.DataFrame(data)\n",
    "    df_mean = df.groupby([\"subject\", \"relabeled\", \"stimulus\"]).mean().reset_index()\n",
    "    var_name = f\"df_relabeled_{relabeled_value}_200\"\n",
    "    globals()[var_name] = df_mean\n",
    "    all_metrics_dfs.append(df_mean)\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "df_all = pd.concat(all_metrics_dfs, ignore_index=True)\n",
    "\n",
    "# Eliminar columnas no deseadas antes de normalizar\n",
    "df_metrics = df_all.drop(columns=['ZC', 'Kurt'])\n",
    "\n",
    "# Seleccionar columnas numéricas a normalizar (ignorando las categóricas)\n",
    "numeric_cols = df_metrics.select_dtypes(include='number').columns.difference(['subject', 'relabeled', 'stimulus'])\n",
    "\n",
    "# Aplicar normalización Min-Max\n",
    "scaler = MinMaxScaler()\n",
    "df_metrics[numeric_cols] = scaler.fit_transform(df_metrics[numeric_cols])\n",
    "\n",
    "# Guardar en un archivo CSV\n",
    "df_metrics.to_csv(\"metrics_all_subjects_normalized.csv\", index=False)\n",
    "\n",
    "# Mostrar resultados\n",
    "display(df_all)\n",
    "display(df_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a9036",
   "metadata": {},
   "source": [
    "## Summary by movement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeca455",
   "metadata": {},
   "source": [
    "- 300 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parámetros para el ventaneado\n",
    "# fm = 2000  # Frecuencia de muestreo en Hz\n",
    "# window_length = 600  # Ventana de 300 ms en muestras\n",
    "# overlap = 0  # Sin superposición\n",
    "\n",
    "# # Lista para almacenar todas las métricas\n",
    "# all_metrics = []\n",
    "\n",
    "# # Buscar carpetas que coincidan con el patrón \"s + número\" o \"Subject + número\"\n",
    "# for folder in os.listdir(data_path):\n",
    "#     if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "#         folder_path = os.path.join(data_path, folder)\n",
    "        \n",
    "#         for file_name in os.listdir(folder_path):\n",
    "#             if file_name.endswith('.mat'):\n",
    "#                 file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "#                 try:\n",
    "#                     mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error loading {file_name}: {str(e)}\")\n",
    "#                     continue\n",
    "\n",
    "#                 test_df, grasps = src.build_dataframe(\n",
    "#                     mat_file=mat_data,\n",
    "#                     database=database,\n",
    "#                     filename=file_name,\n",
    "#                     rectify=False,\n",
    "#                     normalize=True\n",
    "#                 )\n",
    "\n",
    "#                 test_df = test_df[test_df['relabeled'].isin(filtered_labels)]\n",
    "\n",
    "#                 # Detectar canales EMG\n",
    "#                 emg_columns = [col for col in test_df.columns if col.startswith(\"Channel\")]\n",
    "#                 if not emg_columns:\n",
    "#                     print(f\"No se encontraron canales EMG en {file_name}\")\n",
    "#                     continue\n",
    "\n",
    "#                 # Calcular envelope\n",
    "#                 envelope_df = src.get_envelope_lowpass(test_df[emg_columns], fm=fm, cutoff_freq=0.6, envelope_type=1)\n",
    "\n",
    "#                 # Agregar metadata\n",
    "#                 meta_columns = [\"Time (s)\", \"subject\", \"re_repetition\", \"stimulus\", \"relabeled\"]\n",
    "#                 result_df = pd.concat([envelope_df, test_df[meta_columns]], axis=1)\n",
    "\n",
    "#                 for grasp in grasps:\n",
    "#                     grasp_df = result_df[result_df['stimulus'] == grasp]\n",
    "#                     if grasp_df.empty:\n",
    "#                         continue\n",
    "\n",
    "#                     ventanas = src.create_windows_with_overlap(grasp_df, window_length, overlap)\n",
    "#                     for i, ventana in enumerate(ventanas):\n",
    "#                         if len(ventana) != window_length:\n",
    "#                             continue\n",
    "                        \n",
    "#                         metrics_per_channel = []\n",
    "#                         for channel in emg_columns:\n",
    "#                             signal = ventana[channel].values\n",
    "#                             metrics = calculate_emg_metrics_means(signal)\n",
    "#                             metrics_per_channel.append(metrics)\n",
    "\n",
    "#                         # Promediar métricas entre canales\n",
    "#                         if metrics_per_channel:\n",
    "#                             avg_metrics = pd.DataFrame(metrics_per_channel).mean().to_dict()\n",
    "\n",
    "#                             # Agregar metadata\n",
    "#                             metrics_with_meta = {\n",
    "#                                 \"subject\": folder,\n",
    "#                                 \"relabeled\": ventana['relabeled'].iloc[0],\n",
    "#                                 \"stimulus\": grasp,\n",
    "#                                 \"window_id\": f\"{file_name}_{grasp}_{i}\",\n",
    "#                                 \"file_name\": file_name,\n",
    "#                                 \"window_number\": i,\n",
    "#                                 **avg_metrics\n",
    "#                             }\n",
    "\n",
    "#                             all_metrics.append(metrics_with_meta)\n",
    "\n",
    "# # Crear DataFrame con resultados\n",
    "# metrics_df_all_channels = pd.DataFrame(all_metrics)\n",
    "\n",
    "# # Reorganizar columnas\n",
    "# meta_cols = [\"subject\", \"relabeled\", \"stimulus\", \"window_id\", \"file_name\", \"window_number\"]\n",
    "# metric_cols = [col for col in metrics_df_all_channels.columns if col not in meta_cols]\n",
    "# column_order = meta_cols + sorted(metric_cols)\n",
    "# metrics_df_all_channels = metrics_df_all_channels[column_order]\n",
    "# display(metrics_df_all_channels)\n",
    "\n",
    "# # Agrupar y promediar por relabeled por sujeto y tipo de movimiento\n",
    "# summary_by_relabeled_300 = metrics_df_all_channels.drop(columns=[\"window_id\", \"file_name\", \"window_number\"])\n",
    "# summary_by_relabeled_300 = summary_by_relabeled_300.groupby([\"subject\", \"relabeled\", \"stimulus\"]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# print(\"\\nResumen de métricas por sujeto, relabeled y tipo de movimiento:\")\n",
    "# display(summary_by_relabeled_300)\n",
    "\n",
    "# # Agrupar y promediar por relabeled globalmente (todos los sujetos y estímulos)\n",
    "# global_summary_by_relabeled_300 = (\n",
    "#     metrics_df_all_channels\n",
    "#     .drop(columns=[\"subject\", \"stimulus\", \"window_id\", \"file_name\", \"window_number\"])\n",
    "#     .groupby(\"relabeled\")\n",
    "#     .mean(numeric_only=True)\n",
    "#     .reset_index()\n",
    "# )\n",
    "\n",
    "# print(\"\\nResumen global de métricas promediadas por 'relabeled' (todos los sujetos):\")\n",
    "# display(global_summary_by_relabeled_300)\n",
    "\n",
    "# # Estadísticas generales\n",
    "# print(f\"\\nTotal de ventanas procesadas: {len(metrics_df_all_channels)}\")\n",
    "# print(f\"Distribución por sujeto:\\n{metrics_df_all_channels['subject'].value_counts()}\")\n",
    "# print(f\"Distribución por movimiento:\\n{metrics_df_all_channels['relabeled'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe6954",
   "metadata": {},
   "source": [
    "- 200 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39e8909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros para el ventaneado\n",
    "fm = 2000  # Frecuencia de muestreo en Hz\n",
    "window_length = 400  # Ventana de 300 ms en muestras\n",
    "overlap = 0  # Sin superposición\n",
    "\n",
    "# Lista para almacenar todas las métricas\n",
    "all_metrics = []\n",
    "\n",
    "# Buscar carpetas que coincidan con el patrón \"s + número\" o \"Subject + número\"\n",
    "for folder in os.listdir(data_path):\n",
    "    if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "        folder_path = os.path.join(data_path, folder)\n",
    "        \n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.mat'):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "                try:\n",
    "                    mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_name}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "                test_df, grasps = src.build_dataframe(\n",
    "                    mat_file=mat_data,\n",
    "                    database=database,\n",
    "                    filename=file_name,\n",
    "                    rectify=False,\n",
    "                    normalize=True\n",
    "                )\n",
    "\n",
    "                test_df = test_df[test_df['relabeled'].isin(filtered_labels)]\n",
    "\n",
    "                # Detectar canales EMG\n",
    "                emg_columns = [col for col in test_df.columns if col.startswith(\"Channel\")]\n",
    "                if not emg_columns:\n",
    "                    print(f\"No se encontraron canales EMG en {file_name}\")\n",
    "                    continue\n",
    "\n",
    "                # Calcular envelope\n",
    "                envelope_df = src.get_envelope_lowpass(test_df[emg_columns], fm=fm, cutoff_freq=0.6, envelope_type=1)\n",
    "\n",
    "                # Agregar metadata\n",
    "                meta_columns = [\"Time (s)\", \"subject\", \"re_repetition\", \"stimulus\", \"relabeled\"]\n",
    "                result_df = pd.concat([envelope_df, test_df[meta_columns]], axis=1)\n",
    "\n",
    "                for grasp in grasps:\n",
    "                    grasp_df = result_df[result_df['stimulus'] == grasp]\n",
    "                    if grasp_df.empty:\n",
    "                        continue\n",
    "\n",
    "                    ventanas = src.create_windows_with_overlap(grasp_df, window_length, overlap)\n",
    "                    for i, ventana in enumerate(ventanas):\n",
    "                        if len(ventana) != window_length:\n",
    "                            continue\n",
    "                        \n",
    "                        metrics_per_channel = []\n",
    "                        for channel in emg_columns:\n",
    "                            signal = ventana[channel].values\n",
    "                            metrics = calculate_emg_metrics_means(signal)\n",
    "                            metrics_per_channel.append(metrics)\n",
    "\n",
    "                        # Promediar métricas entre canales\n",
    "                        if metrics_per_channel:\n",
    "                            avg_metrics = pd.DataFrame(metrics_per_channel).mean().to_dict()\n",
    "\n",
    "                            # Agregar metadata\n",
    "                            metrics_with_meta = {\n",
    "                                \"subject\": folder,\n",
    "                                \"relabeled\": ventana['relabeled'].iloc[0],\n",
    "                                \"stimulus\": grasp,\n",
    "                                \"window_id\": f\"{file_name}_{grasp}_{i}\",\n",
    "                                \"file_name\": file_name,\n",
    "                                \"window_number\": i,\n",
    "                                **avg_metrics\n",
    "                            }\n",
    "\n",
    "                            all_metrics.append(metrics_with_meta)\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "metrics_df_all_channels = pd.DataFrame(all_metrics)\n",
    "\n",
    "# Reorganizar columnas\n",
    "meta_cols = [\"subject\", \"relabeled\", \"stimulus\", \"window_id\", \"file_name\", \"window_number\"]\n",
    "metric_cols = [col for col in metrics_df_all_channels.columns if col not in meta_cols]\n",
    "column_order = meta_cols + sorted(metric_cols)\n",
    "metrics_df_all_channels = metrics_df_all_channels[column_order]\n",
    "display(metrics_df_all_channels)\n",
    "\n",
    "# Agrupar y promediar por relabeled por sujeto y tipo de movimiento\n",
    "summary_by_relabeled_200 = metrics_df_all_channels.drop(columns=[\"window_id\", \"file_name\", \"window_number\"])\n",
    "summary_by_relabeled_200 = summary_by_relabeled_200.groupby([\"subject\", \"relabeled\", \"stimulus\"]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "print(\"\\nResumen de métricas por sujeto, relabeled y tipo de movimiento:\")\n",
    "display(summary_by_relabeled_200)\n",
    "\n",
    "# Agrupar y promediar por relabeled globalmente (todos los sujetos y estímulos)\n",
    "global_summary_by_relabeled_200 = (\n",
    "    metrics_df_all_channels\n",
    "    .drop(columns=[\"subject\", \"stimulus\", \"window_id\", \"file_name\", \"window_number\"])\n",
    "    .groupby(\"relabeled\")\n",
    "    .mean(numeric_only=True)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\nResumen global de métricas promediadas por 'relabeled' (todos los sujetos):\")\n",
    "display(global_summary_by_relabeled_200)\n",
    "\n",
    "# Estadísticas generales\n",
    "print(f\"\\nTotal de ventanas procesadas: {len(metrics_df_all_channels)}\")\n",
    "print(f\"Distribución por sujeto:\\n{metrics_df_all_channels['subject'].value_counts()}\")\n",
    "print(f\"Distribución por movimiento:\\n{metrics_df_all_channels['relabeled'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas no deseadas antes de guardar\n",
    "columns_to_exclude = ['ZC', 'ZC_STD', 'Kurt', 'Kurt_STD']\n",
    "filtered_summary = summary_by_relabeled_200.drop(columns=[col for col in columns_to_exclude if col in summary_by_relabeled_200.columns])\n",
    "\n",
    "# Guardar en CSV\n",
    "filtered_summary.to_csv('summary_by_relabeled_200_filtered.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63667329",
   "metadata": {},
   "source": [
    "- 100 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a107b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parámetros para el ventaneado\n",
    "# fm = 2000  # Frecuencia de muestreo en Hz\n",
    "# window_length = 200  # Ventana de 300 ms en muestras\n",
    "# overlap = 0  # Sin superposición\n",
    "\n",
    "# # Lista para almacenar todas las métricas\n",
    "# all_metrics = []\n",
    "\n",
    "# # Buscar carpetas que coincidan con el patrón \"s + número\" o \"Subject + número\"\n",
    "# for folder in os.listdir(data_path):\n",
    "#     if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "#         folder_path = os.path.join(data_path, folder)\n",
    "        \n",
    "#         for file_name in os.listdir(folder_path):\n",
    "#             if file_name.endswith('.mat'):\n",
    "#                 file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "#                 try:\n",
    "#                     mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error loading {file_name}: {str(e)}\")\n",
    "#                     continue\n",
    "\n",
    "#                 test_df, grasps = src.build_dataframe(\n",
    "#                     mat_file=mat_data,\n",
    "#                     database=database,\n",
    "#                     filename=file_name,\n",
    "#                     rectify=False,\n",
    "#                     normalize=True\n",
    "#                 )\n",
    "\n",
    "#                 test_df = test_df[test_df['relabeled'].isin(filtered_labels)]\n",
    "\n",
    "#                 # Detectar canales EMG\n",
    "#                 emg_columns = [col for col in test_df.columns if col.startswith(\"Channel\")]\n",
    "#                 if not emg_columns:\n",
    "#                     print(f\"No se encontraron canales EMG en {file_name}\")\n",
    "#                     continue\n",
    "\n",
    "#                 # Calcular envelope\n",
    "#                 envelope_df = src.get_envelope_lowpass(test_df[emg_columns], fm=fm, cutoff_freq=0.6, envelope_type=1)\n",
    "\n",
    "#                 # Agregar metadata\n",
    "#                 meta_columns = [\"Time (s)\", \"subject\", \"re_repetition\", \"stimulus\", \"relabeled\"]\n",
    "#                 result_df = pd.concat([envelope_df, test_df[meta_columns]], axis=1)\n",
    "\n",
    "#                 for grasp in grasps:\n",
    "#                     grasp_df = result_df[result_df['stimulus'] == grasp]\n",
    "#                     if grasp_df.empty:\n",
    "#                         continue\n",
    "\n",
    "#                     ventanas = src.create_windows_with_overlap(grasp_df, window_length, overlap)\n",
    "#                     for i, ventana in enumerate(ventanas):\n",
    "#                         if len(ventana) != window_length:\n",
    "#                             continue\n",
    "                        \n",
    "#                         metrics_per_channel = []\n",
    "#                         for channel in emg_columns:\n",
    "#                             signal = ventana[channel].values\n",
    "#                             metrics = calculate_emg_metrics_means(signal)\n",
    "#                             metrics_per_channel.append(metrics)\n",
    "\n",
    "#                         # Promediar métricas entre canales\n",
    "#                         if metrics_per_channel:\n",
    "#                             avg_metrics = pd.DataFrame(metrics_per_channel).mean().to_dict()\n",
    "\n",
    "#                             # Agregar metadata\n",
    "#                             metrics_with_meta = {\n",
    "#                                 \"subject\": folder,\n",
    "#                                 \"relabeled\": ventana['relabeled'].iloc[0],\n",
    "#                                 \"stimulus\": grasp,\n",
    "#                                 \"window_id\": f\"{file_name}_{grasp}_{i}\",\n",
    "#                                 \"file_name\": file_name,\n",
    "#                                 \"window_number\": i,\n",
    "#                                 **avg_metrics\n",
    "#                             }\n",
    "\n",
    "#                             all_metrics.append(metrics_with_meta)\n",
    "\n",
    "# # Crear DataFrame con resultados\n",
    "# metrics_df_all_channels = pd.DataFrame(all_metrics)\n",
    "\n",
    "# # Reorganizar columnas\n",
    "# meta_cols = [\"subject\", \"relabeled\", \"stimulus\", \"window_id\", \"file_name\", \"window_number\"]\n",
    "# metric_cols = [col for col in metrics_df_all_channels.columns if col not in meta_cols]\n",
    "# column_order = meta_cols + sorted(metric_cols)\n",
    "# metrics_df_all_channels = metrics_df_all_channels[column_order]\n",
    "# display(metrics_df_all_channels)\n",
    "\n",
    "# # Agrupar y promediar por relabeled por sujeto y tipo de movimiento\n",
    "# summary_by_relabeled_100 = metrics_df_all_channels.drop(columns=[\"window_id\", \"file_name\", \"window_number\"])\n",
    "# summary_by_relabeled_100 = summary_by_relabeled_300.groupby([\"subject\", \"relabeled\", \"stimulus\"]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# print(\"\\nResumen de métricas por sujeto, relabeled y tipo de movimiento:\")\n",
    "# display(summary_by_relabeled_100)\n",
    "\n",
    "# # Agrupar y promediar por relabeled globalmente (todos los sujetos y estímulos)\n",
    "# global_summary_by_relabeled_100 = (\n",
    "#     metrics_df_all_channels\n",
    "#     .drop(columns=[\"subject\", \"stimulus\", \"window_id\", \"file_name\", \"window_number\"])\n",
    "#     .groupby(\"relabeled\")\n",
    "#     .mean(numeric_only=True)\n",
    "#     .reset_index()\n",
    "# )\n",
    "\n",
    "# print(\"\\nResumen global de métricas promediadas por 'relabeled' (todos los sujetos):\")\n",
    "# display(global_summary_by_relabeled_100)\n",
    "\n",
    "# # Estadísticas generales\n",
    "# print(f\"\\nTotal de ventanas procesadas: {len(metrics_df_all_channels)}\")\n",
    "# print(f\"Distribución por sujeto:\\n{metrics_df_all_channels['subject'].value_counts()}\")\n",
    "# print(f\"Distribución por movimiento:\\n{metrics_df_all_channels['relabeled'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55626ce2",
   "metadata": {},
   "source": [
    "## Boxplot analysis for windowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb848eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Suponiendo que los DataFrames ya están cargados\n",
    "# dataframes = {\n",
    "#     '300': global_summary_by_relabeled_300,\n",
    "#     '200': global_summary_by_relabeled_200,\n",
    "#     '100': global_summary_by_relabeled_100\n",
    "# }\n",
    "\n",
    "# # Definir las métricas excluyendo 'window_number'\n",
    "# metrics = [col for col in global_summary_by_relabeled_100.columns if col != 'window_number']\n",
    "\n",
    "# # Normalizar los datos\n",
    "# scaler = MinMaxScaler()\n",
    "# normalized_dataframes = {}\n",
    "# for label, df in dataframes.items():\n",
    "#     df_normalized = df.copy()\n",
    "#     df_normalized[metrics] = scaler.fit_transform(df[metrics])\n",
    "#     normalized_dataframes[label] = df_normalized\n",
    "\n",
    "# # Crear un solo DataFrame para facilitar el boxplot\n",
    "# merged_data = []\n",
    "# for label, df in normalized_dataframes.items():\n",
    "#     df_melted = df[metrics].melt(var_name='Métrica', value_name='Valor')\n",
    "#     df_melted['Fuente'] = label\n",
    "#     merged_data.append(df_melted)\n",
    "\n",
    "# df_final = pd.concat(merged_data, ignore_index=True)\n",
    "# display(df_final)\n",
    "# # Configurar el gráfico\n",
    "# plt.figure(figsize=(15, 6))\n",
    "# sns.boxplot(data=df_final, x='Métrica', y='Valor', hue='Fuente')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.title('Distribución de métricas normalizadas en los diferentes DataFrames')\n",
    "# plt.xlabel('Métrica')\n",
    "# plt.ylabel('Valor normalizado')\n",
    "# plt.legend(title='Fuente')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03945ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Organizar los datos por relabeled y tamaño de ventana\n",
    "# ventanas = {\n",
    "#     '100': {},  # DataFrames para ventana de 100ms\n",
    "#     '200': {},  # DataFrames para ventana de 200ms\n",
    "#     '300': {}   # DataFrames para ventana de 300ms\n",
    "# }\n",
    "\n",
    "# # Buscar todos los DataFrames globales que siguen el patrón df_relabeled_*_100\n",
    "# for var_name in globals():\n",
    "#     # Revisamos para las ventanas de 100ms\n",
    "#     if var_name.startswith('df_relabeled_') and var_name.endswith('_100'):\n",
    "#         relabeled_value = var_name.replace('df_relabeled_', '').replace('_100', '')\n",
    "#         ventanas['100'][relabeled_value] = globals()[var_name]\n",
    "    \n",
    "#     # Para ventanas de 200ms (_200) y 300ms (_300)\n",
    "#     elif var_name.startswith('df_relabeled_') and var_name.endswith('_200'):\n",
    "#         relabeled_value = var_name.replace('df_relabeled_', '').replace('_200', '')\n",
    "#         ventanas['200'][relabeled_value] = globals()[var_name]\n",
    "    \n",
    "#     elif var_name.startswith('df_relabeled_') and var_name.endswith('_300'):\n",
    "#         relabeled_value = var_name.replace('df_relabeled_', '').replace('_300', '')\n",
    "#         ventanas['300'][relabeled_value] = globals()[var_name]\n",
    "\n",
    "# # 2. Identificar todas las métricas (columnas comunes excluyendo metadatos)\n",
    "# metadata_cols = ['subject', 'relabeled', 'stimulus', 'channel', 'window_id', 'file_name']\n",
    "# first_df = next(iter(next(iter(ventanas.values())).values()), None)\n",
    "\n",
    "# if first_df is not None:\n",
    "#     metrics = [col for col in first_df.columns if col not in metadata_cols]\n",
    "# else:\n",
    "#     metrics = []  \n",
    "\n",
    "# # 3. Crear un DataFrame combinado para cada tamaño de ventana\n",
    "# combined_data = []\n",
    "\n",
    "# for window_size, relabeled_dict in ventanas.items():\n",
    "#     for relabeled_value, df in relabeled_dict.items():\n",
    "#         # Normalizar los datos de métricas para este relabeled\n",
    "#         df_norm = df.copy()\n",
    "#         scaler = MinMaxScaler()\n",
    "        \n",
    "#         # Solo normalizar columnas numéricas de métricas si hay datos\n",
    "#         if len(df) > 0 and not df[metrics].empty:\n",
    "#             df_norm[metrics] = scaler.fit_transform(df[metrics])\n",
    "        \n",
    "#         # Convertir a formato largo para seaborn\n",
    "#         df_melted = df_norm[metrics].melt(var_name='Métrica', value_name='Valor')\n",
    "#         df_melted['Relabeled'] = relabeled_value\n",
    "#         df_melted['Ventana'] = f'{window_size}'  # Mantener solo el número para la leyenda\n",
    "        \n",
    "#         combined_data.append(df_melted)\n",
    "\n",
    "# # Combinar todos los DataFrames\n",
    "# df_final = pd.concat(combined_data, ignore_index=True)\n",
    "\n",
    "# # 4. Crear un gráfico separado para cada relabeled\n",
    "# relabeled_values = df_final['Relabeled'].unique()\n",
    "\n",
    "# for relabeled in relabeled_values:\n",
    "#     # Filtrar datos para este relabeled\n",
    "#     relabeled_data = df_final[df_final['Relabeled'] == relabeled]\n",
    "    \n",
    "#     # Crear figura\n",
    "#     plt.figure(figsize=(20, 10))\n",
    "    \n",
    "#     # Crear boxplot con métricas en el eje x y comparando ventanas\n",
    "#     ax = sns.boxplot(\n",
    "#         data=relabeled_data, \n",
    "#         x='Métrica', \n",
    "#         y='Valor', \n",
    "#         hue='Ventana',\n",
    "#         palette=['#3274A1', '#E1812C', '#3A923A']  # Colores similares al ejemplo (azul, naranja, verde)\n",
    "#     )\n",
    "    \n",
    "#     # Configurar el gráfico\n",
    "#     plt.title(f'Distribución de métricas normalizadas para {relabeled}', fontsize=16)\n",
    "#     plt.xlabel('Métrica', fontsize=14)\n",
    "#     plt.ylabel('Valor normalizado', fontsize=14)\n",
    "#     plt.xticks(rotation=90)  # Rotar etiquetas para mejorar legibilidad\n",
    "    \n",
    "#     # Personalizar la leyenda para que coincida con el formato del ejemplo\n",
    "#     plt.legend(title='Fuente')\n",
    "    \n",
    "#     # Ajustar límites del eje y para que sea de 0 a 1 como en el ejemplo\n",
    "#     plt.ylim(0, 1.05)\n",
    "    \n",
    "#     # Añadir cuadrícula para mejor lectura\n",
    "#     plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     # Guardar el gráfico (opcional)\n",
    "#     # plt.savefig(f'metricas_relabeled_{relabeled}.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "#     plt.show()\n",
    "\n",
    "# # 5. Opcionalmente, gráfico combinado para todos los relabeled\n",
    "# plt.figure(figsize=(20, 10))\n",
    "\n",
    "# # Crear boxplot con todas las métricas y ventanas\n",
    "# sns.boxplot(\n",
    "#     data=df_final, \n",
    "#     x='Métrica', \n",
    "#     y='Valor', \n",
    "#     hue='Ventana',\n",
    "#     palette=['#3274A1', '#E1812C', '#3A923A'] \n",
    "# )\n",
    "\n",
    "# # Configurar el gráfico\n",
    "# plt.title('Distribución de métricas normalizadas en los diferentes DataFrames', fontsize=16)\n",
    "# plt.xlabel('Métrica', fontsize=14)\n",
    "# plt.ylabel('Valor normalizado', fontsize=14)\n",
    "# plt.xticks(rotation=90)  # Rotar etiquetas para mejorar legibilidad\n",
    "# plt.legend(title='Fuente')\n",
    "# plt.ylim(0, 1.05)  # Límites del eje y para que sea de 0 a 1 como en el ejemplo\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.7)  # Añadir cuadrícula\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae246ea6",
   "metadata": {},
   "source": [
    "## With outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d405da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar todos los dataframes en uno solo para facilitar la visualización\n",
    "all_data = []\n",
    "relabeled_dfs = {}\n",
    "\n",
    "# Buscar todas las variables df_relabeled_X_200 en el espacio global\n",
    "for var_name in list(globals().keys()):\n",
    "    if var_name.startswith('df_relabeled_') and var_name.endswith('_200'):\n",
    "        relabeled_value = var_name.split('_')[2]  # Extraer el valor de relabeled\n",
    "        relabeled_dfs[relabeled_value] = globals()[var_name]\n",
    "        \n",
    "        # Añadir los datos al conjunto combinado\n",
    "        df_copy = globals()[var_name].copy()\n",
    "        all_data.append(df_copy)\n",
    "\n",
    "# Combinar todos los dataframes\n",
    "if all_data:\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    metric_columns = [col for col in combined_df.columns if col not in ['subject', 'relabeled', 'stimulus']]\n",
    "\n",
    "# Aplicar MinMaxScaler a las columnas de métricas\n",
    "    scaler = MinMaxScaler()\n",
    "    combined_df[metric_columns] = scaler.fit_transform(combined_df[metric_columns])\n",
    "    # Identificar columnas de métricas (excluyendo columnas de metadatos)\n",
    "    metric_columns = [col for col in combined_df.columns \n",
    "                    if col not in ['subject', 'relabeled', 'stimulus']]\n",
    "    \n",
    "    # Crear una figura con subplots para cada métrica\n",
    "    n_metrics = len(metric_columns)\n",
    "    fig, axes = plt.subplots(nrows=(n_metrics+1)//2, ncols=2, figsize=(14, 3*((n_metrics+1)//2)), \n",
    "                            constrained_layout=True)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Crear boxplots para cada métrica\n",
    "    for i, metric in enumerate(metric_columns):\n",
    "        if i < len(axes):\n",
    "            # Crear boxplot usando seaborn\n",
    "            sns.boxplot(x='relabeled', y=metric, data=combined_df, ax=axes[i], palette='viridis')\n",
    "            \n",
    "            # Añadir títulos y etiquetas\n",
    "            axes[i].set_title(f'Comparación de {metric} por grasp', fontsize=14)\n",
    "            axes[i].set_xlabel('Categoría')\n",
    "            axes[i].set_ylabel(metric)\n",
    "            \n",
    "            # Rotar etiquetas del eje x si hay muchas categorías\n",
    "            if len(combined_df['relabeled'].unique()) > 5:\n",
    "                axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Eliminar subplots vacíos\n",
    "    for i in range(n_metrics, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    # Añadir título general\n",
    "    plt.suptitle('Comparación de métricas EMG entre diferentes categorías', fontsize=16, y=1.02)\n",
    "    \n",
    "    # Mostrar la figura\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Análisis estadístico básico (opcional)\n",
    "    print(\"Stadistic for grasp:\")\n",
    "    for metric in metric_columns:\n",
    "        print(f\"\\nMétrica: {metric}\")\n",
    "        display(combined_df.groupby('relabeled')[metric].describe())\n",
    "else:\n",
    "    print(\"No se encontraron variables df_relabeled_X_200 en el espacio global.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ab73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Verifica que combined_df esté definido correctamente\n",
    "if not all_data:\n",
    "    print(\"No se encontraron variables df_relabeled_X_200 en el espacio global.\")\n",
    "else:\n",
    "    # Crear un boxplot interactivo para cada métrica\n",
    "    for metric in metric_columns:\n",
    "        fig = px.box(\n",
    "            combined_df,\n",
    "            x='relabeled',\n",
    "            y=metric,\n",
    "            color='relabeled',\n",
    "            points='all',  # Muestra los puntos individuales\n",
    "            hover_data=['subject'],  # Mostrar 'subject' al pasar el cursor\n",
    "            title=f'Boxplot interactivo para {metric} por grasp'\n",
    "        )\n",
    "        fig.update_layout(\n",
    "            xaxis_title='Grasp (relabeled)',\n",
    "            yaxis_title=metric,\n",
    "            boxmode='group',\n",
    "            showlegend=False\n",
    "        )\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234f5bc4",
   "metadata": {},
   "source": [
    "- Fisher Score analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe86c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "import numpy as np\n",
    "\n",
    "# Combinar todos los dataframes en uno solo para facilitar la visualización\n",
    "all_data = []\n",
    "relabeled_dfs = {}\n",
    "\n",
    "# Buscar todas las variables df_relabeled_X_200 en el espacio global\n",
    "for var_name in list(globals().keys()):\n",
    "    if var_name.startswith('df_relabeled_') and var_name.endswith('_200'):\n",
    "        relabeled_value = var_name.split('_')[2]  # Extraer el valor de relabeled\n",
    "        relabeled_dfs[relabeled_value] = globals()[var_name]\n",
    "        \n",
    "        # Añadir los datos al conjunto combinado\n",
    "        df_copy = globals()[var_name].copy()\n",
    "        all_data.append(df_copy)\n",
    "\n",
    "# Combinar todos los dataframes\n",
    "if all_data:\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    metric_columns = [col for col in combined_df.columns if col not in ['subject', 'relabeled', 'stimulus']]\n",
    "\n",
    "# Aplicar MinMaxScaler a las columnas de métricas\n",
    "    scaler = MinMaxScaler()\n",
    "    combined_df[metric_columns] = scaler.fit_transform(combined_df[metric_columns])\n",
    "    # Identificar columnas de métricas (excluyendo columnas de metadatos)\n",
    "    metric_columns = [col for col in combined_df.columns \n",
    "                    if col not in ['subject', 'relabeled', 'stimulus']]\n",
    "    \n",
    "    # Crear una figura con subplots para cada métrica\n",
    "    n_metrics = len(metric_columns)\n",
    "    fig, axes = plt.subplots(nrows=(n_metrics+1)//2, ncols=2, figsize=(14, 3*((n_metrics+1)//2)), \n",
    "                            constrained_layout=True)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Crear boxplots para cada métrica\n",
    "    for i, metric in enumerate(metric_columns):\n",
    "        if i < len(axes):\n",
    "            # Crear boxplot usando seaborn\n",
    "            sns.boxplot(x='relabeled', y=metric, data=combined_df, ax=axes[i], palette='viridis')\n",
    "            \n",
    "            # Añadir títulos y etiquetas\n",
    "            axes[i].set_title(f'Comparación de {metric} por grasp', fontsize=14)\n",
    "            axes[i].set_xlabel('Categoría')\n",
    "            axes[i].set_ylabel(metric)\n",
    "            \n",
    "            # Rotar etiquetas del eje x si hay muchas categorías\n",
    "            if len(combined_df['relabeled'].unique()) > 5:\n",
    "                axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Eliminar subplots vacíos\n",
    "    for i in range(n_metrics, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    # Añadir título general\n",
    "    plt.suptitle('Comparación de métricas EMG entre diferentes categorías', fontsize=16, y=1.02)\n",
    "    \n",
    "    # Mostrar la figura\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 🧪 Calcular ANOVA y Fisher Score\n",
    "    anova_results = {}\n",
    "    fisher_scores = {}\n",
    "\n",
    "    categories = combined_df['relabeled'].unique()\n",
    "\n",
    "    for metric in metric_columns:\n",
    "        # Agrupar por categoría para ANOVA\n",
    "        groups = [combined_df[combined_df['relabeled'] == cat][metric].dropna().values for cat in categories]\n",
    "        \n",
    "        # ANOVA\n",
    "        try:\n",
    "            f_stat, p_val = f_oneway(*groups)\n",
    "        except:\n",
    "            f_stat, p_val = np.nan, np.nan\n",
    "        \n",
    "        anova_results[metric] = {'F-statistic': f_stat, 'p-value': p_val}\n",
    "        \n",
    "        # Fisher Score\n",
    "        overall_mean = combined_df[metric].mean()\n",
    "        num = 0\n",
    "        den = 0\n",
    "        \n",
    "        for cat in categories:\n",
    "            class_data = combined_df[combined_df['relabeled'] == cat][metric]\n",
    "            ni = len(class_data)\n",
    "            class_mean = class_data.mean()\n",
    "            class_var = class_data.var()\n",
    "            \n",
    "            num += ni * (class_mean - overall_mean) ** 2\n",
    "            den += ni * class_var\n",
    "        \n",
    "        fisher = num / den if den != 0 else 0\n",
    "        fisher_scores[metric] = fisher\n",
    "\n",
    "    # 📋 Mostrar resultados ordenados por Fisher Score\n",
    "    results_df = pd.DataFrame.from_dict(anova_results, orient='index')\n",
    "    results_df['Fisher Score'] = pd.Series(fisher_scores)\n",
    "    results_df_sorted = results_df.sort_values(by='Fisher Score', ascending=False)\n",
    "\n",
    "    print(\"\\n📊 Resultados ANOVA y Fisher Score ordenados:\\n\")\n",
    "    display(results_df_sorted)\n",
    "\n",
    "else:\n",
    "    print(\"No se encontraron variables df_relabeled_X_200 en el espacio global.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96034e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results_df_sorted[results_df_sorted['F-statistic'] > 5]\n",
    "df = df[df['p-value'] < 0.05]\n",
    "df = df[df['Fisher Score'] > 0.5]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca76bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_subject_stability = {}\n",
    "\n",
    "for metric in metric_columns:\n",
    "    stability_per_class = {}\n",
    "    for label in combined_df['relabeled'].unique():\n",
    "        subset = combined_df[combined_df['relabeled'] == label]\n",
    "        # Media por sujeto\n",
    "        subject_means = subset.groupby('subject')[metric].mean()\n",
    "        # STD entre sujetos\n",
    "        std_across_subjects = subject_means.std()\n",
    "        stability_per_class[label] = std_across_subjects\n",
    "    inter_subject_stability[metric] = stability_per_class\n",
    "\n",
    "# Convertir a DataFrame para visualizar\n",
    "stability_df = pd.DataFrame(inter_subject_stability).T\n",
    "display(stability_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6757cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Excluir métricas específicas\n",
    "excluded_features = ['ZC', 'ZC_STD', 'Kurt', 'Kurt_STD']\n",
    "filtered_metric_columns = [col for col in metric_columns if col not in excluded_features]\n",
    "\n",
    "# Filtrar columnas relevantes en el DataFrame (sin eliminar atípicos)\n",
    "filtered_df = combined_df[['relabeled'] + filtered_metric_columns].copy()\n",
    "\n",
    "# 1. Calcular la mediana por grupo (relabeled) para cada métrica\n",
    "median_df = filtered_df.groupby('relabeled')[filtered_metric_columns].median()\n",
    "\n",
    "# 2. Calcular la varianza entre las medianas para cada métrica\n",
    "median_variance = median_df.var()\n",
    "\n",
    "# 3. Convertir a DataFrame para visualización\n",
    "median_variance_df = median_variance.reset_index()\n",
    "median_variance_df.columns = ['métrica', 'varianza_entre_medianas']\n",
    "\n",
    "# 4. Normalizar las varianzas (Min-Max)\n",
    "scaler = MinMaxScaler()\n",
    "median_variance_df['varianza_normalizada'] = scaler.fit_transform(\n",
    "    median_variance_df[['varianza_entre_medianas']]\n",
    ")\n",
    "\n",
    "# 5. Mostrar la tabla ordenada (opcional)\n",
    "print(\"Varianza entre medianas y su normalización:\")\n",
    "display(median_variance_df.sort_values(by='varianza_normalizada', ascending=False))\n",
    "\n",
    "# 6. Visualización con barplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    x='varianza_normalizada',\n",
    "    y='métrica',\n",
    "    data=median_variance_df.sort_values(by='varianza_normalizada', ascending=True),\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Varianza normalizada entre medianas por métrica (con atípicos)', fontsize=14)\n",
    "plt.xlabel('Varianza normalizada')\n",
    "plt.ylabel('Métrica')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7875cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = combined_df[metric_columns].corr()\n",
    "\n",
    "# Crear el heatmap de correlación\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Mapa de Correlación de Métricas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba6d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df97cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la matriz en forma de pares con sus correlaciones\n",
    "corr_pairs = corr_matrix.unstack()\n",
    "\n",
    "# Eliminar duplicados y la diagonal (correlación de una variable consigo misma)\n",
    "# corr_pairs = corr_pairs[corr_pairs.index.get_level_values(0) != corr_pairs.index.get_level_values(1)]\n",
    "# corr_pairs = corr_pairs.drop_duplicates()\n",
    "\n",
    "# Filtrar pares con alta correlación\n",
    "high_corr = corr_pairs[abs(corr_pairs) > 0.89].sort_values(ascending=False)\n",
    "\n",
    "# Crear el DataFrame de correlaciones altas\n",
    "high_corr_df = high_corr.reset_index()\n",
    "high_corr_df.columns = ['Métrica 1', 'Métrica 2', 'Correlación']\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "display(high_corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca30934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- 1. Eliminar métricas específicas ----------\n",
    "excluded_metrics = ['ZC', 'ZC_STD', 'Kurt', 'Kurt_STD']\n",
    "filtered_metrics = [col for col in metric_columns if col not in excluded_metrics]\n",
    "\n",
    "# ---------- 2. Entrenamiento del modelo con todos los datos (sin eliminar atípicos) ----------\n",
    "X = combined_df[filtered_metrics]\n",
    "y = combined_df['relabeled']\n",
    "\n",
    "# Crear y entrenar el modelo Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Obtener importancias de características\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# ---------- 3. Visualización ----------\n",
    "plt.figure(figsize=(11, 6))\n",
    "sns.barplot(x=filtered_metrics, y=importances, palette='viridis')\n",
    "plt.title('Importancia de Características para la Clasificación de Agarre (con atípicos y sin ZC/Kurtosis)')\n",
    "plt.xlabel('Métricas')\n",
    "plt.ylabel('Importancia')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a16681a",
   "metadata": {},
   "source": [
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23326be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- 1. Definir las métricas a usar ----------\n",
    "# Asegúrate de que 'filtered_metrics' esté definido, por ejemplo:\n",
    "# filtered_metrics = [col for col in combined_df.columns if col not in ['subject', 'relabeled', 'stimulus']]\n",
    "\n",
    "# ---------- 2. Definir variables X e y ----------\n",
    "X = combined_df[filtered_metrics]\n",
    "y = combined_df['relabeled']\n",
    "\n",
    "# ---------- 3. Entrenar modelo ----------\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# ---------- 4. Importancia de características ----------\n",
    "importances = rf_model.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'Métrica': filtered_metrics,\n",
    "    'Importancia': importances\n",
    "}).sort_values(by='Importancia', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# ---------- 5. Mostrar resultados ----------\n",
    "print(\"Importancia de las características sin eliminar atípicos:\")\n",
    "display(importance_df)\n",
    "\n",
    "# ---------- 6. Visualización ----------\n",
    "plt.figure(figsize=(11, 6))\n",
    "sns.barplot(x='Métrica', y='Importancia', data=importance_df, palette='viridis')\n",
    "plt.title('Importancia de Características para la Clasificación de Agarre (con atípicos)')\n",
    "plt.xlabel('Métricas')\n",
    "plt.ylabel('Importancia')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e944dc",
   "metadata": {},
   "source": [
    "- Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f592502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- 1. Definir las métricas a usar ----------\n",
    "# Asegúrate de tener esta lista definida:\n",
    "# filtered_metrics = [col for col in combined_df.columns if col not in ['subject', 'relabeled', 'stimulus']]\n",
    "\n",
    "# ---------- 2. Definir variables X e y ----------\n",
    "X = combined_df[filtered_metrics]\n",
    "y = combined_df['relabeled']\n",
    "\n",
    "# ---------- 3. Entrenar modelo ----------\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_model.fit(X, y)\n",
    "\n",
    "# ---------- 4. Importancia de características ----------\n",
    "importances = tree_model.feature_importances_\n",
    "importances_percentage = 100 * importances / importances.sum()\n",
    "\n",
    "importances_df = pd.DataFrame({\n",
    "    'Métrica': filtered_metrics,\n",
    "    'Importancia (%)': importances_percentage\n",
    "}).sort_values(by='Importancia (%)', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n📊 Importancia de las características (%):\")\n",
    "display(importances_df)\n",
    "\n",
    "# Verificación: la suma debería ser aproximadamente 100%\n",
    "print(f\"\\n✅ Suma total de importancias: {importances_percentage.sum():.2f}%\")\n",
    "\n",
    "# ---------- 5. Visualización ----------\n",
    "plt.figure(figsize=(11, 6))\n",
    "sns.barplot(data=importances_df, x='Métrica', y='Importancia (%)', palette='viridis')\n",
    "plt.title('Importancia de Características para la Clasificación de Agarre (Árbol de Decisión con atípicos)')\n",
    "plt.xlabel('Métricas')\n",
    "plt.ylabel('Importancia (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f965c35e",
   "metadata": {},
   "source": [
    "- Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad466dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Función para calcular CV ----------\n",
    "def calculate_cv(metrics_df):\n",
    "    cv_values = {}\n",
    "    for metric in metrics_df.columns:\n",
    "        mean_value = metrics_df[metric].mean()\n",
    "        std_value = metrics_df[metric].std()\n",
    "        if mean_value != 0:\n",
    "            cv_values[metric] = (std_value / mean_value) * 100\n",
    "        else:\n",
    "            cv_values[metric] = np.nan\n",
    "    return cv_values\n",
    "\n",
    "# ---------- Parámetros ----------\n",
    "fm = 2000\n",
    "window_length = 400\n",
    "overlap = 0\n",
    "target_channel = \"Channel 8\"\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "# ---------- Iterar sobre los archivos ----------\n",
    "for folder in os.listdir(data_path):\n",
    "    if re.match(r'[sS]\\d+', folder) or re.match(r'Subject\\d+', folder):\n",
    "        folder_path = os.path.join(data_path, folder)\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.mat'):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "                try:\n",
    "                    mat_data = src.loadmatNina(database, file_name, subject=folder)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_name}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "                test_df, grasps = src.build_dataframe(\n",
    "                    mat_file=mat_data,\n",
    "                    database=database,\n",
    "                    filename=file_name,\n",
    "                    rectify=False,\n",
    "                    normalize=True\n",
    "                )\n",
    "                test_df = test_df[test_df['relabeled'].isin(filtered_labels)]\n",
    "\n",
    "                if target_channel not in test_df.columns:\n",
    "                    print(f\"{target_channel} no encontrado en {file_name}, omitiendo.\")\n",
    "                    continue\n",
    "\n",
    "                emg_columns = [target_channel]\n",
    "                envelope_df = src.get_envelope_lowpass(\n",
    "                    test_df[emg_columns], fm=2000, cutoff_freq=0.6, envelope_type=1\n",
    "                )\n",
    "\n",
    "                meta_columns = [\"Time (s)\", \"subject\", \"re_repetition\", \"stimulus\", \"relabeled\"]\n",
    "                result_df = pd.concat([envelope_df, test_df[meta_columns]], axis=1)\n",
    "\n",
    "                window_count = 0\n",
    "\n",
    "                for grasp in grasps:\n",
    "                    try:\n",
    "                        print(f\"\\nProcessing Grasp {grasp} in file {file_name}:\")\n",
    "                        grasp_df = result_df[result_df['stimulus'] == grasp]\n",
    "\n",
    "                        if grasp_df.empty:\n",
    "                            print(f\"No hay datos para el grasp {grasp} en {file_name}.\")\n",
    "                            continue\n",
    "\n",
    "                        ventanas = src.create_windows_with_overlap(grasp_df, window_length, overlap)\n",
    "\n",
    "                        for i, ventana in enumerate(ventanas):\n",
    "                            if len(ventana) == window_length:\n",
    "                                signal = ventana[target_channel].values\n",
    "                                metrics = calculate_emg_metrics_means(signal)\n",
    "\n",
    "                                metrics_with_meta = {\n",
    "                                    \"subject\": folder,\n",
    "                                    \"relabeled\": grasp_df['relabeled'].iloc[0],\n",
    "                                    \"stimulus\": grasp,\n",
    "                                    \"channel\": target_channel,\n",
    "                                    \"window_id\": f\"{file_name}_{grasp}_{i}\",\n",
    "                                    \"file_name\": file_name,\n",
    "                                    \"window_number\": window_count,\n",
    "                                    **metrics\n",
    "                                }\n",
    "\n",
    "                                all_metrics.append(metrics_with_meta)\n",
    "                                window_count += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing grasp {grasp}: {str(e)}\")\n",
    "                        continue\n",
    "\n",
    "                print(f\"Procesadas {window_count} ventanas para el archivo {file_name}\")\n",
    "\n",
    "# ---------- Crear DataFrame general ----------\n",
    "metrics_df_200 = pd.DataFrame(all_metrics)\n",
    "\n",
    "# ---------- Reordenar columnas ----------\n",
    "meta_cols = [\"subject\", \"relabeled\", \"stimulus\", \"channel\", \"window_id\", \"file_name\", \"window_number\"]\n",
    "metric_cols = [col for col in metrics_df_200.columns if col not in meta_cols]\n",
    "column_order = meta_cols + sorted(metric_cols)\n",
    "metrics_df_200 = metrics_df_200[column_order]\n",
    "\n",
    "# ---------- Filtrar métricas no deseadas ----------\n",
    "excluded_metrics = ['ZC', 'ZC_STD', 'Kurt', 'Kurt_STD']\n",
    "filtered_metrics = [col for col in metric_cols if col not in excluded_metrics]\n",
    "\n",
    "# ---------- Calcular CV directamente ----------\n",
    "cv_values = calculate_cv(metrics_df_200[filtered_metrics])\n",
    "cv_df = pd.DataFrame.from_dict(cv_values, orient='index', columns=['Coeficiente de Variación'])\n",
    "cv_df = cv_df.sort_values(by='Coeficiente de Variación', ascending=False)\n",
    "\n",
    "# ---------- Mostrar resultados ----------\n",
    "print(\"\\n📊 Coeficiente de variación de las métricas (con atípicos, sin ZC/Kurtosis):\")\n",
    "display(cv_df)\n",
    "\n",
    "print(\"\\n📈 Resumen de métricas por tipo de movimiento (completo):\")\n",
    "grouped_df = metrics_df_200.drop(columns=['channel'], errors='ignore')\n",
    "summary_by_subject_movement_200 = grouped_df.select_dtypes(include=['number']).groupby(['relabeled']).mean()\n",
    "display(summary_by_subject_movement_200)\n",
    "\n",
    "print(f\"\\n✅ Total de ventanas procesadas: {len(metrics_df_200)}\")\n",
    "print(f\"📌 Distribución por sujeto:\\n{metrics_df_200['subject'].value_counts()}\")\n",
    "print(f\"📌 Distribución por movimiento:\\n{metrics_df_200['relabeled'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1def170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización Min-Max del Coeficiente de Variación\n",
    "\n",
    "cv_df['Coeficiente de Variación Normalizado'] = (cv_df['Coeficiente de Variación'] - cv_df['Coeficiente de Variación'].min()) / (cv_df['Coeficiente de Variación'].max() - cv_df['Coeficiente de Variación'].min())\n",
    "# Mostrar los valores normalizados\n",
    "\n",
    "display(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca96fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_by_relabeled_200.to_csv(\"summary_by_relabeled_200.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
