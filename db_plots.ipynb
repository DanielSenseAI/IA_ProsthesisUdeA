{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "from scipy.io import loadmat, whosmat\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from src import config\n",
    "from src import *\n",
    "import re\n",
    "from src import loadmatNina \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from scipy.io import whosmat\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the database to analyze\n",
    "database = 'DB4'\n",
    "\n",
    "data_path = f'data/{database}'\n",
    "\n",
    "# Find the folder named with the convention s + \"number\"\n",
    "folder = None\n",
    "for item in os.listdir(data_path):\n",
    "    if re.match(r'[sS]\\d+', item) or re.match(r'Subject\\d+', item):\n",
    "        folder = item\n",
    "        break\n",
    "\n",
    "if folder:\n",
    "    folder_path = os.path.join(data_path, folder)\n",
    "    results = []\n",
    "\n",
    "    # Iterate over all .mat files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.mat'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            info = whosmat(file_path)\n",
    "            results.append((file_name, info))\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    data = {}\n",
    "    for file_name, info in results:\n",
    "        for item in info:\n",
    "            if item[0] not in data:\n",
    "                data[item[0]] = {}\n",
    "            data[item[0]][file_name] = item[1:]\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.transpose()\n",
    "    df.columns.name = 'File Name'\n",
    "\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No folder found with the convention s + 'number'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database name \n",
    "database = 'DB4'\n",
    "\n",
    "# Full path to the database folder\n",
    "data_path = os.path.abspath(os.path.join('data', database))\n",
    "\n",
    "# List of subjects, generating names from 's1' to 's10'\n",
    "subjects = [f's{i}' for i in range(1, 11)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each subject\n",
    "for subject in subjects:\n",
    "    subject_path = os.path.join(data_path, subject)  # Ruta de la carpeta s1, s2, etc.\n",
    "\n",
    "    # List of specific file names for each subject\n",
    "    filenames = [f\"{subject.upper()}_E1_A1.mat\",\n",
    "                 f\"{subject.upper()}_E2_A1.mat\",\n",
    "                 f\"{subject.upper()}_E3_A1.mat\"]\n",
    "\n",
    "    # recorrer cada archivo\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(subject_path, filename)\n",
    "        mat_file = src.loadmatNina(database, filename, subject=subject)\n",
    "        \n",
    "        # Verificar si el archivo existe\n",
    "        if os.path.isfile(file_path):\n",
    "            print(f\"Loading file: {file_path}\")\n",
    "            grasp = 2\n",
    "            src.plot_emg_data(database, mat_file, grasp, interactive=False, include_rest=True, use_stimulus=False, addFourier = False, padding = 100, title = filename)\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the results\n",
    "columns = [\"Subject\", \"Filename\", \"Restimulus Shape\", \"Movements\", \"Test Time (s)\"]\n",
    "results = []\n",
    "\n",
    "for subject in subjects:\n",
    "    subject_path = os.path.join(data_path, subject)\n",
    "\n",
    "    # List of specific files for each subject\n",
    "    filenames = [f\"{subject.upper()}_E1_A1.mat\",\n",
    "                 f\"{subject.upper()}_E2_A1.mat\",\n",
    "                 f\"{subject.upper()}_E3_A1.mat\"]\n",
    "\n",
    "    # Iterate over each file\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(subject_path, filename)\n",
    "\n",
    "        # Check if the file exists\n",
    "        if os.path.isfile(file_path):\n",
    "            print(f\"Loading file: {file_path}\")\n",
    "\n",
    "            # Load the .mat file data\n",
    "            data = loadmat(file_path)  \n",
    "            restimulus = data['restimulus'].flatten() # Extract and flatten the restimulus vector\n",
    "\n",
    "            # Output parameters\n",
    "            repetitions = len(set(restimulus))  # Calculate the number of unique movements\n",
    "            test_time = len(restimulus) / 2000  ## Calculate the total time (assuming 2kHz frequency)\n",
    "            \n",
    "            # Store the results in the list\n",
    "            results.append([subject, filename, restimulus.shape, repetitions, test_time])\n",
    "            \n",
    "            # Plot the EMG channels\n",
    "            grasp = 2\n",
    "            src.plot_emg_data(database=\"DB4\", mat_file=data, grasp_number=grasp, interactive=False, include_rest=True, use_stimulus=False, addFourier=False, padding=100, title = filename)\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each subject\n",
    "for subject in subjects:\n",
    "    subject_path = os.path.join(data_path, subject)\n",
    "\n",
    "    # List of .mat files for each subject\n",
    "    filenames = [f\"{subject.upper()}_E1_A1.mat\",\n",
    "                f\"{subject.upper()}_E2_A1.mat\",\n",
    "                f\"{subject.upper()}_E3_A1.mat\"]\n",
    "\n",
    "    # Iterate over each file\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(subject_path, filename) # Build the full file path\n",
    "\n",
    "        if os.path.isfile(file_path): # Check if the file exists\n",
    "            # Load data from the .mat file\n",
    "            print(f\"Loading file: {file_path}\")\n",
    "            data = loadmat(file_path)  \n",
    "            restimulus = data['restimulus'].flatten()  # Extract and flatten the restimulus vector\n",
    "\n",
    "            # Output parameters\n",
    "            repetitions = len(set(restimulus)) # Number of movements (excluding rest, subtract 1)\n",
    "\n",
    "            test_time = len(restimulus) / 2000  # Total time (assuming 2 kHz frequency)\n",
    "\n",
    "            # Store results\n",
    "            results.append([subject, filename, restimulus.shape, repetitions, test_time])\n",
    "            \n",
    "            # Plot EMG data\n",
    "            grasp = 2 # Define grasp type\n",
    "            src.plot_emg_channels(\n",
    "                database=\"DB4\", \n",
    "                mat_file=data,  \n",
    "                grasp_number=grasp, \n",
    "                interactive=False, \n",
    "                include_rest=True, \n",
    "                use_stimulus=False, \n",
    "                addFourier=False, \n",
    "                padding=100,\n",
    "                title= filename\n",
    "            )\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Procesamiento de datos\n",
    "# ---------------------------\n",
    "\n",
    "# Mapeo de ejercicios E1, E2, E3 a los rangos de grasps correspondientes\n",
    "exercise_mapping = {\n",
    "    \"E1\": list(range(50, 62)),   # E1 corresponde a grasps 50-61\n",
    "    \"E2\": list(range(1, 18)),    # E2 corresponde a grasps 1-17\n",
    "    \"E3\": list(range(18, 41))    # E3 corresponde a grasps 18-40\n",
    "}\n",
    "\n",
    "for subject in subjects:\n",
    "    subject_dir = os.path.join(data_path, subject)\n",
    "    \n",
    "    # Archivos E1, E2, E3 para el sujeto actual\n",
    "    for exercise in [\"E1\", \"E2\", \"E3\"]:\n",
    "        filename = f\"{subject.upper()}_{exercise}_A1.mat\"\n",
    "        file_path = os.path.join(subject_dir, filename)\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Archivo no encontrado: {file_path}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcesando: {filename}\")\n",
    "        \n",
    "        # Cargar datos del archivo .mat\n",
    "        mat_data = src.loadmatNina(database, filename, subject=subject)\n",
    "        \n",
    "        # Obtener datos reetiquetados\n",
    "        test_df, grasps_etiquetados = src.build_dataframe(\n",
    "            mat_file=mat_data,\n",
    "            database=database,\n",
    "            filename=filename,\n",
    "            rectify=False,\n",
    "            normalize=True\n",
    "        )\n",
    "        \n",
    "        # Iterar sobre grasps etiquetados\n",
    "        for grasp in grasps_etiquetados:\n",
    "            try:\n",
    "                # Graficar datos EMG para el grasp reetiquetado\n",
    "                src.plot_emg_data(\n",
    "                    database=database,\n",
    "                    mat_file=mat_data,\n",
    "                    grasp_number=grasp,\n",
    "                    interactive=False,\n",
    "                    include_rest=True,\n",
    "                    use_stimulus=False,\n",
    "                    addFourier=False,\n",
    "                    padding=100,\n",
    "                    title=f\"{filename} - Grasp {grasp}\"  # Usar el número del grasp actual\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"    Error procesando grasp {grasp}: {str(e)}\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_mapping = {\n",
    "    \"E1\": list(range(50, 62)),   # Grasps 50-61\n",
    "    \"E2\": list(range(1, 18)),    # Grasps 1-17\n",
    "    \"E3\": list(range(18, 41))    # Grasps 18-40\n",
    "}\n",
    "\n",
    "results = []\n",
    "columns = ['Subject', 'Filename', 'Data Shape', 'Repetitions', 'Test Time']\n",
    "\n",
    "for subject in subjects:\n",
    "    subject_path = os.path.join(data_path, subject)\n",
    "    \n",
    "    # Procesar cada ejercicio (E1, E2, E3)\n",
    "    for exercise in [\"E1\", \"E2\", \"E3\"]:\n",
    "        filename = f\"{subject.upper()}_{exercise}_A1.mat\"\n",
    "        file_path = os.path.join(subject_path, filename)\n",
    "        \n",
    "        if not os.path.isfile(file_path):\n",
    "            print(f\"Archivo no encontrado: {file_path}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcesando: {filename}\")\n",
    "        \n",
    "        # Cargar datos .mat\n",
    "        data = loadmat(file_path)\n",
    "        mat_data = src.loadmatNina(database, filename, subject=subject)\n",
    "        restimulus = data['restimulus'].flatten()\n",
    "        \n",
    "        # Obtener grasps reetiquetados\n",
    "        test_df, grasps_etiquetados = src.build_dataframe(\n",
    "            mat_file=mat_data,\n",
    "            database=database,\n",
    "            filename=filename,\n",
    "            rectify=False,\n",
    "            normalize=True\n",
    "        )\n",
    "        \n",
    "        # Procesar cada grasp individualmente\n",
    "        for grasp in grasps_etiquetados:\n",
    "            try:\n",
    "                # Mapear grasp reetiquetado al número original\n",
    "                # grasp_original = exercise_mapping[exercise][grasp - 1]  # -1 porque los índices empiezan en 0\n",
    "                \n",
    "                # Graficar datos EMG\n",
    "                src.plot_emg_channels(\n",
    "                    database=\"DB4\", \n",
    "                    mat_file=data,  \n",
    "                    grasp_number=grasp,\n",
    "                    interactive=False, \n",
    "                    include_rest=True,\n",
    "                    use_stimulus=False,\n",
    "                    addFourier=False,\n",
    "                    padding=100,\n",
    "                    title=f\"{filename} - Grasp {grasp}\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"    Error procesando grasp {grasp}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Calcular métricas generales del archivo\n",
    "        repetitions = len(set(restimulus)) - 1  # Excluir reposo\n",
    "        test_time = len(restimulus) / 2000  # 2000 Hz\n",
    "        \n",
    "        # Almacenar resultados generales\n",
    "        results.append([subject, filename, restimulus.shape, repetitions, test_time])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
