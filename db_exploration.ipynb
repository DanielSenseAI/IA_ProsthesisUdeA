{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Exploration\n",
    "\n",
    "This notebook allows for easy exploration of the contents of the /data folder.\n",
    "\n",
    "It is mainly design for use with the Ninapro databases and databases which are setup in similar fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "from scipy.io import loadmat, whosmat\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from src import config\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore a dataset general information. It will output a summary for each file found in a subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the database to analyze\n",
    "database = 'DB4'\n",
    "\n",
    "data_path = f'data/{database}'\n",
    "\n",
    "# Find the folder named with the convention s + \"number\"\n",
    "folder = None\n",
    "for item in os.listdir(data_path):\n",
    "    if re.match(r'[sS]\\d+', item) or re.match(r'Subject\\d+', item):\n",
    "        folder = item\n",
    "        break\n",
    "\n",
    "if folder:\n",
    "    folder_path = os.path.join(data_path, folder)\n",
    "    results = []\n",
    "\n",
    "    # Iterate over all .mat files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.mat'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            info = whosmat(file_path)\n",
    "            results.append((file_name, info))\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    data = {}\n",
    "    for file_name, info in results:\n",
    "        for item in info:\n",
    "            if item[0] not in data:\n",
    "                data[item[0]] = {}\n",
    "            data[item[0]][file_name] = item[1:]\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.transpose()\n",
    "    df.columns.name = 'File Name'\n",
    "\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No folder found with the convention s + 'number'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'S1_E1_A1.mat'\n",
    "subject  = 's1'\n",
    "mat_file = src.loadmatNina(database, filename, subject=subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### analizar tiempo de respuesta entre \"stimulus\" y \"restimulus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src import loadmatNina  # Importa la función loadmatNina\n",
    "\n",
    "# Nombre de la base de datos (coincide con DATABASE_INFO)\n",
    "database = 'DB4'\n",
    "\n",
    "# Ruta completa a la carpeta DB4\n",
    "data_path = os.path.abspath(os.path.join('data', database))\n",
    "\n",
    "# Lista de sujetos\n",
    "subjects = [f's{i}' for i in range(1, 11)]\n",
    "\n",
    "# recorrer cada sujeto\n",
    "for subject in subjects:\n",
    "    subject_path = os.path.join(data_path, subject)  # Ruta de la carpeta s1, s2, etc.\n",
    "\n",
    "    # Lista de nombres de archivos específicos\n",
    "    filenames = [f\"{subject.upper()}_E1_A1.mat\",\n",
    "                 f\"{subject.upper()}_E2_A1.mat\",\n",
    "                 f\"{subject.upper()}_E3_A1.mat\"]\n",
    "\n",
    "    # recorrer cada archivo\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(subject_path, filename)\n",
    "        \n",
    "        # Verificar si el archivo existe\n",
    "        if os.path.isfile(file_path):\n",
    "            print(f\"Loading file: {file_path}\")\n",
    "            mat_file = loadmatNina(database, filename, subject=subject)\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separar por canales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp = 2\n",
    "src.plot_emg_data(database, mat_file, grasp, interactive=False, include_rest=True, use_stimulus=False, addFourier = False, padding = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Calculation and Database Relabeling for Ninapro\n",
    "\n",
    "#### Overview\n",
    "This script demonstrates how to import EMG data and stimulus data, along with a sample calculation of features. The following parameters can be customized:\n",
    "- **Window size**\n",
    "- **Padding (zeroes)** \n",
    "- **Labeling thresholds**\n",
    "\n",
    "#### Relabeling Ninapro Databases\n",
    "To maintain consistency across databases, **Databases 1, 4, and 5** require relabeling to match the convention used in the other databases. The script reorganizes **Exercise A** to appear last in the database, resulting in the following grasp numbering:\n",
    "\n",
    "- **1 - 17:** Exercise B  \n",
    "- **18 - 40:** Exercise C  \n",
    "- **41 - 49:** Exercise D  \n",
    "- **50 - 61:** Exercise A  \n",
    "- **0:** Rest  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df, grasps = src.build_dataframe(mat_file, database, filename, rectify= False, normalize = True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_new = src.db_utils.filter_data_pandas(test_df, 50, include_rest=False, padding = 0)\n",
    "dataframe_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp = 58\n",
    "src.plot_emg_dataframe(database, test_df, grasp, interactive=False, include_rest=True, use_stimulus=True, addFourier = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "segmented_re_stimulus = src.get_signal_by_movement_complete(re_stimulus, filtered_start_index_re_stimulus[str(movement)]) #Gets the signal of the movement\n",
    "windows_re_stimulus = src.create_windows_with_overlap(segmented_re_stimulus, window_length, overlapping)\n",
    "labels = []\n",
    "for window in windows_re_stimulus:\n",
    "    label = src.get_label(window, threshold, movements_label, database)\n",
    "    labels.append(label)\n",
    "emg_signals = []\n",
    "for electrode in range(electrodes):\n",
    "    segmented_emg_signal = src.get_signal_by_movement_complete(emg[:, electrode], filtered_start_index_re_stimulus[str(movement)])\n",
    "    filtered_segmented_emg_signal = src.get_envelope_filtered(segmented_emg_signal, fc, fm)\n",
    "    windows_emg_electrode = src.create_windows_with_overlap(filtered_segmented_emg_signal, window_length, overlapping)\n",
    "    emg_signals.append(windows_emg_electrode)\n",
    "windows_quantity  = len(emg_signals[0])\n",
    "if (windows_quantity != len(labels)):\n",
    "    print('Different longitude in labels with electrodes', movement, individual, database) #This is used to check the windows between labels and windows in electrodes\n",
    "    raise ValueError('No es compatible')\n",
    "for index_label,label in enumerate(labels):\n",
    "    if not label:\n",
    "        print(label)\n",
    "    data_label = {\n",
    "        'label': label,\n",
    "    }\n",
    "    for index_electrode, element in enumerate(emg_signals):\n",
    "        if len(element) != windows_quantity:\n",
    "            print('Different longitude in electrodes', index_electrode, movement, individual, database) #This is used to find any signal with different number of window\n",
    "            raise ValueError('No es compatible')\n",
    "        for feature, function in features.items():\n",
    "            feature_calculus = function(element[index_label])\n",
    "            data_label[feature+str(index_electrode+1)] = np.array([feature_calculus])\n",
    "    new_data_label = pd.DataFrame(data_label)\n",
    "    signals_features = pd.concat([signals_features, new_data_label], ignore_index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
